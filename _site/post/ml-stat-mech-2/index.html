<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2021-05-25">

<title>Austen Lamacraft - Machine Learning and Statistical Mechanics II</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon-32x32-roboto-slab.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Austen Lamacraft</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../talks.html"> 
<span class="menu-text">Talks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../cv.pdf"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/AustenLamacraft"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/AustenLamacraft"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Machine Learning and Statistical Mechanics II</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">ML</div>
                <div class="quarto-category">Physics</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Austen Lamacraft </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 25, 2021</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#lecture-2-the-variational-autoencoder" id="toc-lecture-2-the-variational-autoencoder" class="nav-link" data-scroll-target="#lecture-2-the-variational-autoencoder">Lecture 2: The Variational Autoencoder</a>
  <ul class="collapse">
  <li><a href="#vi-redux" id="toc-vi-redux" class="nav-link" data-scroll-target="#vi-redux">VI redux</a></li>
  <li><a href="#variational-autoencoder" id="toc-variational-autoencoder" class="nav-link" data-scroll-target="#variational-autoencoder">Variational autoencoder</a>
  <ul class="collapse">
  <li><a href="#parameterization" id="toc-parameterization" class="nav-link" data-scroll-target="#parameterization">Parameterization</a></li>
  <li><a href="#reparameterization-trick" id="toc-reparameterization-trick" class="nav-link" data-scroll-target="#reparameterization-trick">Reparameterization trick</a></li>
  <li><a href="#more-practicalities" id="toc-more-practicalities" class="nav-link" data-scroll-target="#more-practicalities">More practicalities</a></li>
  <li><a href="#interpretability" id="toc-interpretability" class="nav-link" data-scroll-target="#interpretability">Interpretability</a></li>
  <li><a href="#compression-with-vaes-bits-back" id="toc-compression-with-vaes-bits-back" class="nav-link" data-scroll-target="#compression-with-vaes-bits-back">Compression with VAEs: bits back</a></li>
  </ul></li>
  <li><a href="#related-models" id="toc-related-models" class="nav-link" data-scroll-target="#related-models">Related Models</a>
  <ul class="collapse">
  <li><a href="#markov-model-autoencoders" id="toc-markov-model-autoencoders" class="nav-link" data-scroll-target="#markov-model-autoencoders">Markov Model autoencoders</a></li>
  <li><a href="#normalizing-flows" id="toc-normalizing-flows" class="nav-link" data-scroll-target="#normalizing-flows">Normalizing flows</a></li>
  </ul></li>
  <li><a href="#learning-the-path-integral" id="toc-learning-the-path-integral" class="nav-link" data-scroll-target="#learning-the-path-integral">Learning the path integral</a>
  <ul class="collapse">
  <li><a href="#the-feynmankac-formula" id="toc-the-feynmankac-formula" class="nav-link" data-scroll-target="#the-feynmankac-formula">The Feynman–Kac formula</a></li>
  <li><a href="#the-loss-function" id="toc-the-loss-function" class="nav-link" data-scroll-target="#the-loss-function">The loss function</a></li>
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training">Training</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In <a href="../ml-stat-mech-1">Lecture 1</a> we introduced the idea of Variational Inference (VI), which turns the problem of inference in latent variable models into one of optimization. That was a rather high-level view: in this lecture we are going to see in more detail how this works in practice in modern approaches that leverage neural networks and automatic differentiation. Specifically, we going to look at one class of versatile models, with many generalizations, called <strong>Variational Autoencoders</strong>.</p>
<p><span class="math display">\[
\DeclareMathOperator*{\E}{\mathbb{E}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bzeta}{\boldsymbol{\zeta}}
\]</span></p>
</section>
<section id="lecture-2-the-variational-autoencoder" class="level1">
<h1>Lecture 2: The Variational Autoencoder</h1>
<section id="vi-redux" class="level2">
<h2 class="anchored" data-anchor-id="vi-redux">VI redux</h2>
<p>Suppose we have a model defined by a prior <span class="math inline">\(p(z)\)</span> over latent variables and a generative model <span class="math inline">\(p_\phi(x|z)\)</span> for our data <span class="math inline">\(x\)</span> with parameters <span class="math inline">\(\phi\)</span>. We introduce a similar model for the posterior distribution of the latent variables <span class="math inline">\(q_\theta(z|x)\)</span>. This establishes two representations of the joint distribution of observed and latent variables. We’ll call the model expressed in terms of the generative model and the prior the <strong>forward</strong> model</p>
<p><span class="math display">\[
p_\text{F}(x,z)= p_\theta(x|z)p(z),
\]</span></p>
<p>and the model expressed in terms of the data distribution <span class="math inline">\(p_\text{D}(x)\)</span> and the posterior the <strong>backward</strong> model</p>
<p><span class="math display">\[
p_\text{B}(x,z)= q_\phi(z|x)p_\text{D}(x).
\]</span></p>
<p>The KL between these two models is</p>
<p><span class="math display">\[
D_\text{KL}(p_\text{B}||p_\text{F})= \E_{x\sim \text{Data}}\left[\E_{z\sim q_\phi(\cdot|x)}\left[\log\left(\frac{q_\phi(z|x)p_\text{D}(x)}{p_\theta(x|z)p(z)}\right)\right]\right]\geq 0.
\]</span></p>
<p>This inequality can be rearranged to</p>
<p><span class="math display">\[
H[p_\text{D}]\leq \E_{x\sim \text{Data}}\left[\E_{z\sim q_\phi(\cdot|x)}\left[\log\left(\frac{q_\phi(z|x)}{p_\theta(x|z)p(z)}\right)\right]\right].
\tag{1}
\label{eq:kl-loss}
\]</span></p>
<p>It doesn’t matter that we don’t have the explicit form of the data distribution <span class="math inline">\(p_\text{D}(x)\)</span>, because the right hand side only involves the expectation over this distribution (that’s why we chose this KL and not the reverse). This is implemented as an empirical average over (batches of) the data.</p>
<p>The right hand side of <span class="math inline">\(\eqref{eq:kl-loss}\)</span> is often presented as</p>
<p><span class="math display">\[
\E_{x\sim \text{Data}}\left[D_\text{KL}(q_\phi(\cdot|x)||p)-\E_{z\sim q_\phi(\cdot|x)}\left[\log p_\theta(x|z)\right]\right].
\]</span></p>
<p>The first term is small when the posterior matches the prior, while the second is small when the output of the generative model matches the data (the <strong>reconstruction error</strong>). Using <span class="math inline">\(\eqref{eq:kl-loss}\)</span> as a loss function for optimization therefore represents a trade-off between these two contributions.</p>
<p>There is considerable freedom in this formulation. Given a data distribution, we could change the forward and backward model, keeping <span class="math inline">\(p_\text{F}=p_\text{B}\)</span> but changing the prior <span class="math inline">\(p(z)\)</span>. Even after fixing the prior, the joint distribution <span class="math inline">\(p(x,z)\)</span> is not fixed, being determined by an unspecified <a href="https://en.wikipedia.org/wiki/Copula_(probability_theory)">Copula</a> between the two sets of variables. In practice, the parameterization of the forward and backward models, as well as the details of the optimization, will determine what you get. Additional terms are sometimes added to an objective function, particularly for overparameterized models like deep neural nets, to “encourage” certain behaviour in the parameters. This is called <strong>regularization</strong>.</p>
</section>
<section id="variational-autoencoder" class="level2">
<h2 class="anchored" data-anchor-id="variational-autoencoder">Variational autoencoder</h2>
<p><a href="https://arxiv.org/abs/1312.6114">Kingma and Welling</a> noticed that the above description fits neatly into an exisiting class of ML models called <a href="https://en.wikipedia.org/wiki/Autoencoder">Autoencoders</a>. In their original incarnation these are deterministic models that use neural nets (NNs) to map the original data <span class="math inline">\(x\)</span> to some lower dimensional representation in terms of some latent variables <span class="math inline">\(h\)</span> (this part is called the <strong>encoder</strong>), and then map <span class="math inline">\(h\)</span> to an output <span class="math inline">\(x'\)</span> of the same format as the original data (<strong>decoder</strong>).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/512px-Autoencoder_schema.png" class="img-fluid figure-img"></p>
<figcaption>Schematic view of an autoencoder. Source: <a href="https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Autoencoder_schema.png/512px-Autoencoder_schema.png%22">Wikipedia</a></figcaption>
</figure>
</div>
<p>An autoencoder is trained to return outputs close to the inputs. Because of the lower dimensional hidden layer, it cannot do this in a trivial way by learning the identity mapping in the data space. Instead, the idea is that if the data lives close to some lower dimensional manifold embedded in the high dimensional data space – an idea called the <strong>manifold hypothesis</strong> – the trained autoencoder can map this data manifold to the hidden layer.</p>
<p>To perform VI in the autoencoder framework – giving a <a href="https://en.wikipedia.org/wiki/Autoencoder#Variational_autoencoder_(VAE)">Variational Autoencoder</a> (VAE) – we need two things</p>
<ol type="1">
<li>A way to parameterize <span class="math inline">\(p_\theta(x|z)\)</span> and <span class="math inline">\(q_\phi(z|x)\)</span> using NNs.</li>
<li>A way to take gradients of the loss function <span class="math display">\[
\mathcal{L}(\theta,\phi)=\E_{x\sim \text{Data}}\left[D_\text{KL}(q_\phi(\cdot|x)||p)-\E_{z\sim q_\phi(\cdot|x)}\left[\log p_\theta(x|z)\right]\right]
\tag{2}
\label{eq:VAE-loss}
\]</span> to perform optimization.</li>
</ol>
<p>Let’s look at these in turn.</p>
<section id="parameterization" class="level3">
<h3 class="anchored" data-anchor-id="parameterization">Parameterization</h3>
<p>Suppose our latent variables are <span class="math inline">\(\bz\in \R^{H}\)</span> ( we switch to bold notation to emphasize that we are dealing with a vector of continuous variables). For the encoder <span class="math inline">\(q_\phi(\bz|\bx)\)</span>, it’s normal to choose the multivariate normal distribution <span class="math inline">\(\mathcal{N}(\bmu_\phi(\bx),\bSigma_\phi(\bx))\)</span> with mean <span class="math inline">\(\bmu_\phi(\bx)\in \R^{H}\)</span> and symmetric covariance matrix <span class="math inline">\(\bSigma(\bx)\in \R^{H\times H}\)</span> dependent on the input <span class="math inline">\(\bx\in \R^D\)</span>. If the prior is also normal – the choice <span class="math inline">\(\mathcal{N}(0,\mathbb{1})\)</span> is common – the KL term in <span class="math inline">\(\eqref{eq:VAE-loss}\)</span> can be evaluated explicitly in terms of <span class="math inline">\(\bmu_\phi(\bx)\)</span> and <span class="math inline">\(\bSigma_\phi(\bx)\)</span>.</p>
<p>In practice the covariance matrix <span class="math inline">\(\bSigma_\phi(\bx)\)</span> is usually chosen to be diagonal for simplicity. The functions <span class="math inline">\(\bmu_\phi(\bx)\)</span> and <span class="math inline">\(\bSigma_\phi(\bx)\)</span> are then parameterized using NNs, with an architecture that is adapted to the data. <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional neural networks</a> are widely used for images, for example.</p>
<p>If we make a similar model for the decoder <span class="math inline">\(p_\theta(\cdot|\bz)=\mathcal{N}(\bmu'_\theta(\bz),\bSigma'_\theta(\bz))\)</span>, then the second term of <span class="math inline">\(\eqref{eq:VAE-loss}\)</span> involves</p>
<p><span class="math display">\[
-\log p_\theta(\bx|\bz) = \frac{1}{2}(\bx-\bmu'_\theta(\bz))^T\bSigma'^{-1}_\theta(\bz)(\bx-\bmu'_\theta(\bz))+\frac{1}{2}\log\det\bSigma_\theta'(\bz)+\text{const.},
\]</span></p>
<p>which encourages the mean output <span class="math inline">\(\bmu'_\theta(\bz)\)</span> for <span class="math inline">\(\bz\sim q_\phi(\cdot|\bx)\)</span> to be close to the data point <span class="math inline">\(\bx\)</span> (reconstruction error).</p>
<p>The required expectation over <span class="math inline">\(\bz\)</span> cannot be taken in closed form, however, if we want to model a complex decoder function <span class="math inline">\(p_\theta\)</span>. It has to be done by Monte Carlo, but the expectation depends on parameters <span class="math inline">\(\phi\)</span>, and we want to take derivatives with respect to these parameters. What do we do?</p>
</section>
<section id="reparameterization-trick" class="level3">
<h3 class="anchored" data-anchor-id="reparameterization-trick">Reparameterization trick</h3>
<p>For continuous variables there is a nice solution, which you’d probably think of fairly quickly, though it has its own name: the <strong>reparameterization trick</strong>.</p>
<p>If you want to generate samples from <span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span> and you have at your disposal a random variable <span class="math inline">\(\zeta\sim\mathcal{N}(0,1)\)</span> then <span class="math inline">\(\sigma \zeta +\mu\)</span> does the job. The nice thing about this observation is that it separates the parameters from the sampling, so that a Monte Carlo estimate of an expectation</p>
<p><span class="math display">\[
\E_{x\sim \mathcal{N}(\mu,\sigma^2)}\left[f(x)\right]\approx \frac{1}{S}\sum_{s=1}^S f(\sigma z_s + \mu)
\]</span></p>
<p>is explicitly a function of <span class="math inline">\(\sigma\)</span> and <span class="math inline">\(\mu\)</span>, so that derivatives with respect to these parameters may be calculated. This generalizes straightforwardly to the multivariate Gaussian we use in the decoder as <span class="math inline">\(\bz\sim \bSigma_\phi^{1/2}(\bx)\bzeta+\mu_\phi(\bx)\)</span>. For other distributions the required functional mapping may become more complicated.</p>
<p>It’s clear that the reparameterization trick is limited to continuous variables. Monte Carlo gradient estimation for discrete variables is <a href="https://jmlr.csail.mit.edu/papers/v21/19-346.html">an active area of research</a>.</p>
</section>
<section id="more-practicalities" class="level3">
<h3 class="anchored" data-anchor-id="more-practicalities">More practicalities</h3>
<p>At this point we understand how to evaluate the loss function on a data point <span class="math inline">\(\bx\)</span> using Monte Carlo estimation for the encoder <span class="math inline">\(\bz\sim q_\phi(\cdot|\bx)\)</span>, in such a way that the estimate is differentiable. In practice a single <span class="math inline">\(\bz\)</span> sample is usually found to provide useful gradients for optimization. Large datasets are usually split into <strong>batches</strong> (sometimes called <strong>mini-batches</strong>, confusingly), so for a batch of size <span class="math inline">\(B\)</span> the loss function is estimated as</p>
<p><span class="math display">\[
\mathcal{L}(\theta,\phi)\approx\frac{1}{B}\sum_{b=1}^B\left[D_\text{KL}(q_\phi(\cdot|\bx_b)||p)-\log p_\theta(\bx_b|\bSigma_\phi^{1/2}(\bx_b)\bzeta_b+\mu_\phi(\bx_b))\right]\qquad \bzeta_b\sim \mathcal{N}(0,\mathbb{1})
\]</span></p>
<p>For optimization, gradients are calculated by automatic differentiation, implemented in all modern deep learning libraries. There’s a great deal of craft to this business, but that’s enough detail for now.</p>
</section>
<section id="interpretability" class="level3">
<h3 class="anchored" data-anchor-id="interpretability">Interpretability</h3>
<p>One of the promises of latent variable models like the VAE is that, as well as providing a good generative model for making new samples, or a way of assessing the likelihood of inputs, the latent space may be <strong>interpretable</strong>. That is, moving in a lower dimensional latent space <span class="math inline">\(\R^H\)</span> may allow us to explore the manifold on which the data is embedded in <span class="math inline">\(\R^D\)</span>. Developing models and training protocols that encourage this <strong>structure learning</strong> is an area of active research, but here are some of the issues:</p>
<ol type="1">
<li><p>Nothing about the loss function <span class="math inline">\(\eqref{eq:VAE-loss}\)</span> actually requires that the latent space is used <em>at all</em>. If the decoder model <span class="math inline">\(p_\theta(\bx|\bz)\)</span> is rich enough it’s possible that it approaches the data distribution for <em>any</em> <span class="math inline">\(\bz\)</span>: <span class="math inline">\(p_\theta(\bx|\bz)\approx p_\text{D}(\bx)\)</span>, meaning that by Bayes’ theorem the posterior is <span class="math display">\[
\frac{p_\theta(\bx|\bz)p(\bz)}{p_\text{D}(\bx)}\approx p(\bz),
\]</span> the same as the prior! This is known as <strong>posterior collapse</strong>. You may have a good generative model, but you don’t learn anything about your data.</p></li>
<li><p>Even if the latent space is used by the trained model, there’s no guarantee that it’s used <em>nicely</em>, with different latent variables corresponding to meaningfully different qualities of the data: colour, shape, position, etc.. This is called <strong>disentangling</strong>. Part of the problem is that the prior <span class="math inline">\(\mathcal{N}(0,\mathbb{1})\)</span> is rotationally invariant, so lifting this symmetry is necessary.</p></li>
</ol>
</section>
<section id="compression-with-vaes-bits-back" class="level3">
<h3 class="anchored" data-anchor-id="compression-with-vaes-bits-back">Compression with VAEs: bits back</h3>
<p>In <a href="../ml-stat-mech-1">Lecture 1</a> we discussed the entropy as a fundamental bound on the compression of data, and I suggested that good probabilistic models tailored to a particular kind of data would give better compression. How can we deliver on this promise for latent variable models like the VAE? The problem, as always, is that the model doesn’t supply an explicit expression for <span class="math inline">\(p_\text{M}(x)\)</span>: marginalizing over the latent variables is intractable.</p>
<p>There is a beautiful idea called <strong>bits back coding</strong> that is particularly well suited to the encoder-decoder formulation of latent variable models, and allows the unavailability of <span class="math inline">\(p_\text{M}(x)\)</span> to be circumvented. Recall that the loss function of the VAE is based on the inequality</p>
<p><span class="math display">\[
H[p_\text{D}]\leq \E_{x\sim \text{Data}}\left[\E_{z\sim q_\phi(\cdot|x)}\left[\log\left(\frac{q_\phi(z|x)}{p_\theta(x|z)p(z)}\right)\right]\right].
\]</span></p>
<p>Let’s split the right hand side up into three terms</p>
<p><span class="math display">\[
\E_{x\sim \text{Data}}\left[\E_{z\sim q_\phi(\cdot|x)}\left[\log\left(q_\phi(z|x)\right)-\log\left(p_\theta(x|z)\right)-\log\left(p(z)\right)\right]\right].
\tag{3}
\label{eq:loss-3-terms}
\]</span></p>
<p>Recall that <span class="math inline">\(-\log_2 p(x)\)</span> is the length in bits of the optimal encoding of <span class="math inline">\(x\)</span>. The last two terms could be interpreted as follows</p>
<ol type="1">
<li>Given data <span class="math inline">\(x\)</span> we sample <span class="math inline">\(z\sim q_\phi(\cdot|x)\)</span>.</li>
<li>We encode <span class="math inline">\(x\)</span> using the distribution <span class="math inline">\(p_\theta(\cdot|z)\)</span>, then</li>
<li>Encode <span class="math inline">\(z\)</span> using the prior <span class="math inline">\(p(\cdot)\)</span>.</li>
</ol>
<p>When it comes to decoding, we go in reverse: decoding <span class="math inline">\(z\)</span> using the prior and then <span class="math inline">\(x\)</span> using <span class="math inline">\(p_\theta(\cdot|z)\)</span>. We’ll never reach the Shannon bound this way, however, because of the negative first term in <span class="math inline">\(\eqref{eq:loss-3-terms}\)</span>. We need to make the code <em>shorter</em>. How? At this point we need to remember that the idea of entropy as a lower bound applies in the limit of <span class="math inline">\(N\to\infty\)</span> iid data. Imagine a semi-infinite bit stream that we are mid-way through encoding. Here’s the big idea: we decode part of already encoded bitstream using the model <span class="math inline">\(q_\phi(\cdot|x)\)</span>. The result is a <span class="math inline">\(z\sim q_\phi(\cdot|x)\)</span> which we then use for encoding <span class="math inline">\(x\)</span> as described above. These are the <strong>bits back</strong>: we will remove <span class="math inline">\(H(q_\phi(\cdot|x))\)</span> bits on average, which allows us to reach the Shannon bound (in reality the separate encoding and decoding stages are not perfect). When decoding data, the last thing we do for each <span class="math inline">\(x\)</span> is encode <span class="math inline">\(z\)</span> back to the bitstream using <span class="math inline">\(q_\phi(\cdot|x)\)</span></p>
<p>I’m of course skipping over many issues to do with the implementation, including quantizing the data of a continuous VAE, and the fact that the stack-like nature of the encoder had to await the development of <a href="https://en.wikipedia.org/wiki/Asymmetric_numeral_systems">asymmetric numeral systems</a> to become practical. See the <a href="https://arxiv.org/abs/1901.04866">original paper</a> for more details.</p>
</section>
</section>
<section id="related-models" class="level2">
<h2 class="anchored" data-anchor-id="related-models">Related Models</h2>
<p>The VAE framework is quite general, and in recent years has been elaborated in various ways.</p>
<section id="markov-model-autoencoders" class="level3">
<h3 class="anchored" data-anchor-id="markov-model-autoencoders">Markov Model autoencoders</h3>
<p>So our encoder and decoder were just Gaussian models, albeit with a potentially complicated dependence of the mean and covariance. Can we produce a model with a richer distribution? One straightforward way is to make the forward and backward models Markov processes with <span class="math inline">\(T\)</span> steps, with latent variables <span class="math inline">\(z_0,\ldots z_{T-1}\)</span>. It’s easier to write if we identify <span class="math inline">\(x=z_T\)</span>, so that</p>
<p><span class="math display">\[
p_\text{F}(z_0,\ldots x=z_T) = p_\theta(x=z_T|z_{T-1})p_\theta(z_{T-1}|z_{T-2})\cdots p_\theta(z_1|z_{0})p(z_0)
\]</span></p>
<p><span class="math display">\[
p_\text{B}(z_0,\ldots \ldots x=z_T) = q_\phi(z_0|z_{1})\cdots q_\phi(z_{T-2}|z_{T-1})q_\phi(z_{T-1}|z_T)p_\text{D}(x=z_T)
\]</span></p>
<p>(We could have different kernels at each time step, and different dimensionalities, but I’m suppressing this for now). The loss function comes from a straightforward generalization of <span class="math inline">\(\eqref{eq:kl-loss}\)</span></p>
<p><span class="math display">\[
H[p_\text{D}]\leq \E_{z\sim p_\text{B}}\left[\log \left(\frac{q_\phi(z_0|z_1)}{p(z_0)}\right)+\sum_{t=0}^{T-2}\log\left(\frac{q_\phi(z_{t+1}|z_{t+2})}{p_\theta(z_{t+1}|z_t)}\right)\right].
\]</span></p>
<p>This loss is an expectation (with respect to the backward model) of the log-likelihood ratio of the forward and backward Markov processes. Note that this model has a large amount of “gauge” freedom: the intermediate dynamics is completely unspecified by the loss function so will be determined by the details of the parameterization and optimization.</p>
<!-- h transform -->
<p>We can even imagine passing to the <em>continuous time limit</em>, in which case <span class="math inline">\(z_t\)</span> becomes a continuous time stochastic process described by a stochastic differential equation (SDE).</p>
<p><span class="math display">\[
dz_t = \mu_\theta(z_t)dt + dW_t
\]</span></p>
<p>where <span class="math inline">\(W_t\)</span> denotes a <span class="math inline">\(\R^H\)</span> dimensional Brownian motion. and <span class="math inline">\(\mu_\theta(z_t)\)</span> is a parameterized drift (it could have an explicit time dependence too). More precisely, there are <em>two</em> SDEs, one describing the forward process and one the backward, each with their own drift (for technical reasons the volatilities of the two processes have to match, which is why they’ve been set to one here). In the continuum limit the KL involves the log of the <a href="https://en.wikipedia.org/wiki/Radon%E2%80%93Nikodym_theorem">Radon–Nikodym derivative</a>.</p>
<p>A nice feature of the SDE formulation is that the model is separated from the implementation of the dynamics. You can solve the SDE by whatever method you like: as long as you can differentiate the solution with respect to the parameters it can be plugged into the loss and optimized.</p>
<p>One possible application of this kind of model is to infer the trajectories that led to some measured outcomes in stochastic dynamics. If the forward model is fixed and describes a simulation of a physical system – for example a molecular dynamics simulation of a biomolecule – the backward model can be used to infer the trajectories that led up to some measured states <span class="math inline">\(z_T\)</span>.</p>
<p>Alternatively, one can fix the backward model and just learn the forward model. This seems a bit strange from our original point of view of finding the posterior, but one can obtain perfectly good generative models this way. See <a href="https://arxiv.org/abs/2006.11239">Denoising Diffusion Probabilistic Models</a> for a recent example.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/diffusion-model.png" class="img-fluid figure-img"></p>
<figcaption>(Top) Model architecture and (Bottom) generated samples from <a href="https://arxiv.org/abs/2006.11239">Denoising Diffusion Probabilistic Models</a>.</figcaption>
</figure>
</div>
</section>
<section id="normalizing-flows" class="level3">
<h3 class="anchored" data-anchor-id="normalizing-flows">Normalizing flows</h3>
<p>Autoencoders were originally conceived to learn a low dimensional latent representation of the data. By taking the latent space and the data space to be identical <span class="math inline">\(\R^H=\R^D\)</span>, however, we can make contact with another kind of model called a <a href="http://proceedings.mlr.press/v37/rezende15.html">Normalizing Flow</a>. In this setting, let’s take the covariances of the Gaussian models for the encoder (<span class="math inline">\(\bSigma_\phi\)</span>) and decoder (<span class="math inline">\(\bSigma'_\theta\)</span>) to zero, so that <span class="math inline">\(q_\phi(\bz|\bx)\)</span> and <span class="math inline">\(p_\theta(\bx|\bz)\)</span> become deterministic maps given by</p>
<p><span class="math display">\[
\bz = \mu_\phi(\bx),\qquad \bx = \mu'_\theta(\bz).
\tag{4}
\label{eq:bij}
\]</span></p>
<p>The only way for the KL to be nonzero in this limit is if these maps are inverses of each other. What value does the KL take in this case? The multivariate Gaussian distribution for the encoder is</p>
<p><span class="math display">\[
q_\phi(\cdot|\bx) = \frac{1}{\sqrt{(2\pi)^{D} \det\bSigma_\phi(\bx)}} \exp\left[-\frac{1}{2}(\bz-\bmu_\phi(\bx))^T\bSigma^{-1}_\phi(\bx)(\bz-\bmu_\phi(\bx))\right],
\]</span></p>
<p>with a similar expression for the decoder. The KL involves the ratio</p>
<p><span class="math display">\[
\frac{q_\phi(\bz|\bx)}{p_\theta(\bx|\bz)}
\]</span></p>
<p>which, when <span class="math inline">\(\bz\)</span> and <span class="math inline">\(\bx\)</span> are related by <span class="math inline">\(\eqref{eq:bij}\)</span>, takes on the value</p>
<p><span class="math display">\[
\frac{q_\phi(\bz|\bx)}{p_\theta(\bx|\bz)}\longrightarrow \sqrt{\frac{\det\bSigma'_\theta(\bz)}{\det\bSigma_\phi(\bx)}}=\det \left(\frac{\partial\bx}{\partial\bz}\right).
\]</span></p>
<p>The appearance of the Jacobian is more easily understood starting from first principles. If <span class="math inline">\(\bz\)</span> is described by a probability density <span class="math inline">\(p(\bz)\)</span> then <span class="math inline">\(\bx=\mu'_\theta(\bz)\)</span> has density</p>
<p><span class="math display">\[
\det\left(\frac{\partial\bz}{\partial\bx}\right) p(\mu_\phi(\bx)).
\]</span></p>
<p>In words: to evaluate the probability density at <span class="math inline">\(\bx\)</span> we map to <span class="math inline">\(\bz\)</span> and evaluate the density there, accounting for the Jacobian of the transformation.</p>
<p>In the deterministic limit, the KL becomes</p>
<p><span class="math display">\[
D_\text{KL}(p_\text{B}||p_\text{F})\longrightarrow -\E_{x\sim \text{Data}}\left[\log\det \left(\frac{\partial\bz}{\partial\bx}\right)+\log p(\mu_\phi(\bx))\right].
\]</span></p>
<p>Conceptually, normalizing flows are perhaps a bit simpler than VAEs. The challenge in implementing this scheme is constructing flexible, invertible models with tractable Jacobians (since computing the determinant is <span class="math inline">\(O(D^3)\)</span> and has to be done for every data point). In practice this is done by stacking together simpler transformations, each of which is invertible with known Jacobian.</p>
</section>
</section>
<section id="learning-the-path-integral" class="level2">
<h2 class="anchored" data-anchor-id="learning-the-path-integral">Learning the path integral</h2>
<p>Finally, we’ll look at an application of these methods from <a href="http://proceedings.mlr.press/v107/barr20a.html">Barr, Gispen, Lamacraft (2020)</a> that is squarely in the domain of physics: finding the ground states of quantum systems.</p>
<section id="the-feynmankac-formula" class="level3">
<h3 class="anchored" data-anchor-id="the-feynmankac-formula">The Feynman–Kac formula</h3>
<p>One of the many connections between quantum mechanics and stochastic processes is provided by the <a href="https://en.wikipedia.org/wiki/Feynman%E2%80%93Kac_formula">Feynman–Kac formula</a> (FK), which is a fully rigorous path integral formula exists for the heat-type equations</p>
<p><span class="math display">\[
  \frac{\partial\psi(\br,t)}{\partial t} = -\left[H\psi\right](\br,t),
  \tag{5}
  \label{eq:im-time}
\]</span></p>
<p>also known as the imaginary time Schrödinger equation. The FK formula expresses the solution as an expectation over Brownian paths</p>
<p><span class="math display">\[
  \psi(\br_2,t_2) =  \E_{\br(t_2)=\br_2}\left[\exp\left(-\int_{t_1}^{t_2}V(\br(t))dt\right)\psi(\br(t_1),t_1)\right],
\]</span></p>
<p>where the paths must finish at <span class="math inline">\(\br_2\)</span> at time <span class="math inline">\(t_2\)</span>. If you’ve seen the path integral before and are asking yourself what happened to the term in the exponent that derives from the kinetic energy: <em>that’s</em> what describes the distribution over Brownian paths.</p>
<p>In this way quantum mechanics is brought into the realm of stochastic processes, albeit in “imaginary time”. Whilst this formulation is therefore not of direct utility in studying quantum dynamics, it provides a very useful tool for studying <em>ground states</em>. This is because the propagator <span class="math inline">\(K(\br_2,t_2;\br_1,t_1)\)</span> for <span class="math inline">\(\eqref{eq:im-time}\)</span> has a spectral representation in terms of the eigenfunctions <span class="math inline">\(\varphi_n\)</span> and eigenenergies <span class="math inline">\(E_n\)</span> of the time independent Schrödinger equation <span class="math inline">\(H\varphi_n = E_n\varphi_n\)</span> as</p>
<p><span class="math display">\[
K(\br_2,t_2;\br_1,t_1) = \sum_n \varphi_n(\br_2)\varphi^*_n(\br_1)e^{-E_n(t_2-t_1)}.
\]</span></p>
<p>Thus, as <span class="math inline">\(t_2-t_1\to\infty\)</span>, only the ground state contributes.</p>
<p><span class="math display">\[
K(\br_2,t_2;\br_1,t_1)\longrightarrow \varphi_0(\br_2)\varphi^*_0(\br_1)e^{-E_0(t_2-t_1)} \qquad \text{ as } t_2-t_1\to\infty.
\]</span></p>
<p>The FK formula defines a new path measure <span class="math inline">\(\mathbb{P}_\text{FK}\)</span> that differs from the Brownian measure <span class="math inline">\(\mathbb{P}_0\)</span> by the Radon–Nikodym derivative</p>
<p><span class="math display">\[
\frac{d\mathbb{P}_{\text{FK}}}{d\mathbb{P}_{0}} = \mathcal{N}\exp\left(-\int_{t_1}^{t_2}V(\br(t))dt\right)
\tag{6}
\label{eq:RN}
\]</span></p>
<p>where <span class="math inline">\(\mathcal{N}\)</span> is a normalization factor. Think of <span class="math inline">\(\eqref{eq:RN}\)</span> as a Boltzmann factor that describes paths that spend more time in the attractive regions of the potential (<span class="math inline">\(V(\br)&lt;0\)</span>) and less time in the repulsive regions (<span class="math inline">\(V(\br)&gt;0\)</span>).</p>
<p>As <span class="math inline">\(T\equiv t_2-t_1\to\infty\)</span>, the distribution of <span class="math inline">\(\br(0)\)</span> under this measure coincides with the ground state probability distribution <span class="math inline">\(|\varphi_0(\br)|^2\)</span> from the Born rule. To see that this is the case, consider a path that passes through <span class="math inline">\((\br_-,-T/2)\)</span>, <span class="math inline">\((\br,0)\)</span> and <span class="math inline">\((\br_+,T/2)\)</span> for some arbitrary initial and final point <span class="math inline">\(\br_\pm\)</span>. The overall propagator is then</p>
<p><span class="math display">\[
  K(\br_+,T/2;\br,0)K(\br,0;\br_-,-T/2;)\sim  |\varphi_0(\br)|^2\varphi_0(\br_+)\varphi^*_0(\br_-)e^{-E_0T}.
\]</span></p>
<p>Apart from a normalization factor that depends on <span class="math inline">\(\br_\pm\)</span> and <span class="math inline">\(T\)</span>, this is just the expected ground state distribution <span class="math inline">\(|\varphi_0(\br)|^2\)</span>. Thus, the ability to sample from the FK measure for long trajectories would also allow us to sample from the ground state distribution. One technique for doing this is <a href="https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.67.279">Path integral Monte Carlo</a>, which performs Monte Carlo sampling the space of Feynman trajectories.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="assets/ceperley.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption>Source: <a href="https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.67.279">Ceperley (1995)</a>.</figcaption>
</figure>
</div>
</section>
<section id="the-loss-function" class="level3">
<h3 class="anchored" data-anchor-id="the-loss-function">The loss function</h3>
<p>A different way to turn the above connection into a calculational tool, is to use the fact that the path measure defined by the FK formula is <strong>Markovian</strong>, meaning that the trajectories are solutions of the SDE</p>
<p><span class="math display">\[
d\br_t = d\mathbf{B}_t + \bv(\br_t,t)dt
\]</span></p>
<p>for some drift function <span class="math inline">\(\bv(\br_t,t)\)</span>. In fact for <span class="math inline">\(T\to\infty\)</span> the drift is time independent and related to the ground state wavefunction <span class="math inline">\(\varphi_0(\br)\)</span> by <span class="math inline">\(\bv(\br)=\nabla\varphi_0(\br)\)</span>.</p>
<p>Now, we don’t know the ground state wavefunction, but we can turn this observation into a variational principle by introducing a (NN) parameterized drift <span class="math inline">\(\bv_\theta(\br) = \textsf{NN}_\theta(\br)\)</span> and attempting to minimize the KL between the measure defined by this drift and the FK measure. The log likelihood ratio (log Radon–Nikodym derivative) of the two measures obeys</p>
<p><span class="math display">\[
  \log\left(\frac{d\mathbb{P}_{\bv}}{d\mathbb{P}_\text{FK}}\right) =\ell_T - E_0 T+\log\left(\frac{\varphi_0(\br_0)}{\varphi_0(\br_T)}\right)
\]</span></p>
<p><span class="math display">\[
   \ell_T\equiv \int \bv(\br_t)
  \cdot d\vec{B}_t+\int dt\left(\frac{1}{2}|\bv(\br_t)|^2+V(\br_t)\right).
\]</span></p>
<p>The KL of the two measures is then obtained by taking the expectation over trajectories of the SDE</p>
<p><span class="math display">\[
    D_{\text{KL}}\left(\mathbb{P}_{\bv} \middle\| \mathbb{P}_\text{FK}\right)=\E_{\mathbb{P}_{\bv}}\left[\ell_T-E_0 T+\log\left(\frac{\varphi_0(\br_0)}{\varphi_0(\br_T)}\right)\right].
    \tag{7}
    \label{eq:full-KL}
\]</span></p>
<p>(as usual, we choose this KL rather than the reverse because it’s the one we can evaluate) Note that <span class="math inline">\(\eqref{eq:full-KL}\)</span> is true for any <span class="math inline">\(\br_0\)</span>. If we additionally average over <span class="math inline">\(\br_0\)</span> drawn from the stationary distribution of the SDE, then the distributions of <span class="math inline">\(\br_T\)</span> and <span class="math inline">\(\br_0\)</span> coincide, and the final term vanishes. Because the KL divergence is positive <span class="math inline">\(D_{\text{KL}}\left(\mathbb{P}_{\bv} \middle\| \mathbb{P}_\text{FK}\right)\geq 0\)</span> we then have <span class="math inline">\(\E_{\mathbb{P}_{\bv}}\left[\ell_T\right]\geq E_0 T\)</span>, with equality when the two measures match. This is the variational principle that forms the basis of our approach. For <span class="math inline">\(T\to\infty\)</span> we can ignore the final term so that</p>
<p><span class="math display">\[
    \lim_{T\to\infty} \frac{\E_{\mathbb{P}_{\bv}}\left[\ell_T\right]}{T}\geq E_0,
\]</span></p>
<p>irrespective of the initial state distribution (as <span class="math inline">\(T\to\infty\)</span> the final state distribution will be the stationary state of the SDE, assuming ergodicity).</p>
</section>
<section id="training" class="level3">
<h3 class="anchored" data-anchor-id="training">Training</h3>
<p>For details of how the model is parameterized and trained see <a href="http://proceedings.mlr.press/v107/barr20a.html">our paper</a>.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>