[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hello",
    "section": "",
    "text": "I’m a Professor of Theoretical Physics at the University of Cambridge"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Hello",
    "section": "Experience",
    "text": "Experience\n\nOct 2007 – Sep 2012: Assistant → Associate Professor. University of Virginia\nOct 2005 – Sep 2007: Postdoctoral Fellow. All Souls College, University of Oxford\nOct 2002 – Sep 2005: Dicke Fellow. Princeton University, Department of Physics\nOct 2001 – Sep 2002: Junior Research Fellow. Trinity College, University of Cambridge"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Hello",
    "section": "Education",
    "text": "Education\n\nPhD in Theoretical Physics, 2002. University of Cambridge\nMaster of Mathematics, 1998. University of Cambridge\nMA in Natural Sciences, 1997. University of Cambridge"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html",
    "href": "talks/superdiffusion-spin-chains/index.html",
    "title": "Austen Lamacraft",
    "section": "",
    "text": "\\[\n\\nonumber\n\\newcommand{\\bra}[1]{\\langle{#1}\\rvert}\n\\newcommand{\\ket}[1]{\\lvert{#1}\\rangle}\n\\newcommand{\\br}{\\mathbf{r}}\n\\newcommand{\\bR}{\\mathbf{R}}\n\\newcommand{\\bp}{\\mathbf{p}}\n\\newcommand{\\bk}{\\mathbf{k}}\n\\newcommand{\\bq}{\\mathbf{q}}\n\\newcommand{\\bv}{\\mathbf{v}}\n\\newcommand{\\bx}{\\mathbf{x}}\n\\newcommand{\\bz}{\\mathbf{z}}\n\\DeclareMathOperator*{\\E}{\\mathbb{E}}\n\\]"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html#superdiffusion-in-spin-chains",
    "href": "talks/superdiffusion-spin-chains/index.html#superdiffusion-in-spin-chains",
    "title": "Austen Lamacraft",
    "section": "Superdiffusion in spin chains",
    "text": "Superdiffusion in spin chains\nReview: arXiv:2103.01976 Bulchandani, Gopalakrishnan, Ilievski\n\nWhat?\nWhere?\nHow?"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html#diffusion",
    "href": "talks/superdiffusion-spin-chains/index.html#diffusion",
    "title": "Austen Lamacraft",
    "section": "Diffusion",
    "text": "Diffusion\n\\[\n\\frac{\\partial u}{\\partial t} = D \\frac{\\partial^2 u}{\\partial x^2}\n\\] - Fundamental solution of heat equation \\[\nu(x,t) = \\frac{1}{\\sqrt{4\\pi Dt}}\\exp\\left[-\\frac{(x-x_0)^2}{4Dt}\\right]\n\\] - More generally have scaling solutions \\(u(x,t)\\to \\frac{1}{\\sqrt{t}}f\\left(\\frac{x-x_0}{\\sqrt{Dt}}\\right)\\) - Dynamical critical exponent \\(x\\sim t^{1/z}\\) with \\(z=2\\) - \\(u(x,t)\\) is conserved: \\(\\int u(x,t) dx=\\text{const.}\\)"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html#spin-diffusion",
    "href": "talks/superdiffusion-spin-chains/index.html#spin-diffusion",
    "title": "Austen Lamacraft",
    "section": "Spin diffusion",
    "text": "Spin diffusion\n\nRelaxation of inhomogeneity (e.g. domain wall)\n\n\n\n\n\nSpin correlations \\(\\langle Z(x,t)Z(x',t')\\rangle\\) as measured in neutron diffraction (say)"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html#models",
    "href": "talks/superdiffusion-spin-chains/index.html#models",
    "title": "Austen Lamacraft",
    "section": "Models",
    "text": "Models\n\nHeisenberg spin-1/2 chain \\[\nH = \\sum_j \\left[X_j X_{j+1}+Y_j Y_{j+1}+ \\Delta Z_j Z_{j+1}\\right]\n\\]\n\\(\\Delta=1\\) is isotropic (XXX model). All 3 components conserved\n\\(\\Delta\\neq 1\\): Only \\(Z\\) conserved\n(Naive) expectation: \\(Z\\) diffuses. In fact: something’s up at \\(\\Delta=1\\)!"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html#numerics-steady-state",
    "href": "talks/superdiffusion-spin-chains/index.html#numerics-steady-state",
    "title": "Austen Lamacraft",
    "section": "Numerics: steady state",
    "text": "Numerics: steady state\n\nŽnidarič (2011) tDMRG with ends coupled to reservoirs with fixed chemical potentials\n\n\n\n\n\nSteady state current \\(j\\sim L^{-1/2}\\). \\(j= D\\frac{\\partial s}{\\partial x}\\) suggests \\(D\\sim L^{1/2}\\)\n\\(\\omega = Dk^2\\) implies \\(\\omega\\sim k^{3/2}\\) or \\(z=3/2\\). Superdiffusion"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html#numerics-relaxation",
    "href": "talks/superdiffusion-spin-chains/index.html#numerics-relaxation",
    "title": "Austen Lamacraft",
    "section": "Numerics: relaxation",
    "text": "Numerics: relaxation\n\nLjubotina, Žnidarič, Prosen (2017) studied weak domain wall initial conditions\n\n\n\n\n\nAgain, superdiffusion with \\(z=3/2\\)\nIn 2019, same authors improved accuracy and identified scaling behaviour with KPZ universality class (more later)"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html#numerics-classical",
    "href": "talks/superdiffusion-spin-chains/index.html#numerics-classical",
    "title": "Austen Lamacraft",
    "section": "Numerics: classical",
    "text": "Numerics: classical\n\nKrajnik and Prosen (2020) introduced classical circuit\n\n\n\n\n\\[\n\\begin{align}\n\\Phi_\\tau(\\mathbf{S}_1,\\mathbf{S}_2) = \\frac{1}{\\sigma^2+\\tau^2}&\\left[\\sigma^2 \\mathbf{S}_1+\\tau^2 \\mathbf{S}_2 + \\tau \\mathbf{S}_1\\times \\mathbf{S}_2,\\\\\\\\\n\\sigma^2 \\mathbf{S}_2+\\tau^2 \\mathbf{S}_1 + \\tau \\mathbf{S}_2\\times \\mathbf{S}_1\\right]\n\\end{align}\n\\]\n\n\\(\\sigma^2=\\frac{1}{2}\\left(1+\\mathbf{S}_1\\cdot \\mathbf{S}_2\\right)\\)"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html#features-in-common",
    "href": "talks/superdiffusion-spin-chains/index.html#features-in-common",
    "title": "Austen Lamacraft",
    "section": "Features in common?",
    "text": "Features in common?\n\nNon-abelian symmetry e.g. \\(SU(2)\\) not \\(U(1)\\)\nIntegrability (extensive number of conservation laws)"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html#experiment",
    "href": "talks/superdiffusion-spin-chains/index.html#experiment",
    "title": "Austen Lamacraft",
    "section": "Experiment",
    "text": "Experiment\n\nScheie et al observe KPZ scaling in 1D Heisenberg antiferromagnet KCuF3 with neutron scattering"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html#kpz-equation",
    "href": "talks/superdiffusion-spin-chains/index.html#kpz-equation",
    "title": "Austen Lamacraft",
    "section": "KPZ equation",
    "text": "KPZ equation\n\\[\n\\partial_t h = \\partial_x^2 h + \\frac{\\lambda}{2}(\\partial_x h)^2 + \\overbrace{\\xi(x,t)}^{\\text{noise}}\n\\]"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html#origin-of-z32",
    "href": "talks/superdiffusion-spin-chains/index.html#origin-of-z32",
    "title": "Austen Lamacraft",
    "section": "Origin of \\(z=3/2\\)",
    "text": "Origin of \\(z=3/2\\)\n\nKPZ is related to Burgers equation via \\(v=-\\partial_x h\\) (set \\(\\lambda=1\\)) \\[\n\\partial_t v + v\\partial_x v = \\partial_x^2 h + \\partial_x\\xi(x,t)\n\\]\nScale \\(x\\to \\lambda x\\), \\(t\\to \\lambda^z t\\)\nPreserves Galilean invariance: \\(\\partial_t v+v\\partial_x v\\) preserved\nSteady state \\(v\\) is white noise (\\(h\\) is Brownian): \\(v\\to \\lambda^{-1/2}v\\)\nMust have \\(z=1+\\frac{1}{2}=\\frac{3}{2}\\) (Forster, Nelson, and Stephen (1977))\nMuch recent progress on scaling functions in 1+1 dimensions"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html#why-kpz",
    "href": "talks/superdiffusion-spin-chains/index.html#why-kpz",
    "title": "Austen Lamacraft",
    "section": "Why KPZ?",
    "text": "Why KPZ?\n\nBulchandani (2020) suggests following (classical) picture\nLandau–Lifshitz equation for magnetization density \\(\\mathbf{s}(x,t)\\) \\[\n\\partial_t\\mathbf{s} = \\mathbf{s}\\times \\partial_x^2\\mathbf{s}\n\\]\nRegard \\(\\mathbf{s}(x)=\\mathbf{T}(x)\\) as tangent vector of space curve, with \\(x\\) as arc length\n\n\n\n\n\n\\[\n\\begin{align}\n\\frac{d\\mathbf{T}}{ds}=\\kappa\\mathbf{N},\\qquad {\\frac {d\\mathbf {B} }{ds}}=-\\tau \\mathbf {N}\\\\\n{\\frac {d\\mathbf {N} }{ds}}=-\\kappa \\mathbf {T} +\\tau \\mathbf {B} ,\\\\\n\\end{align}\n\\]\n\n\nWith \\(\\mathcal{E}\\equiv \\kappa^2/2\\) LLE takes form (dropping higher derivative terms)\n\n\\[\n\\begin{align}\n\\partial_t \\mathcal{E} +2\\partial_x\\left(\\mathcal{E}\\tau\\right)&=0\\\\\\\\\n\\partial_t \\tau +\\partial_x\\left(\\tau^2-\\mathcal{E}\\right)&=0\n\\end{align}\n\\]\n\nLinear instability!\nIf we can set \\(\\mathcal{E}=0\\) at long scales and coarse graining introduces noise and damping, then\n\n\\[\n\\partial_t \\tau +\\partial_x\\left(\\tau^2-D\\partial_x\\tau+\\xi(x,t\\right)=0\n\\]\n\nNoisy Burgers, hence KPZ"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html#whats-missing",
    "href": "talks/superdiffusion-spin-chains/index.html#whats-missing",
    "title": "Austen Lamacraft",
    "section": "What’s missing?",
    "text": "What’s missing?\n\nA straight-through calculation starting from a microscopic model"
  },
  {
    "objectID": "talks/superdiffusion-spin-chains/index.html#a-model-with-a-small-parameter",
    "href": "talks/superdiffusion-spin-chains/index.html#a-model-with-a-small-parameter",
    "title": "Austen Lamacraft",
    "section": "A model with a small parameter",
    "text": "A model with a small parameter\n\nFluctuating exchange interaction \\[\nd\\ket{\\psi} = \\sum_j \\left[-i(J dt + dW_j)P_{j,j+1}-\\frac{1}{2}dt\\right]\\ket{\\psi}.\n\\] (last term is there to ensure that the norm is preserved)\nHeisenberg equation of motion \\[\nd\\mathcal{O} = \\sum_j i\\left[\\left(J dt + dW_j\\right)P_{j,j+1},\\mathcal{O}\\right]+dt\\left(P_{j,j+1}\\mathcal{O}P_{j,j+1}-\\mathcal{O}\\right).\n\\]\n\n\n\n\\(\\bar{\\mathcal{O}}\\equiv\\E \\mathcal{O}\\) obeys Lindblad equation\n\n\\[\n\\begin{equation}\n\\frac{d\\bar{\\mathcal{O}}}{dt} = \\sum_j iJ \\left[P_{j,j+1},\\bar{\\mathcal{O}}\\right]+\\left(P_{j,j+1}\\bar{\\mathcal{O}}P_{j,j+1}-\\bar{\\mathcal{O}}\\right)\n\\end{equation}\n\\]\n\nExpand in components\n\n$$ \\mathcal{O}= \\sum_{\\mu_{1:N}=\\{0,1,2,3\\}^N} \\mathcal{C}^a_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots \\sigma_N^{\\mu_N}, $$ $$ \\partial_t \\mathcal{C}_{\\mu_{1:N}} = \\sum_j \\left[J\\sum_{\\alpha\\beta} \\epsilon_{\\alpha\\beta \\mu_j \\mu_{j+1}} \\mathcal{C}_{\\mu_1\\cdots \\alpha\\beta \\cdots \\mu_N} + \\mathcal{C}_{\\mu_1\\cdots \\mu_{j+1}\\mu_j \\cdots \\mu_N} - \\mathcal{C}_{\\mu_1\\cdots \\mu_{j}\\mu_{j+1} \\cdots \\mu_N}\\right] $$\n\n$$ \\partial_t \\mathcal{C}_{\\mu_{1:N}} = \\sum_j \\left[J\\sum_{\\alpha\\beta} \\epsilon_{\\alpha\\beta \\mu_j \\mu_{j+1}} \\mathcal{C}_{\\mu_1\\cdots \\alpha\\beta \\cdots \\mu_N} + \\mathcal{C}_{\\mu_1\\cdots \\mu_{j+1}\\mu_j \\cdots \\mu_N} - \\mathcal{C}_{\\mu_1\\cdots \\mu_{j}\\mu_{j+1} \\cdots \\mu_N}\\right] $$\n\n\\(J=0\\) describes operator diffusion\n\\(J\\neq 0\\) describes splitting and merging e.g. \\(Z_j\\leftrightarrow X_jY_{j+1}\\)"
  },
  {
    "objectID": "talks/new-rules-ictp/notebooks/clifford_brickwork.html",
    "href": "talks/new-rules-ictp/notebooks/clifford_brickwork.html",
    "title": "Austen Lamacraft",
    "section": "",
    "text": "Simulate brickwork Clifford cellular automata\n\n#Load necessary packages\n%matplotlib inline\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\n\n#Parameters for matplotlib\nfig_size = [6.9185, 3.4207]\nparams = {'backend': 'ps',\n      'axes.labelsize': 18,\n      'font.size': 16,\n      'legend.fontsize': 12,\n      'axes.titlesize' : 16,\n      'xtick.labelsize': 14,\n      'ytick.labelsize': 14,\n      'xtick.direction': 'in',\n      'ytick.direction': 'in',\n      'xtick.top' : True,\n      'ytick.right' : True,\n      'legend.frameon' : False,\n      'axes.linewidth' : 1.,\n      'lines.linewidth' : 1.3,\n      'figure.figsize': fig_size}\n      \nplt.rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\nplt.rc('text', usetex=True)\nplt.style.use('seaborn-dark-palette')\nplt.rcParams.update(params)\n\n/var/folders/xs/y8sn45v943s2_62flnxw0p940000gn/T/ipykernel_77959/4135101326.py:21: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-&lt;style&gt;'. Alternatively, directly use the seaborn API instead.\n  plt.style.use('seaborn-dark-palette')\n\n\n\n#Set printing precision\nnp.set_printoptions(precision=4)\n\n#Cast tensors to matrices\ndef tensor_to_matrix(tensor):\n    #Given tensor T_abcd...efgh... returns matrix M_{abcd..., efgh...}\n    num_row_indices = len(tensor.shape) // 2\n    q = tensor.shape[0]\n    return tensor.reshape(2 * [q ** num_row_indices])\n\nSection VC of Sommers tells us how to translate the gates to their action on Paulis. We have the iSWAP in Eq. (19), \\(\\pi/2\\) rotation about the \\(X\\) axis in (21a), and \\(-2\\pi/3\\) rotation about \\((1,1,1)\\) in (23b).\n\ndef iSWAP(a, b):\n    # a and b are tuples of length 2\n    # This is the iSWAP update\n    a1, a2 = a\n    b1, b2 = b\n    b1, b2 = b2, b1\n    a1, a2 = a2 + b1 + b2, a1 + b1 + b2\n    a1 = a1 % 2\n    a2 = a2 % 2\n    b1 = b1 % 2\n    b2 = b2 % 2\n    return (a1, a2), (b1, b2)\n\n\ndef RX(a, b):\n    # Pi / 2 rotation about the X axis\n    b = (a + b) % 2\n    return a, b\n\n\ndef R111(a, b):\n    # -2Pi / 3 rotation about (1,1,1)\n    a, b = (a + b) % 2 , a\n    return a, b\n\n\nL = 200\n#row_init = [0,0]*(L//2)\n#row_init[L//2] = 1\n# a = -np.array(L // 2 * [1] + L // 2 * [0]) % d\n# b = np.array(((L // 2) + 1) * [1] + ((L // 2) - 1) * [0])\na = np.zeros(L)\nb = np.zeros(L)\na[L // 2 - 1] = 1\nb[L // 2] = 1\n\n# a = np.random.choice(d, L)\n# b = np.random.choice(d, L)\n\nn_t = 100\n\nsim_a = np.zeros([n_t,L],dtype=np.uint8)\nsim_b = np.zeros([n_t,L],dtype=np.uint8)\nsim_a[0,:] = a\nsim_b[0,:] = b\n\nfor i in range(1, n_t):\n    a[::2], b[::2] = RX(a[::2], b[::2])\n    a[1::2], b[1::2] = RX(a[1::2], b[1::2])\n    for x in range(i % 2, L - i % 2, 2):\n        # 2 qubit gate\n        a[x:x+2], b[x:x+2] = iSWAP(a[x:x+2], b[x:x+2]) \n        \n    sim_a[i,:] = a.astype(int)\n    sim_b[i,:] = b.astype(int)\n    \n\n\nplt.figure(figsize = (18,10))\nplt.imshow(sim_a, cmap='Greys',interpolation='nearest', aspect='equal', origin='lower')\nplt.xlabel(r'$x$', fontsize=36)\nplt.ylabel(r'$t$', fontsize=36, rotation=0)\nplt.xticks(fontsize=36, rotation=0)\nplt.yticks(fontsize=36, rotation=0)\nplt.savefig(f'z2-clifford-z.png')\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure(figsize = (18,10))\nplt.imshow(sim_b, cmap='Greys', aspect='equal', origin='lower')\nplt.xlabel(r'$x$', fontsize=36)\nplt.ylabel(r'$t$', fontsize=36, rotation=0)\nplt.xticks(fontsize=36, rotation=0)\nplt.yticks(fontsize=36, rotation=0)\nplt.savefig('z2-clifford-x.png')\nplt.show()"
  },
  {
    "objectID": "talks/unitary-circuits-kings/index.html",
    "href": "talks/unitary-circuits-kings/index.html",
    "title": "Circuit Models of Many Body Quantum Dynamics",
    "section": "",
    "text": "Physics question:\n\nHow does time evolution couple independent subsystems?\n\nMathematical question:\n\nHow does many-body unitary evolution cause deviation from an initial product state?\n[Unitary normally has structure e.g. from local Hamiltonian]\n\n\n\n\n\n\n\nUnitary transformation composed of unitaries on subsets.\nIntroduced as model of quantum computation.\n\n\n\n\n\n\n\n\n\nState of a single spin-1/2 \\(\\psi_{s}\\) \\(s=\\uparrow,\\downarrow\\).\nState of two spins $\\Psi_{s_1s_2}$.\nProduct states $\\Psi_{s_1s_2}=\\psi^{(1)}_{s_1}\\psi^{(2)}_{s_2}$ are special case.\nState of \\(N\\) spins $\\Psi_{s_1s_2\\cdots s_N}$ is rank \\(N\\) tensor.\n\\(2^N\\) components: “curse of dimensionality”.\n\n\n\n\n\n\n\n\nSee Pan Zhang’s tutorial\n\n\n\n\n\nEvery diagram corresponds to a unique expression\n\n\n\n\n$$ \\sum_{p,q,r,s} A_{pqr} B_{rqsu} C_{pts} $$\n\n\n\n\n\n\n\n\nSome notion of locality built in!\nGates operate on neighbouring pairs, triplets, etc.\n[Often] start from product state $\\Psi_{s_1,s_2,\\ldots s_N}=\\psi_{s_1}\\psi_{s_2}\\cdots \\psi_{s_N}$\n\n\n\n\n\n\nInterested in \\(U(t)|\\psi_0\\rangle\\) with \\(U(t) = e^{-iHt}\\), where (say)\n\n$$ H = \\sum_j \\mathbf{s}_j\\cdot \\mathbf{s}_{j+1} $$\n\nFor small \\(t\\) can approximate $U(t)\\sim U_1(t)U_2(t)$ with $U_{a}=e^{-iH_a t}$\n\n$$ H_1 = \\sum_j \\mathbf{s}_{2j}\\cdot \\mathbf{s}_{2j+1},\\qquad H_2 = \\sum_j \\mathbf{s}_{2j}\\cdot \\mathbf{s}_{2j-1} $$\n\n\nTime evolution for \\(T=Nt\\) is approximately\n\n\\[\nU(T)\\sim \\left[U_1(t)U_2(t)\\right]^N\n\\]\n\n\n\n\n\n\n\n\nTime dependent Hamiltonian with kicks at \\(t=0,1,2,\\ldots\\).\n\n$$ \\begin{aligned} H_{\\text{KIM}}(t) = H_\\text{I}[\\mathbf{h}] + \\sum_{m}\\delta(t-n)H_\\text{K}\\\\ H_\\text{I}[\\mathbf{h}]=\\sum_{j=1}^L\\left[J Z_j Z_{j+1} + h_j Z_j\\right],\\qquad H_\\text{K} &= b\\sum_{j=1}^L X_j, \\end{aligned} $$\n\n“Stroboscopic” form of \\(U(t)=\\mathcal{T}\\exp\\left[-i\\int^t H_{\\text{KIM}}(t') dt'\\right]\\)\n\n$$ \\begin{aligned}   U(n_+) = \\left[U(1_+)\\right]^n,\\qquad U(1_-) = K I_\\mathbf{h}\\\\   I_\\mathbf{h} = e^{-iH_\\text{I}[\\mathbf{h}]}, \\qquad K &= e^{-iH_\\text{K}}, \\end{aligned} $$\n\n\n\n\n\n\n\n$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]. \\end{aligned} $$\n\n\n\n\n\n\n\n\nStatic disorder, or fully random\nFloquet\nMotivation: “general” quantum dynamics (no Hamiltonian) with only constraint of locality.\n\n\n\n\n\n\nHas the graphical representation\n\n\n\n\n\n\n\n\n$$ \\begin{aligned} C(x,y,t)=\\mathop{\\text{tr}}\\left[O(x,t)O(y,0)\\right]\\\\ O(x,t) = U(t)^\\dagger O(x) U(t) \\end{aligned} $$\n\nKeep track of \\(U\\) and \\(U^\\dagger\\)\n\n\n\n\n\n\n\n\n[Chan, De Luca, Chalker (2018)]\n$$ C(x,y,t)=\\mathop{\\text{tr}}\\left[U(t)^\\dagger O(x)U(t) O(y)\\right] $$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLater point must be in “future light cone” of earlier\n\n\n\n\n\n\n\n\n\n[Bertini, Kos, Prosen (2019)] for special models (see later)\nIn fact consequence of unitarity only\n\n\n\n\n\n\n \n\n$$ \\begin{align} C_\\nu^{\\alpha\\beta}(\\nu t,t) = \\frac{1}{d} {\\rm tr}\\left[\\mathcal M_{\\nu}^{2t}(a^\\beta)a^\\alpha\\right]\\\\ \\mathcal M_{+}(a) = \\frac{1}{d} {\\rm tr}_1\\left[U^\\dagger (a\\otimes\\mathbb{1}) U\\right] \\end{align} $$\n\nUnitarity means map is trace preserving, completely positive and unital (identity is fixed point)\n\n\n\n\n\n[Gopalakrishnan & Lamacraft (2019)]\n\nArises when the reshuffled unitary \\(\\tilde U\\) is unitary too\n\n$$ (\\tilde U)_{ab,cd}=(U)_{ac,bd} $$\n\n     \n\n\n14 parameters for qubits! [Bertini, Kos, Prosen (2019)]\n\n\n\n\n\n\n\n\n$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]. \\end{aligned} $$\n\n\\(\\tilde U\\) unitary (“self dual”) for \\(|J|=|b|=\\frac{\\pi}{4}\\)\n\n\n\n\n\n\n\n\n\nUnitarity and dual unitarity\n\n\n   \n\n\n\n\n\n\n[Bertini, Kos, Prosen (2019)]\n\n\n\n\nProof by words:\n\nUnitarity fixes correlations to lie in “past” or “future”\nDual unitarity fiex correlations to be outside the light cone\nTherefore: only nonzero on light cone\n\n\n\n\n\n\n\n\n\n$$ \\rho^{(A)}_{s_1\\cdots s_N,s_1'\\cdots s'_{N}} = \\sum_{s_{N+1}\\cdots s_L} \\Psi_{s_1\\cdots s_N s_{N+1}\\cdots s_L}\\bar \\Psi_{s'_1\\cdots s'_{N}s_{N+1}\\cdots s_{L}} $$\n\nEverything we want is contained in \\(\\rho^{(A)}\\)!\n\n\n\n\n\n\nSince $\\text{tr}\\left[|\\Psi\\rangle\\langle\\Psi|\\right]^2=1$ define purity\n\n$$ \\gamma = \\text{tr}\\left[\\rho_A^2\\right] $$\n\n(von Neumann) Entanglement entropy\n\n$$ S = -\\text{tr}\\left[\\rho_A \\log \\rho_A\\right] $$\n\nRényi entropies\n\n$$   S^{(n)}_A = \\frac{1}{1-n}\\log \\text{tr}\\left[\\rho^n\\right] $$\n\n\\(S^{(n)}\\to S\\) as \\(n\\to 1\\) and \\(S^{(2)} = -\\log\\gamma\\)\n\n\n\n\n\n\nRényi entropies depend on eigenvalues of RDM\n\n$$   S^{(n)}_A = \\frac{1}{1-n}\\sum_\\alpha \\lambda_\\alpha^n $$\n\n$\\epsilon_\\alpha = -\\log \\lambda_\\alpha$ known as entanglement spectrum.\n\n\n\n\n\n\n\n\n\n[Bertini, Kos, Prosen (2018)]\n\\[\n\\lim_{L\\to\\infty} S^{(n)}_A(t) =\\min(2t-2,N)\\log 2,\n\\]\n\nAny \\(h_j\\); inital \\(Z_j\\) product state\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n“Static” disorder or full randomness\nProjective Measurements\nConserved quantities\nClassical circuits [Krajnik & Prosen (2019)]"
  },
  {
    "objectID": "talks/unitary-circuits-kings/index.html#austen-lamacraft",
    "href": "talks/unitary-circuits-kings/index.html#austen-lamacraft",
    "title": "Circuit Models of Many Body Quantum Dynamics",
    "section": "",
    "text": "Physics question:\n\nHow does time evolution couple independent subsystems?\n\nMathematical question:\n\nHow does many-body unitary evolution cause deviation from an initial product state?\n[Unitary normally has structure e.g. from local Hamiltonian]\n\n\n\n\n\n\n\nUnitary transformation composed of unitaries on subsets.\nIntroduced as model of quantum computation.\n\n\n\n\n\n\n\n\n\nState of a single spin-1/2 \\(\\psi_{s}\\) \\(s=\\uparrow,\\downarrow\\).\nState of two spins $\\Psi_{s_1s_2}$.\nProduct states $\\Psi_{s_1s_2}=\\psi^{(1)}_{s_1}\\psi^{(2)}_{s_2}$ are special case.\nState of \\(N\\) spins $\\Psi_{s_1s_2\\cdots s_N}$ is rank \\(N\\) tensor.\n\\(2^N\\) components: “curse of dimensionality”.\n\n\n\n\n\n\n\n\nSee Pan Zhang’s tutorial\n\n\n\n\n\nEvery diagram corresponds to a unique expression\n\n\n\n\n$$ \\sum_{p,q,r,s} A_{pqr} B_{rqsu} C_{pts} $$\n\n\n\n\n\n\n\n\nSome notion of locality built in!\nGates operate on neighbouring pairs, triplets, etc.\n[Often] start from product state $\\Psi_{s_1,s_2,\\ldots s_N}=\\psi_{s_1}\\psi_{s_2}\\cdots \\psi_{s_N}$\n\n\n\n\n\n\nInterested in \\(U(t)|\\psi_0\\rangle\\) with \\(U(t) = e^{-iHt}\\), where (say)\n\n$$ H = \\sum_j \\mathbf{s}_j\\cdot \\mathbf{s}_{j+1} $$\n\nFor small \\(t\\) can approximate $U(t)\\sim U_1(t)U_2(t)$ with $U_{a}=e^{-iH_a t}$\n\n$$ H_1 = \\sum_j \\mathbf{s}_{2j}\\cdot \\mathbf{s}_{2j+1},\\qquad H_2 = \\sum_j \\mathbf{s}_{2j}\\cdot \\mathbf{s}_{2j-1} $$\n\n\nTime evolution for \\(T=Nt\\) is approximately\n\n\\[\nU(T)\\sim \\left[U_1(t)U_2(t)\\right]^N\n\\]\n\n\n\n\n\n\n\n\nTime dependent Hamiltonian with kicks at \\(t=0,1,2,\\ldots\\).\n\n$$ \\begin{aligned} H_{\\text{KIM}}(t) = H_\\text{I}[\\mathbf{h}] + \\sum_{m}\\delta(t-n)H_\\text{K}\\\\ H_\\text{I}[\\mathbf{h}]=\\sum_{j=1}^L\\left[J Z_j Z_{j+1} + h_j Z_j\\right],\\qquad H_\\text{K} &= b\\sum_{j=1}^L X_j, \\end{aligned} $$\n\n“Stroboscopic” form of \\(U(t)=\\mathcal{T}\\exp\\left[-i\\int^t H_{\\text{KIM}}(t') dt'\\right]\\)\n\n$$ \\begin{aligned}   U(n_+) = \\left[U(1_+)\\right]^n,\\qquad U(1_-) = K I_\\mathbf{h}\\\\   I_\\mathbf{h} = e^{-iH_\\text{I}[\\mathbf{h}]}, \\qquad K &= e^{-iH_\\text{K}}, \\end{aligned} $$\n\n\n\n\n\n\n\n$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]. \\end{aligned} $$\n\n\n\n\n\n\n\n\nStatic disorder, or fully random\nFloquet\nMotivation: “general” quantum dynamics (no Hamiltonian) with only constraint of locality.\n\n\n\n\n\n\nHas the graphical representation\n\n\n\n\n\n\n\n\n$$ \\begin{aligned} C(x,y,t)=\\mathop{\\text{tr}}\\left[O(x,t)O(y,0)\\right]\\\\ O(x,t) = U(t)^\\dagger O(x) U(t) \\end{aligned} $$\n\nKeep track of \\(U\\) and \\(U^\\dagger\\)\n\n\n\n\n\n\n\n\n[Chan, De Luca, Chalker (2018)]\n$$ C(x,y,t)=\\mathop{\\text{tr}}\\left[U(t)^\\dagger O(x)U(t) O(y)\\right] $$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLater point must be in “future light cone” of earlier\n\n\n\n\n\n\n\n\n\n[Bertini, Kos, Prosen (2019)] for special models (see later)\nIn fact consequence of unitarity only\n\n\n\n\n\n\n \n\n$$ \\begin{align} C_\\nu^{\\alpha\\beta}(\\nu t,t) = \\frac{1}{d} {\\rm tr}\\left[\\mathcal M_{\\nu}^{2t}(a^\\beta)a^\\alpha\\right]\\\\ \\mathcal M_{+}(a) = \\frac{1}{d} {\\rm tr}_1\\left[U^\\dagger (a\\otimes\\mathbb{1}) U\\right] \\end{align} $$\n\nUnitarity means map is trace preserving, completely positive and unital (identity is fixed point)\n\n\n\n\n\n[Gopalakrishnan & Lamacraft (2019)]\n\nArises when the reshuffled unitary \\(\\tilde U\\) is unitary too\n\n$$ (\\tilde U)_{ab,cd}=(U)_{ac,bd} $$\n\n     \n\n\n14 parameters for qubits! [Bertini, Kos, Prosen (2019)]\n\n\n\n\n\n\n\n\n$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]. \\end{aligned} $$\n\n\\(\\tilde U\\) unitary (“self dual”) for \\(|J|=|b|=\\frac{\\pi}{4}\\)\n\n\n\n\n\n\n\n\n\nUnitarity and dual unitarity\n\n\n   \n\n\n\n\n\n\n[Bertini, Kos, Prosen (2019)]\n\n\n\n\nProof by words:\n\nUnitarity fixes correlations to lie in “past” or “future”\nDual unitarity fiex correlations to be outside the light cone\nTherefore: only nonzero on light cone\n\n\n\n\n\n\n\n\n\n$$ \\rho^{(A)}_{s_1\\cdots s_N,s_1'\\cdots s'_{N}} = \\sum_{s_{N+1}\\cdots s_L} \\Psi_{s_1\\cdots s_N s_{N+1}\\cdots s_L}\\bar \\Psi_{s'_1\\cdots s'_{N}s_{N+1}\\cdots s_{L}} $$\n\nEverything we want is contained in \\(\\rho^{(A)}\\)!\n\n\n\n\n\n\nSince $\\text{tr}\\left[|\\Psi\\rangle\\langle\\Psi|\\right]^2=1$ define purity\n\n$$ \\gamma = \\text{tr}\\left[\\rho_A^2\\right] $$\n\n(von Neumann) Entanglement entropy\n\n$$ S = -\\text{tr}\\left[\\rho_A \\log \\rho_A\\right] $$\n\nRényi entropies\n\n$$   S^{(n)}_A = \\frac{1}{1-n}\\log \\text{tr}\\left[\\rho^n\\right] $$\n\n\\(S^{(n)}\\to S\\) as \\(n\\to 1\\) and \\(S^{(2)} = -\\log\\gamma\\)\n\n\n\n\n\n\nRényi entropies depend on eigenvalues of RDM\n\n$$   S^{(n)}_A = \\frac{1}{1-n}\\sum_\\alpha \\lambda_\\alpha^n $$\n\n$\\epsilon_\\alpha = -\\log \\lambda_\\alpha$ known as entanglement spectrum.\n\n\n\n\n\n\n\n\n\n[Bertini, Kos, Prosen (2018)]\n\\[\n\\lim_{L\\to\\infty} S^{(n)}_A(t) =\\min(2t-2,N)\\log 2,\n\\]\n\nAny \\(h_j\\); inital \\(Z_j\\) product state\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n“Static” disorder or full randomness\nProjective Measurements\nConserved quantities\nClassical circuits [Krajnik & Prosen (2019)]"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html",
    "href": "talks/quantum-circuits-2-icts/index.html",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "austen.uk/slides/quantum-circuits-2-icts for slides\n\n\n\n\n\nCircuits with special structure \\(\\longrightarrow\\) theoretical progress / new insights\n\nRandom circuits\nDual unitary circuits\nOther possibilities: Clifford (Arijeet’s talk), free fermions, …\n\n\n\n\n\n\n\\[\nZ_n(t)= \\sum_{\\mu_{1:N}=\\\\{1,x,y,z\\\\}^N} \\mathcal{C}\\_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots \\sigma_N^{\\mu_N}\n\\]\n\nOperator norm \\(\\tr\\left[Z\\_n^2(t)\\right]=2\\) is conserved under time evolution\n\n\\[\n\\sum_{\\mu_{1:N}=\\\\{1,x,y,z\\\\}^N} \\mathcal{C}^2\\_{\\mu_{1:N}}(t) = \\frac{1}{2^{N-1}}\n\\]\n\n\n\n\n\nCorrelation function \\(\\langle Z_j(t)Z_k(0)\\rangle\\) captures only a single coefficient\n\n\\[\n\\langle Z_j(t)Z_k(0)\\rangle=C_{jk}(t) \\equiv \\mathcal{C}_{1\\cdots \\mu_k=z \\cdots 1}(t)\n\\]\n\n\n\n\nWhat about the rest?\n\n\n\n\n\n\\[\n\\operatorname{OTOC}_{jk}(t) \\equiv \\langle Z_j(t)Z_k(0)Z_j(t)Z_k(0)\\rangle\n\\]\n\nOTOC sometimes written as squared commutator\n\n\\[\n\\langle \\left[Z_k(0),Z_j(t)\\right]^2 \\rangle\n\\]\n\nRelation between two expressions is (using \\(Z^2=1\\))\n\n\\[\n\\operatorname{OTOC}_{jk}(t) = \\frac{1}{2}\\langle \\left[Z_k(0),Z_j(t)\\right]^2 \\rangle + 1\n\\]\n\n\\[\n\\operatorname{OTOC}_{jk}(t) = \\frac{1}{2}\\langle \\left[Z_k(0),Z_j(t)\\right]^2 \\rangle + 1\n\\]\n\nAt short times commutator vanishes so \\(\\operatorname{OTOC}_{jk}(t\\to 0)=1\\)\n\n\\[\n\\operatorname{OTOC}\\_{jk}(t)= 2^{N-1} \\sum_{\\mu_{1:N}}\\mathcal{C}\\_{\\mu_{1:N}}^2(t)\\left[\\delta_{\\mu_k,0}+\\delta_{\\mu_k,3}-\\delta_{\\mu_k,1}-\\delta_{\\mu_k,2}\\right]\n\\]\n\n\\(\\operatorname{OTOC}\\_{jk}(t)\\neq 1\\) after operator \\(Z_j(t)\\) spreads from site \\(j\\) to site \\(k\\)\nCharacteristic speed of propagation of OTOC is “butterfly velocity” \\(v_\\text{B}\\)\nSince OTOC depends on square of the coefficients, a nonzero value survives after averaging over random circuits\n\n\n\n\n\n\nOTOC measured in 2021 by Google\n\n\n\n\nThe measured OTOC for \\(i\\operatorname{\\operatorname{\\mathsf{SWAP}}}\\) gates (top) and \\(\\sqrt{i\\operatorname{\\mathsf{SWAP}}}\\) (bottom) after averaging over single qubit gates.\n\n\n\n\n\n\n\nOTOC provides one measure of operator spreading\nAnother question: how many nonzero coefficients \\(\\mathcal{C}\\_{\\mu_{1:N}}\\)?\nIntroduce Schmidt decomposition for operators \\[\n\\mathcal{O}\\_{AB} = \\sum\\_{n=1}^{\\min(n^2_A, n^2_B)} \\Sigma\\_n A_n\\otimes B_n\n\\]\n\\(\\Sigma_n\\geq 0\\) are operator Schmidt coefficients\n\\(A_n\\) and \\(B_n\\) are orthonormal operators on \\(\\mathcal{H}\\_A\\) and \\(\\mathcal{H}\\_B\\) i.e. \\(\\tr\\left[A^\\dagger_m A_n\\right]=\\tr\\left[B^\\dagger_m B_n\\right]=\\delta_{mn}\\)\n\n\n\nSame entanglement measures as before be applied to evaluate the operator entanglement\nSimplest example, analogous to Bell state, is SWAP operator\n\n\\[\n\\operatorname{\\mathsf{SWAP}}=\\frac{1}{2}\\left[X\\otimes X+Y\\otimes Y+Z\\otimes Z + \\mathsf{1}\\otimes\\mathsf{1}\\right]\n\\]\n\nAll Schmidt coefficients are equal (maximum operator entanglement)\n\n\n\n\n\n\nMet this idea last time: average over \\(\\theta\\) in\n\n\\[\nU\\_{j,j+1} = \\cos\\theta \\mathbb{1}\\_{j,j+1} + i\\sin\\theta \\operatorname{\\mathsf{S}}\\_{j.j+1}\n\\]\n\nNow consider even more random gates: average uniformly over single site unitaries\n\n\n\n\n\n\n\n\n\nNo symmetries so results should be generic (“in some sense”)\n(real reason) Averaging over circuits simplifies things considerably, sometimes allowing tractable classical description\n\n\nChoose gates iid. Other options: randomness in space but not time\nRecent review: Fisher et al (2023)\n\n\n\n\n\\[\n\\operatorname{OTOC}_{jk}(t) \\equiv \\langle Z_j(t)Z_k(0)Z_j(t)Z_k(0)\\rangle\n\\]\n\nOTOC can be extracted by appropriately contracting indices in \\(Z_j(t)\\otimes Z_j(t)\\) (two copies)\nWhen we average over random unitaries, only certain components survive\nSingle qubit unitaries identified with rotations, so look for scalar operators made from two copies on each site\n\n\\[\n\\mathsf{1}\\otimes\\mathsf{1},\\qquad \\frac{1}{3}\\left[X\\otimes X+Y\\otimes Y + Z\\otimes Z\\right]\n\\]\n\n\nDifferent papers prefer different bases. The most popular choice is \\[\n\\mathsf{1}\\otimes\\mathsf{1},\\qquad \\operatorname{SWAP}\n\\] (recall that \\(\\operatorname{\\mathsf{SWAP}}=\\frac{1}{2}\\left[X\\otimes X+Y\\otimes Y+Z\\otimes Z + \\mathsf{1}\\otimes\\mathsf{1}\\right]\\))\nAdvantage: generalizes to multiple copies\nGeneral set of invariants are generalized SWAP operators corresponding to permutations of copies (for two copies only two permutations)\n\n\n\nNow use invariant local basis to expand average of two copies\n\n\\[\n\\mathcal{O}^{(2)}(t)=\\overline{O(t) \\otimes O(t)} \\equiv \\overline{O(t)^{\\otimes 2}}\n\\]\n\\[\n\\begin{align*}\n\\mathsf{O} &\\equiv\\mathsf{1}\\otimes\\mathsf{1} \\\\\\\n\\mathsf{1}&\\equiv\\frac{1}{3}\\left[X\\otimes X + Y\\otimes Y+ Z\\otimes Z\\right]\n\\end{align*}\n\\]\n\nIntroduce basis \\(\\mathsf{S}_{1:N}\\equiv\\mathsf{S}_1\\otimes \\mathsf{S}_2\\otimes\\cdots \\mathsf{S}_N\\), with \\(\\mathsf{S}_j=\\mathsf{0},\\mathsf{1}\\)\n\n\\[\n\\mathcal{O}^{(2)}(t) = \\sum\\_{\\mathsf{S}\\_{1:N}\\in\\\\{\\mathsf{0},\\mathsf{1}\\\\}^N} P\\_{\\mathsf{S}\\_{1:N}}(t)\\mathsf{S}\\_{1:N}\n\\]\n\nCoefficients \\(P\\_{\\mathsf{S}\\_{1:N}}(t)\\) describe averaged OTOC\n\n\n\nNext find how \\(P\\_{\\mathsf{S}\\_{1:N}}(t)\\) are updated by a single gate (after averaging)\nGate acting on sites \\(j\\) and \\(j+1\\) yields\n\n\\[\nU^\\dagger_{j,j+1}\\otimes U^\\dagger_{j,j+1} \\mathcal{O}^{(2)}(t)U_{j,j+1}\\otimes U_{j,j+1}\n\\]\n\nTake \\(U_{j,j+1}\\) of form \\[\nU_{j,j+1} = V_{j,j+1} u_j \\otimes u_{j+1}\n\\] where \\(u_j\\) and \\(u_{j+1}\\) are single quibit unitaries chosen uniformly\nAfter averaging all non-invariant components vanish and invariant components don’t depend on \\(u_j\\) and \\(u_{j+1}\\)\nExtract \\(P\\_{\\mathsf{S}\\_{1:N}}(t+1)\\) using orthgonality \\(\\tr\\left[\\mathsf{O}\\mathsf{1}\\right]=0\\)\n\n\n\\[\nP\\_{\\mathsf{S}\\_{1:N}}(t+1) = \\sum\\_{\\mathsf{S}'\\_j, \\mathsf{S}'\\_{j+1}}  P\\_{\\mathsf{S}\\_1\\cdots \\mathsf{S}'\\_j  \\mathsf{S}'\\_{j+1}\\cdots \\mathsf{S}\\_N}(t)\\Omega\\_{\\mathsf{S}'\\_j \\mathsf{S}'\\_{j+1},\\mathsf{S}\\_j \\mathsf{S}\\_k}\n\\]\n\nPrecise form of matrix \\(\\Omega\\) depends on \\(V_{j,j+1}\\) “core”\nUse conservation of operator norm \\(\\tr\\left[O(t)^\\dagger O(t)\\right]\\)\n\n\\[\n\\overline{\\tr\\left[O(t)^\\dagger O(t)\\right]} = 2\\sum\\_{\\mathsf{S}\\_{1:N}\\in\\{\\mathsf{0},\\mathsf{1}\\}^N} P\\_{\\mathsf{S}\\_{1:N}}\n\\]\n\\[\n\\sum_{S_j, S_{j+1}}\\Omega\\_{\\mathsf{S}'\\_j \\mathsf{S}'\\_{j+1},\\mathsf{S}\\_j \\mathsf{S}\\_k} = 1\n\\]\n\nIf matrix elements additionally nonnegative we have a Markov process, with transition matrix \\(\\Omega\\)\n\n\n\nFor Sycamore gate (Google’s OTOC experiment, supplementary material)\n\n\\[\n\\begin{align*}\n\\Omega&=\\left(\\begin{array}{cccc}\n1 & 0 & 0 & 0 \\\\\\\n0 & 1-a-b & a & b \\\\\\\n0 & a & 1-a-b & b \\\\\\\n0 & \\frac{b}{3} & \\frac{b}{3} & \\left(1-\\frac{2}{3} b\\right)\n\\end{array}\\right) \\\\\\\na&=\\frac{1}{3}\\left(2 \\sin ^{2} \\theta+\\sin ^{4} \\theta\\right) \\qquad b=\\frac{1}{3}\\left(\\frac{1}{2} \\sin ^{2} 2 \\theta+2\\left(\\sin ^{2} \\theta+\\cos ^{2} \\theta\\right)\\right)\n\\end{align*}\n\\]\n\n\\(\\theta=\\pi/2\\) for \\(i\\operatorname{SWAP}\\) gate and \\(\\theta=\\pi/4\\) for \\(\\sqrt{i\\operatorname{SWAP}}\\)\n\n\n\n\n\n\n\nIdea that unitary averages over two copies yields a Markov process on the invariant space goes back to Oliveria, Dahlsten, and Plenio (2007), which was concerned with dynamics of average purity \\(\\gamma\\equiv \\tr \\rho_A^2\\)\n\\(\\bar \\gamma\\) can be extracted from average of two copies of density matrix \\(\\rho(t)\\otimes\\rho(t)\\). See e.g. Rowlands and Lamacraft (2018) for noisy unitary evolution in continuous time\n\n\n\n\n\n\\[\n\\begin{align*}\n\\Omega&=\\left(\\begin{array}{cccc}\n1 & 0 & 0 & 0 \\\\\\\n0 & 1-a-b & a & b \\\\\\\n0 & a & 1-a-b & b \\\\\\\n0 & \\frac{b}{3} & \\frac{b}{3} & \\left(1-\\frac{2}{3} b\\right)\n\\end{array}\\right)\n\\end{align*}\n\\]\n\nDescribes transitions\n\n\\[\n\\mathsf{10} \\xleftrightharpoons[a]{a}  \\mathsf{01} \\qquad \\mathsf{11} \\xleftrightharpoons[b/3]{b} \\mathsf{10},\\mathsf{01}\n\\]\n\nNote that \\(\\mathsf{0}=\\mathsf{1}\\otimes\\mathsf{1}\\) is “inert”: there no transitions from or to \\(\\mathsf{00}\\)\n\n\n\n\n\n\\[\n\\mathsf{10} \\xleftrightharpoons[a]{a}  \\mathsf{01} \\qquad \\mathsf{11} \\xleftrightharpoons[b/3]{b} \\mathsf{10},\\mathsf{01}\n\\]\n\n\n\n\n\n\n\nStationary state: independent sites with \\(p_1=3/4\\), \\(p_0=1/4\\)\n\n\n\n\n\n\nFront propagation characterised by finite velocity \\(v_\\text{B}\\)\n\n\n\n\n\n\n\n\n\nFront broadens unless \\(v_\\text{B}\\) maximal as for \\(i\\operatorname{SWAP}\\)\n\n\n \n\n\\(i\\operatorname{SWAP}\\) (left) vs. \\(\\sqrt{i\\operatorname{SWAP}}\\) (right)\n\n\n\n\nDiffusive in 1D \\(\\propto \\sqrt{t}\\)\nKPZ dynamics in 2D\n\n\n\n\n\nSee Nahum, Vijay, and Haah (2018) for much more\n\n\n\n\n\n\nEfficient simulation of averaged OTOC dynamics via Monte Carlo\nAppearance of Markov process a little surprising\n\n\n\n\n\n\nCircuit-to-circuit fluctuations of OTOC from\n\n\\[\n\\mathcal{O}^{(4)}(t)=\\overline{O(t) \\otimes O(t) \\otimes O(t) \\otimes O(t)} \\equiv \\overline{O(t)^{\\otimes 4}}\n\\]\n\nGo through same procedure of identifying invariant states\nEvolution of average now involves negative matrix elements\nLeads to sign problem in Monte Carlo simulation\nSame problem for \\(\\overline{\\operatorname{OTOC}}\\) in models with number conservation (Rowlands and Lamacraft)\n\n\n\n\n\n\n\n\n\n\nTime dependent Hamiltonian with kicks at \\(t=0,1,2,\\ldots\\).\n\n\\[\n\\begin{align*}\nH_{\\text{KIM}}(t) = H_\\text{I}[\\mathbf{h}] + \\sum_{n}\\delta(t-n)H_\\text{K}\\\\\\\nH_\\text{I}[\\mathbf{h}]=\\sum_{j=1}^L\\left[J Z_j Z_{j+1} + h_j Z_j\\right],\\qquad H_\\text{K} &= b\\sum_{j=1}^L X_j\n\\end{align*}\n\\]\n\n\n\n\n\nBertini, Kos, Prosen (2019) found that when \\(|J|=|b|=\\pi/4\\)\n\n\\[\n\\lim_{L\\to\\infty} S_A =\\min(2t-2,N_A)\\log 2,\n\\]\n\nAny \\(h_j\\); initial \\(Z_j\\) product state\n\n\n\n\n\n\n\n\n\nRényi entropies depend on eigenvalues of reduced density matrix\n\n$$   S^{(\\alpha)}_A = \\frac{1}{1-\\alpha}\\log \\text{tr}\\left[\\rho^\\alpha\\right]=\\frac{1}{1-\\alpha}\\sum_n p_n^\\alpha $$\n\nFor SDKIM have \\(2^{\\min(2t-2,N_A)}\\) non-zero eigenvalues all equal\n\n\\[\np_n = \\left(\\frac{1}{2}\\right)^{\\min(2t-2,N_A)}\n\\]\n\n\n\n\n\nAfter \\(N_A/2 + 1\\) steps, reduced density matrix is \\(\\propto \\mathbb{1}\\)\nAll expectations (with \\(A\\)) take on infinite temperature value\n\n\n\n\n\n\nRecall KIM has circuit representation\n\n\n\n\n$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right] \\end{aligned} $$\n\nAt \\(|J|=|b|=\\pi/4\\) has additional property of dual unitarity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnitarity:\n\n\n\n\n\n\n\n\n\nImpose additional restriction\n\n\n\n\n\nGopalakrishnan and Lamacraft (2019), Bertini, Kos, and Prosen (2019)\n\n\n\n\n\n\nInitial state of NN Bell pairs\n8 sites; 4 layers\n\n\n\n\n\\(\\rho_A\\) is unitary transformation of\n\n\\[\n  \\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\n\\]\n\n\n\n\n\n\n\n\\(\\rho_A\\) is unitary transformation of\n\n\\[\n\\mathbb{1}\\otimes\\mathbb{1}\\ket{\\Phi^+}\\bra{\\Phi^+}\\otimes\\ket{\\Phi^+}\\bra{\\Phi^+}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\n\\]\n\n\n\n\n\nRDM is unitary transformation of\n\n\\[\n\\rho_0=\\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1} \\otimes\\overbrace{\\ket{\\Phi^+}\\bra{\\Phi^+} \\cdots }^{N_A/2-t+1 } \\otimes \\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1}\n\\]\n\nRDM has \\(2^{\\min(2t-2,N_A)}\\) non-zero eigenvalues all equal to \\(\\left(\\frac{1}{2}\\right)^{\\min(2t-2,N_A)}\\)\nConverse – maximal entanglement growth implies dual unitary gates – recently proved by Zhou and Harrow (2022)\n\n\n\n\n\n\n\\(4\\times 4\\) unitaries are 16-dimensional\nFamily of dual unitaries is 14-dimensional\nIncludes kicked Ising model at particular values of couplings\nDual unitaries not “integrable” but have enough structure to allow many calculations\n\n\n\n\n\n\n\n\n\n(\\(q=2\\) here) Not satisfied by e.g. \\(\\operatorname{SWAP}\\)\nMaps product states to maximally entangled (Bell) states\nProduct initial states also work for KIM!\nPiroli et al (2020) studied more general initial states\nFoligno and Bertini (2023) study general initial conditions\n\n\n\n\n\n\nInfinite temperature correlator \\(\\tr\\left[\\sigma^\\alpha_x(x,t)\\sigma^\\beta(y,0)\\right]\\)\n\n\n\n\n\nBertini, Kos, and Prosen (2019): dual unitarity means correlations vanish inside light cone!\n\n\n\n\n\n\nCorrelations measured in SDKIM last year\n\n\n\n\n\n\n\n\n\nClaeys and Lamacraft (2020). \\(v_\\text{B}=1\\). OTOC grows at maximum speed, c.f. Google experiment\nJonay, Kehmani, Ippoliti (2021). Triunitary circuits (incl. 2+1 dimensions)\nStephen et al (2022). Measurement based quantum computation in 1D using dual unitaries\nSommers, Huse, Gullans (2022). Dual unitary Clifford automata with applications to codes\nSuzuki, Mitarai, Fujii (2022). Computational power of dual unitaries\nMany more!"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#some-special-kinds-of-circuits",
    "href": "talks/quantum-circuits-2-icts/index.html#some-special-kinds-of-circuits",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "austen.uk/slides/quantum-circuits-2-icts for slides"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#outline",
    "href": "talks/quantum-circuits-2-icts/index.html#outline",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Circuits with special structure \\(\\longrightarrow\\) theoretical progress / new insights\n\nRandom circuits\nDual unitary circuits\nOther possibilities: Clifford (Arijeet’s talk), free fermions, …"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#reminder-operator-spreading",
    "href": "talks/quantum-circuits-2-icts/index.html#reminder-operator-spreading",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "\\[\nZ_n(t)= \\sum_{\\mu_{1:N}=\\\\{1,x,y,z\\\\}^N} \\mathcal{C}\\_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots \\sigma_N^{\\mu_N}\n\\]\n\nOperator norm \\(\\tr\\left[Z\\_n^2(t)\\right]=2\\) is conserved under time evolution\n\n\\[\n\\sum_{\\mu_{1:N}=\\\\{1,x,y,z\\\\}^N} \\mathcal{C}^2\\_{\\mu_{1:N}}(t) = \\frac{1}{2^{N-1}}\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#describing-operator-spreading",
    "href": "talks/quantum-circuits-2-icts/index.html#describing-operator-spreading",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Correlation function \\(\\langle Z_j(t)Z_k(0)\\rangle\\) captures only a single coefficient\n\n\\[\n\\langle Z_j(t)Z_k(0)\\rangle=C_{jk}(t) \\equiv \\mathcal{C}_{1\\cdots \\mu_k=z \\cdots 1}(t)\n\\]\n\n\n\n\nWhat about the rest?"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#out-of-time-order-correlator",
    "href": "talks/quantum-circuits-2-icts/index.html#out-of-time-order-correlator",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "\\[\n\\operatorname{OTOC}_{jk}(t) \\equiv \\langle Z_j(t)Z_k(0)Z_j(t)Z_k(0)\\rangle\n\\]\n\nOTOC sometimes written as squared commutator\n\n\\[\n\\langle \\left[Z_k(0),Z_j(t)\\right]^2 \\rangle\n\\]\n\nRelation between two expressions is (using \\(Z^2=1\\))\n\n\\[\n\\operatorname{OTOC}_{jk}(t) = \\frac{1}{2}\\langle \\left[Z_k(0),Z_j(t)\\right]^2 \\rangle + 1\n\\]\n\n\\[\n\\operatorname{OTOC}_{jk}(t) = \\frac{1}{2}\\langle \\left[Z_k(0),Z_j(t)\\right]^2 \\rangle + 1\n\\]\n\nAt short times commutator vanishes so \\(\\operatorname{OTOC}_{jk}(t\\to 0)=1\\)\n\n\\[\n\\operatorname{OTOC}\\_{jk}(t)= 2^{N-1} \\sum_{\\mu_{1:N}}\\mathcal{C}\\_{\\mu_{1:N}}^2(t)\\left[\\delta_{\\mu_k,0}+\\delta_{\\mu_k,3}-\\delta_{\\mu_k,1}-\\delta_{\\mu_k,2}\\right]\n\\]\n\n\\(\\operatorname{OTOC}\\_{jk}(t)\\neq 1\\) after operator \\(Z_j(t)\\) spreads from site \\(j\\) to site \\(k\\)\nCharacteristic speed of propagation of OTOC is “butterfly velocity” \\(v_\\text{B}\\)\nSince OTOC depends on square of the coefficients, a nonzero value survives after averaging over random circuits"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#googles-otoc-experiment",
    "href": "talks/quantum-circuits-2-icts/index.html#googles-otoc-experiment",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "OTOC measured in 2021 by Google\n\n\n\n\nThe measured OTOC for \\(i\\operatorname{\\operatorname{\\mathsf{SWAP}}}\\) gates (top) and \\(\\sqrt{i\\operatorname{\\mathsf{SWAP}}}\\) (bottom) after averaging over single qubit gates."
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#remark-operator-entanglement",
    "href": "talks/quantum-circuits-2-icts/index.html#remark-operator-entanglement",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "OTOC provides one measure of operator spreading\nAnother question: how many nonzero coefficients \\(\\mathcal{C}\\_{\\mu_{1:N}}\\)?\nIntroduce Schmidt decomposition for operators \\[\n\\mathcal{O}\\_{AB} = \\sum\\_{n=1}^{\\min(n^2_A, n^2_B)} \\Sigma\\_n A_n\\otimes B_n\n\\]\n\\(\\Sigma_n\\geq 0\\) are operator Schmidt coefficients\n\\(A_n\\) and \\(B_n\\) are orthonormal operators on \\(\\mathcal{H}\\_A\\) and \\(\\mathcal{H}\\_B\\) i.e. \\(\\tr\\left[A^\\dagger_m A_n\\right]=\\tr\\left[B^\\dagger_m B_n\\right]=\\delta_{mn}\\)\n\n\n\nSame entanglement measures as before be applied to evaluate the operator entanglement\nSimplest example, analogous to Bell state, is SWAP operator\n\n\\[\n\\operatorname{\\mathsf{SWAP}}=\\frac{1}{2}\\left[X\\otimes X+Y\\otimes Y+Z\\otimes Z + \\mathsf{1}\\otimes\\mathsf{1}\\right]\n\\]\n\nAll Schmidt coefficients are equal (maximum operator entanglement)"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#random-circuits",
    "href": "talks/quantum-circuits-2-icts/index.html#random-circuits",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Met this idea last time: average over \\(\\theta\\) in\n\n\\[\nU\\_{j,j+1} = \\cos\\theta \\mathbb{1}\\_{j,j+1} + i\\sin\\theta \\operatorname{\\mathsf{S}}\\_{j.j+1}\n\\]\n\nNow consider even more random gates: average uniformly over single site unitaries"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#why",
    "href": "talks/quantum-circuits-2-icts/index.html#why",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "No symmetries so results should be generic (“in some sense”)\n(real reason) Averaging over circuits simplifies things considerably, sometimes allowing tractable classical description\n\n\nChoose gates iid. Other options: randomness in space but not time\nRecent review: Fisher et al (2023)\n\n\n\n\n\\[\n\\operatorname{OTOC}_{jk}(t) \\equiv \\langle Z_j(t)Z_k(0)Z_j(t)Z_k(0)\\rangle\n\\]\n\nOTOC can be extracted by appropriately contracting indices in \\(Z_j(t)\\otimes Z_j(t)\\) (two copies)\nWhen we average over random unitaries, only certain components survive\nSingle qubit unitaries identified with rotations, so look for scalar operators made from two copies on each site\n\n\\[\n\\mathsf{1}\\otimes\\mathsf{1},\\qquad \\frac{1}{3}\\left[X\\otimes X+Y\\otimes Y + Z\\otimes Z\\right]\n\\]\n\n\nDifferent papers prefer different bases. The most popular choice is \\[\n\\mathsf{1}\\otimes\\mathsf{1},\\qquad \\operatorname{SWAP}\n\\] (recall that \\(\\operatorname{\\mathsf{SWAP}}=\\frac{1}{2}\\left[X\\otimes X+Y\\otimes Y+Z\\otimes Z + \\mathsf{1}\\otimes\\mathsf{1}\\right]\\))\nAdvantage: generalizes to multiple copies\nGeneral set of invariants are generalized SWAP operators corresponding to permutations of copies (for two copies only two permutations)\n\n\n\nNow use invariant local basis to expand average of two copies\n\n\\[\n\\mathcal{O}^{(2)}(t)=\\overline{O(t) \\otimes O(t)} \\equiv \\overline{O(t)^{\\otimes 2}}\n\\]\n\\[\n\\begin{align*}\n\\mathsf{O} &\\equiv\\mathsf{1}\\otimes\\mathsf{1} \\\\\\\n\\mathsf{1}&\\equiv\\frac{1}{3}\\left[X\\otimes X + Y\\otimes Y+ Z\\otimes Z\\right]\n\\end{align*}\n\\]\n\nIntroduce basis \\(\\mathsf{S}_{1:N}\\equiv\\mathsf{S}_1\\otimes \\mathsf{S}_2\\otimes\\cdots \\mathsf{S}_N\\), with \\(\\mathsf{S}_j=\\mathsf{0},\\mathsf{1}\\)\n\n\\[\n\\mathcal{O}^{(2)}(t) = \\sum\\_{\\mathsf{S}\\_{1:N}\\in\\\\{\\mathsf{0},\\mathsf{1}\\\\}^N} P\\_{\\mathsf{S}\\_{1:N}}(t)\\mathsf{S}\\_{1:N}\n\\]\n\nCoefficients \\(P\\_{\\mathsf{S}\\_{1:N}}(t)\\) describe averaged OTOC\n\n\n\nNext find how \\(P\\_{\\mathsf{S}\\_{1:N}}(t)\\) are updated by a single gate (after averaging)\nGate acting on sites \\(j\\) and \\(j+1\\) yields\n\n\\[\nU^\\dagger_{j,j+1}\\otimes U^\\dagger_{j,j+1} \\mathcal{O}^{(2)}(t)U_{j,j+1}\\otimes U_{j,j+1}\n\\]\n\nTake \\(U_{j,j+1}\\) of form \\[\nU_{j,j+1} = V_{j,j+1} u_j \\otimes u_{j+1}\n\\] where \\(u_j\\) and \\(u_{j+1}\\) are single quibit unitaries chosen uniformly\nAfter averaging all non-invariant components vanish and invariant components don’t depend on \\(u_j\\) and \\(u_{j+1}\\)\nExtract \\(P\\_{\\mathsf{S}\\_{1:N}}(t+1)\\) using orthgonality \\(\\tr\\left[\\mathsf{O}\\mathsf{1}\\right]=0\\)\n\n\n\\[\nP\\_{\\mathsf{S}\\_{1:N}}(t+1) = \\sum\\_{\\mathsf{S}'\\_j, \\mathsf{S}'\\_{j+1}}  P\\_{\\mathsf{S}\\_1\\cdots \\mathsf{S}'\\_j  \\mathsf{S}'\\_{j+1}\\cdots \\mathsf{S}\\_N}(t)\\Omega\\_{\\mathsf{S}'\\_j \\mathsf{S}'\\_{j+1},\\mathsf{S}\\_j \\mathsf{S}\\_k}\n\\]\n\nPrecise form of matrix \\(\\Omega\\) depends on \\(V_{j,j+1}\\) “core”\nUse conservation of operator norm \\(\\tr\\left[O(t)^\\dagger O(t)\\right]\\)\n\n\\[\n\\overline{\\tr\\left[O(t)^\\dagger O(t)\\right]} = 2\\sum\\_{\\mathsf{S}\\_{1:N}\\in\\{\\mathsf{0},\\mathsf{1}\\}^N} P\\_{\\mathsf{S}\\_{1:N}}\n\\]\n\\[\n\\sum_{S_j, S_{j+1}}\\Omega\\_{\\mathsf{S}'\\_j \\mathsf{S}'\\_{j+1},\\mathsf{S}\\_j \\mathsf{S}\\_k} = 1\n\\]\n\nIf matrix elements additionally nonnegative we have a Markov process, with transition matrix \\(\\Omega\\)\n\n\n\nFor Sycamore gate (Google’s OTOC experiment, supplementary material)\n\n\\[\n\\begin{align*}\n\\Omega&=\\left(\\begin{array}{cccc}\n1 & 0 & 0 & 0 \\\\\\\n0 & 1-a-b & a & b \\\\\\\n0 & a & 1-a-b & b \\\\\\\n0 & \\frac{b}{3} & \\frac{b}{3} & \\left(1-\\frac{2}{3} b\\right)\n\\end{array}\\right) \\\\\\\na&=\\frac{1}{3}\\left(2 \\sin ^{2} \\theta+\\sin ^{4} \\theta\\right) \\qquad b=\\frac{1}{3}\\left(\\frac{1}{2} \\sin ^{2} 2 \\theta+2\\left(\\sin ^{2} \\theta+\\cos ^{2} \\theta\\right)\\right)\n\\end{align*}\n\\]\n\n\\(\\theta=\\pi/2\\) for \\(i\\operatorname{SWAP}\\) gate and \\(\\theta=\\pi/4\\) for \\(\\sqrt{i\\operatorname{SWAP}}\\)"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#remarks",
    "href": "talks/quantum-circuits-2-icts/index.html#remarks",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Idea that unitary averages over two copies yields a Markov process on the invariant space goes back to Oliveria, Dahlsten, and Plenio (2007), which was concerned with dynamics of average purity \\(\\gamma\\equiv \\tr \\rho_A^2\\)\n\\(\\bar \\gamma\\) can be extracted from average of two copies of density matrix \\(\\rho(t)\\otimes\\rho(t)\\). See e.g. Rowlands and Lamacraft (2018) for noisy unitary evolution in continuous time"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#the-markov-process",
    "href": "talks/quantum-circuits-2-icts/index.html#the-markov-process",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "\\[\n\\begin{align*}\n\\Omega&=\\left(\\begin{array}{cccc}\n1 & 0 & 0 & 0 \\\\\\\n0 & 1-a-b & a & b \\\\\\\n0 & a & 1-a-b & b \\\\\\\n0 & \\frac{b}{3} & \\frac{b}{3} & \\left(1-\\frac{2}{3} b\\right)\n\\end{array}\\right)\n\\end{align*}\n\\]\n\nDescribes transitions\n\n\\[\n\\mathsf{10} \\xleftrightharpoons[a]{a}  \\mathsf{01} \\qquad \\mathsf{11} \\xleftrightharpoons[b/3]{b} \\mathsf{10},\\mathsf{01}\n\\]\n\nNote that \\(\\mathsf{0}=\\mathsf{1}\\otimes\\mathsf{1}\\) is “inert”: there no transitions from or to \\(\\mathsf{00}\\)"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#fredricksonandersen-model",
    "href": "talks/quantum-circuits-2-icts/index.html#fredricksonandersen-model",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "\\[\n\\mathsf{10} \\xleftrightharpoons[a]{a}  \\mathsf{01} \\qquad \\mathsf{11} \\xleftrightharpoons[b/3]{b} \\mathsf{10},\\mathsf{01}\n\\]\n\n\n\n\n\n\n\nStationary state: independent sites with \\(p_1=3/4\\), \\(p_0=1/4\\)"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#butterfly-velocity",
    "href": "talks/quantum-circuits-2-icts/index.html#butterfly-velocity",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Front propagation characterised by finite velocity \\(v_\\text{B}\\)"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#front-broadening",
    "href": "talks/quantum-circuits-2-icts/index.html#front-broadening",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Front broadens unless \\(v_\\text{B}\\) maximal as for \\(i\\operatorname{SWAP}\\)\n\n\n \n\n\\(i\\operatorname{SWAP}\\) (left) vs. \\(\\sqrt{i\\operatorname{SWAP}}\\) (right)\n\n\n\n\nDiffusive in 1D \\(\\propto \\sqrt{t}\\)\nKPZ dynamics in 2D\n\n\n\n\n\nSee Nahum, Vijay, and Haah (2018) for much more"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#classical-simulation",
    "href": "talks/quantum-circuits-2-icts/index.html#classical-simulation",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Efficient simulation of averaged OTOC dynamics via Monte Carlo\nAppearance of Markov process a little surprising"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#otoc-fluctuations",
    "href": "talks/quantum-circuits-2-icts/index.html#otoc-fluctuations",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Circuit-to-circuit fluctuations of OTOC from\n\n\\[\n\\mathcal{O}^{(4)}(t)=\\overline{O(t) \\otimes O(t) \\otimes O(t) \\otimes O(t)} \\equiv \\overline{O(t)^{\\otimes 4}}\n\\]\n\nGo through same procedure of identifying invariant states\nEvolution of average now involves negative matrix elements\nLeads to sign problem in Monte Carlo simulation\nSame problem for \\(\\overline{\\operatorname{OTOC}}\\) in models with number conservation (Rowlands and Lamacraft)"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#recall-kicked-ising-model",
    "href": "talks/quantum-circuits-2-icts/index.html#recall-kicked-ising-model",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Time dependent Hamiltonian with kicks at \\(t=0,1,2,\\ldots\\).\n\n\\[\n\\begin{align*}\nH_{\\text{KIM}}(t) = H_\\text{I}[\\mathbf{h}] + \\sum_{n}\\delta(t-n)H_\\text{K}\\\\\\\nH_\\text{I}[\\mathbf{h}]=\\sum_{j=1}^L\\left[J Z_j Z_{j+1} + h_j Z_j\\right],\\qquad H_\\text{K} &= b\\sum_{j=1}^L X_j\n\\end{align*}\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#entanglement-growth-for-kim",
    "href": "talks/quantum-circuits-2-icts/index.html#entanglement-growth-for-kim",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Bertini, Kos, Prosen (2019) found that when \\(|J|=|b|=\\pi/4\\)\n\n\\[\n\\lim_{L\\to\\infty} S_A =\\min(2t-2,N_A)\\log 2,\n\\]\n\nAny \\(h_j\\); initial \\(Z_j\\) product state"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#entanglement-spectrum",
    "href": "talks/quantum-circuits-2-icts/index.html#entanglement-spectrum",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Rényi entropies depend on eigenvalues of reduced density matrix\n\n$$   S^{(\\alpha)}_A = \\frac{1}{1-\\alpha}\\log \\text{tr}\\left[\\rho^\\alpha\\right]=\\frac{1}{1-\\alpha}\\sum_n p_n^\\alpha $$\n\nFor SDKIM have \\(2^{\\min(2t-2,N_A)}\\) non-zero eigenvalues all equal\n\n\\[\np_n = \\left(\\frac{1}{2}\\right)^{\\min(2t-2,N_A)}\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#thermalization",
    "href": "talks/quantum-circuits-2-icts/index.html#thermalization",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "After \\(N_A/2 + 1\\) steps, reduced density matrix is \\(\\propto \\mathbb{1}\\)\nAll expectations (with \\(A\\)) take on infinite temperature value"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#dual-unitarity",
    "href": "talks/quantum-circuits-2-icts/index.html#dual-unitarity",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Recall KIM has circuit representation\n\n\n\n\n$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right] \\end{aligned} $$\n\nAt \\(|J|=|b|=\\pi/4\\) has additional property of dual unitarity"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#folded-representations",
    "href": "talks/quantum-circuits-2-icts/index.html#folded-representations",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Unitarity:"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#dual-unitary-gates",
    "href": "talks/quantum-circuits-2-icts/index.html#dual-unitary-gates",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Impose additional restriction\n\n\n\n\n\nGopalakrishnan and Lamacraft (2019), Bertini, Kos, and Prosen (2019)"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#rho_a-via-dual-unitarity",
    "href": "talks/quantum-circuits-2-icts/index.html#rho_a-via-dual-unitarity",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Initial state of NN Bell pairs\n8 sites; 4 layers\n\n\n\n\n\\(\\rho_A\\) is unitary transformation of\n\n\\[\n  \\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#shallower",
    "href": "talks/quantum-circuits-2-icts/index.html#shallower",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "\\(\\rho_A\\) is unitary transformation of\n\n\\[\n\\mathbb{1}\\otimes\\mathbb{1}\\ket{\\Phi^+}\\bra{\\Phi^+}\\otimes\\ket{\\Phi^+}\\bra{\\Phi^+}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#general-case",
    "href": "talks/quantum-circuits-2-icts/index.html#general-case",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "RDM is unitary transformation of\n\n\\[\n\\rho_0=\\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1} \\otimes\\overbrace{\\ket{\\Phi^+}\\bra{\\Phi^+} \\cdots }^{N_A/2-t+1 } \\otimes \\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1}\n\\]\n\nRDM has \\(2^{\\min(2t-2,N_A)}\\) non-zero eigenvalues all equal to \\(\\left(\\frac{1}{2}\\right)^{\\min(2t-2,N_A)}\\)\nConverse – maximal entanglement growth implies dual unitary gates – recently proved by Zhou and Harrow (2022)"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#the-dual-unitary-family",
    "href": "talks/quantum-circuits-2-icts/index.html#the-dual-unitary-family",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "\\(4\\times 4\\) unitaries are 16-dimensional\nFamily of dual unitaries is 14-dimensional\nIncludes kicked Ising model at particular values of couplings\nDual unitaries not “integrable” but have enough structure to allow many calculations"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#kim-property",
    "href": "talks/quantum-circuits-2-icts/index.html#kim-property",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "(\\(q=2\\) here) Not satisfied by e.g. \\(\\operatorname{SWAP}\\)\nMaps product states to maximally entangled (Bell) states\nProduct initial states also work for KIM!\nPiroli et al (2020) studied more general initial states\nFoligno and Bertini (2023) study general initial conditions"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#correlation-functions",
    "href": "talks/quantum-circuits-2-icts/index.html#correlation-functions",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Infinite temperature correlator \\(\\tr\\left[\\sigma^\\alpha_x(x,t)\\sigma^\\beta(y,0)\\right]\\)\n\n\n\n\n\nBertini, Kos, and Prosen (2019): dual unitarity means correlations vanish inside light cone!"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#quantinuum-experiment",
    "href": "talks/quantum-circuits-2-icts/index.html#quantinuum-experiment",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Correlations measured in SDKIM last year"
  },
  {
    "objectID": "talks/quantum-circuits-2-icts/index.html#other-applications-of-dual-unitarity",
    "href": "talks/quantum-circuits-2-icts/index.html#other-applications-of-dual-unitarity",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Claeys and Lamacraft (2020). \\(v_\\text{B}=1\\). OTOC grows at maximum speed, c.f. Google experiment\nJonay, Kehmani, Ippoliti (2021). Triunitary circuits (incl. 2+1 dimensions)\nStephen et al (2022). Measurement based quantum computation in 1D using dual unitaries\nSommers, Huse, Gullans (2022). Dual unitary Clifford automata with applications to codes\nSuzuki, Mitarai, Fujii (2022). Computational power of dual unitaries\nMany more!"
  },
  {
    "objectID": "talks/new-rules/index.html",
    "href": "talks/new-rules/index.html",
    "title": "New Rules:",
    "section": "",
    "text": "austen.uk/slides/new-rules\nAusten Lamacraft, University of Cambridge\n\n\n\n\n\n\n\n\n\n\n\n\nEach site either dead (0) or alive (1)\nFate of cell determined by eight neighbors\n\nAny live cell with two or three live neighbours survives\nAny dead cell with three live neighbours becomes a live cell\nAll other live cells die in the next generation\n\nComplex behavior!\n\n\n\n\n\n\nDynamical systems with discrete space, time, and degrees of freedom\nInteresting for statistical physics:\n\nWhat kinds of dynamics may occur?\nHow does dynamics determine thermodynamic behavior?\n\n\n\n\n\n\n\nA quantum analog of CAs\nBasis of “quantum supremacy” work by Google and others\n\n\n\n\nA schematic view of the Google Sycamore processor.\n\n\n\n\n\n\n\nWhat are the similarities and differences?\nWhen is quantum dynamics harder?\n\n\nLittle quantum computation per se, though it saturates the field\n\n\n\n\n\n\n“Space” is one dimension with cells \\(x_n=0,1\\) \\(n\\in\\mathbb{Z}\\)\nUpdate cells every time step depending on cells in neighborhood\n\nNeighborhood is cell and two neighbors for elementary CA\n\n\n\n\nUpdate specified by function\n\n\\[\nf:\\\\{0,1\\\\}^3\\longrightarrow \\\\{0,1\\\\}.\n\\]\n\\[\nx^{t+1}_{n} = f(x^{t}\\_{n-1},x^{t}\\_{n},x^{t}\\_{n+1})\n\\]\n\nHow many possible functions?\n\n\n\n\n\n\nDomain of \\(f\\) is \\(2^3=8\\) possible values for three cells\n\\(2^8=256\\) possible choices for the function \\(f\\)\nList outputs corresponding to inputs: 111, 110, … 000\n\n\n\n\n111\n110\n101\n100\n011\n010\n001\n000\n\n\n\n\n0\n1\n1\n0\n1\n1\n1\n0\n\n\n\n\nInterpret as binary number: this one is Rule 110\n\n\n\nMany behaviors, from ordered (Rule 18) to chaotic (Rule 30)\n\n\n\n\n\n\n\n\nRule 110 is capable of universal computation!\n\n\n\n\n\nThat’s Christmas sorted\n\n\n\n\n\n\n\n\n\ngive each pixel a random Pokemon type, and then battle pixels against their neighbors, updating each pixel with the winning type (using the Pokemon type chart)we quickly see areas of fire &gt; water &gt; grass &gt; fire, electric sweeping over, ground frontiers taking over etc etc pic.twitter.com/BHgQuKRApR\n\n— Matt Henderson (@matthen2) July 2, 2022\n\n\n\n\n\n\n\nNotion of a causal “light cone” (45 degree lines)\nVariety of possible behaviors: chaos, periodicity, …\n\n\n\n\n\n\nRapid growth of small differences between two trajectories\n\n\n\n\n\n\n\n\nSmallest change: flip one site and monitor \\(z^t\\equiv x^t\\oplus y^t\\)\n\n\n\n\n\n\nNo exponential growth (c.f. Lyapunov exponent in continuous systems)\nTrack number of differences (Hamming distance) between trajectories\nPropagating “front” cannot exceed “speed of light”: generally slower\n\n\n\n\n\n\nNo chance of solving the dynamics of any one CA\nLooking for generic properties: natural to consider ensembles\n\nof initial conditions\nof rules\n\n\n\n\n\n\n\nChoose rules iid for each site and instant\n\n\n\n\n\n\n\n\nCell values are now white noise\n\n\n\nFluctuations of front are larger and average speed \\(&lt;\\) maximum\nInteresting variation: choose output \\(1\\) with probability \\(p\\)\n\\(p\\neq 1/2\\) makes dynamics less one-to-one. What happens?\n\n\n\n\n\n\nFor \\(0.25\\lesssim p\\lesssim 0.75\\) front propagates to infinity\nOutside this region, front dies out\nIn finite system two copies always merge after exponentially long time\n\n\n\n\n\n\nIf inputs differ, \\(z^{t+1}_n=1\\) with probability \\(2p(1-p)\\) (Derrida and Stauffer (1986))\n\n\n\n\n\n\\(z^{t+1}\\_{n}=1\\) only if at least one of \\(z^t\\_{n\\pm 1}=1\\)\n\n\n\nSeek connected cluster of sites occupied with probability \\(x=2p(1-p)\\)\nThis is (site) directed percolation\n\\(x\\leq 1/2&lt; x_\\text{crit}\\sim 0.706\\) on square lattice: require NN neighbors\n\n\n\n\n\n\nNo elementary CAs are reversible (bijective)!\nReversibility is undecidable above one spatial dimension\n\\(∃\\) reversible constructions\n\n\n\n\n\n\n\n\n\nPartition cells into blocks (Margolus neighborhoods)\nApply invertible mapping to block\nAlternate overlapping partitions\n\n\n\n\n\n\n\n\n\nBlue squares: invertible mapping on states of two sites: 00, 01, 10, 11\n\n\n\n\n\ngiven these four jigsaw pieces, there is only one way to fill in the rest of the puzzle. The solution ends up drawing a Sierpinski triangle. Can you see why? pic.twitter.com/OvxVz2oehy\n\n— Matt Henderson (@matthen2) May 25, 2022\n\n\n\n\n\n\n\n\nEach block a permutation of 00, 01, 10, 11\n\\(4!=24\\) blocks\nOrder:\n\n\n\n\n\n\n\n(1324), and so on\n\nBlock 2 is the map \\((00, 01, 10, 11) ⟶ (00, 10, 01, 11)\\)\nExchange, or SWAP gate in quantum information\n\n\n\n\n\n\n\n\n\n\n\n\nResults qualitatively similar to chaotic phase of of PCA\nNo phase transition because all blocks are reversible\n\n\n\n\n\n\nCan we find an ensemble where front propagates at maximal speed?\nYes! Dual reversible blocks are bijections in both time and space\nThere are 12 such blocks (out of 24)\nEnsemble is Markov in time and space: must have maximal velocity!\n\n\n\n\n\n\nDisjoint regions \\(A\\) and \\(\\bar A\\): how much does one tell about the other?\nUse mutual information: measure of dependence of random variables\nSuggested in this context by Pizzi et al. (2022)\n\n\n\nMI defined as \\[\nI(X;Y) \\equiv S(X) + S(Y) - S(X,Y)\n\\]\n\n\\(S(X)\\) is entropy of \\(p_X(x)\\); marginal distribution of \\(X\\)\n\\(S(Y)\\) is entropy of \\(p_Y(y)\\); marginal distribution of \\(Y\\)\n\\(S(X,Y)\\) is entropy of joint distribution \\(p_{(X,Y)}(x,y)\\)\n\nVanishes if \\(p_{(X,Y)}(x,y)=p_X(x)p_Y(y)\\)\n\n\n\n\n\n\nSuppose either \\(X=Y=1\\) or \\(X=Y=0\\), with equal probability\n\n$$ \\begin{align} p_{(X,Y)}(0,0)&=p_{(X,Y)}(1,1)=1/2\\\\  p_{(X,Y)}(1,0)&=p_{(X,Y)}(0,1)=0 \\end{align} $$\n\\[\nI(X;Y)=S(X) + S(Y) - S(X,Y)= 1+1-1=1 \\text{ bit}\n\\]\n\n\n\n\n\n\n\n\nInitial distribution factorizes over correlated pairs\nApply SWAPs\n1 bit MI for every pair with one member in \\(A\\) and one in \\(\\bar A\\)\n\n\\[\nI(A;\\bar A) = \\min(4\\lfloor t/2\\rfloor, |A|) \\text{ bits}\n\\]\n\n\\(|A|\\) is (even) number of sites in \\(A\\)\n\n\n\n\n\n\nTotal entropy conserved (c.f Liouville’s theorem)\nEntropy of initial distribution is half max, but entropy \\(S(A)\\) saturates at maximal value (thermalization in time \\(\\sim |A|/2\\))\nThis model is not so special! Any of the dual reversible blocks CAs behaves exactly the same!\n\n\n\n\n\n\n\nCAs as dynamical systems: chaotic fronts and information dynamics\nDynamical ensembles as a theoretical tool\n\n\nHow can we extend these ideas to quantum systems?\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlock CA\nQuantum Circuit\n\n\n\n\nBasic unit\nInvertible map\nUnitary operator (gate)\n\n\nLocal variable\n\\(z_n \\in \\\\{0, 1\\\\}\\)\n\\(\\ket{\\psi_n}\\in \\mathbb{C}^2\\)\n\n\nGlobal state\n$z \\{0,1\\}^N $\n\\(\\ket{\\Psi(t)}\\in \\mathbb{C}^{2^N}\\)\n\n\nSimulation\nEasy\nHard\n\n\n\n\n\n\n\n\nModel of universal quantum computation\nExample of discrete time, many body quantum dynamics\n\n\nEveryone’s doing it!\n\n\n\n\n\n\n\\(n\\)-qubit unitary has matrix elements \\(U_{x_1\\ldots x_n,x'_1,\\ldots, x'_n}\\) in computational basis \\(\\ket{0}\\), \\(\\ket{1}\\)\nUnitarity means\n\n\\[\n\\sum\\_{x_1'\\ldots x_N'}U_{x_1\\ldots x_n,x'_1,\\ldots, x'_n} U^\\dagger\\_{x'_1\\ldots x'_n,x''_1,\\ldots, x''_n}=\\delta\\_{x_1,x_1''}\\ldots \\delta\\_{x_N,x_N''},\n\\]\n\nBut we’d like to avoid such awful looking expressions\n\n\n\n\n\n\nGeneral state of \\(N\\) qubits is\n\n$$ \\ket{\\Psi} = \\sum_{x_{1:N}\\in \\{0,1\\}^N} \\Psi_{x_1\\ldots x_N}\\ket{x_1}_1\\ket{x_2}_2\\cdots \\ket{x_N}_N $$\n\nWrite \\(\\ket{x_1}\\_1\\ket{x_2}\\_2\\cdots \\ket{x_N}\\_N =\\ket{x_1\\cdots x_N}=\\ket{x_{1:N}}\\) for brevity\nOperator on \\(N\\) qubits has matrix elements\n\n$$ \\mathcal{O}_{x_{1:N},x'_{1:N}} = \\bra{x_{1:N}}\\mathcal{O}\\ket{x'_{1:N}} $$\n\n\n\n\n\n\n\nSee Pan Zhang’s tutorial\n\n\n\n\n\n\n\n\n\n\nHave causality built in\nQuantum analog of (block) CAs\n\n\n\n\n\n\nWork in the basis \\(\\ket{00}\\), \\(\\ket{01}\\), \\(\\ket{10}\\), \\(\\ket{11}\\)\nSimplest example: SWAP gate\n\n\\[\n\\operatorname{SWAP}=\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\\\n0 & 0 & 1 & 0 \\\\\\\n0 & 1 & 0 & 0 \\\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n\\]\n\nSwitches states. Takes product state to product state\n\n\\[\n\\operatorname{SWAP}\\ket{10} = \\ket{01}\n\\]\n\n\n\n\n\\[\n\\sqrt{\\operatorname{SWAP}}=\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\\\n0 & \\frac{1}{2}(1+i) & \\frac{1}{2}(1-i) & 0 \\\\\\\n0 & \\frac{1}{2}(1-i) & \\frac{1}{2}(1+i) & 0 \\\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}.\n\\]\n\nGenerates entanglement (non product state)\n\n\\[\n\\sqrt{\\operatorname{SWAP}}\\ket{10} = \\frac{1}{2}\\left[(1+i)\\ket{10}+(1-i)\\ket{01}\\right]\n\\]\n\n\\(\\sqrt{\\operatorname{SWAP}}\\) and single qubit unitaries are universal gate set\n\n\n\n\n\n\nWe need both \\(U\\)s and \\(U^\\dagger\\)s (e.g. for \\(\\mathcal{O}(t)=U^\\dagger(t)\\mathcal{O}U(t)\\))\n\n\n\n\n\n\n\n\n\n\n\nMuch better!\n\n\n\n\n\n\n \n\n(left) Schematic view of the Google Sycamore processor (right)\n\n\n\n\n\n\n\nSampling from circuits basis of Google’s “quantum supremacy”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNormally matrix-vector multiplication is \\(O(\\operatorname{dim}^2)=2^{2N}\\)\nGates are sparse so \\(O(\\operatorname{dim})=2^{N}\\), but still exponentially hard\nFor low depth \\(T&lt;N\\) move horizontally instead\n\n\n\n\n\n\nEvaluate \\(\\bra{\\Psi}\\mathcal{O}\\ket{\\Psi}=\\bra{\\Psi_0}\\mathcal{U}^\\dagger\\mathcal{O}\\mathcal{U}\\ket{\\Psi_0}\\) for local \\(\\mathcal{O}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter folding, lines correspond to two indices / 4 dimensions\n\n\n\n\n\n\nCircle denotes \\(\\delta_{ab}\\)\n\n\n\n\n\n\n\n\n\nEmergence of “light cone”\n\n\n\n\n\n\n\n\nExpectation values in region \\(A\\) evaluated using reduced density matrix\n\n\\[\n\\rho_A = \\operatorname{tr}\\_{\\bar A}\\left[\\ket{\\Psi}\\bra{\\Psi}\\right]=\\operatorname{tr}_{\\bar A}\\left[\\mathcal{U}\\ket{\\Psi_0}\\bra{\\Psi_0}\\mathcal{U}^\\dagger\\right]\n\\]\n\n\n\n\n\n\n\n\\(\\rho_A\\) very useful for quantifying entanglement\nIf $\\ket{\\Psi} = \\ket{\\psi}_A \\otimes \\ket{\\phi}_{\\bar A}$ then \\(\\rho_A = \\ket{\\psi}_A\\bra{\\psi}_A\\)`\nAny deviation from product state leads to mixed density matrix\nQuantify by entropy of \\(\\rho_A\\) (the entanglement entropy)\n\n\\[\nS_A \\equiv -\\operatorname{tr}\\left[\\rho_A\\log \\rho_A\\right].\n\\]\n\n\n\n\n\n\n\n\nEach pair in Bell state $ \\ket{\\Phi^+}_{2n, 2n+1} = \\frac{1}{\\sqrt{2}}\\left[\\ket{0}_{2n}\\ket{0}_{2n+1}+ \\ket{1}_{2n}\\ket{1}_{2n+1}\\right] $\nReduced density matrix for one member: $\\operatorname{tr}_{2}\\left[\\ket{\\Phi^+}_{12}\\bra{\\Phi^+}_{12}\\right] = \\frac{1}{2}\\mathbb{1}_1$\nEntanglement entropy of 1 bit\n\n\n\n\n\n\nFor a Bell pair consisting of qubits at sites \\(m\\) and \\(n\\):\n\nIf \\(n\\in A\\), \\(m\\in\\bar A\\), \\(\\rho_A\\) has factor \\(\\mathbb{1}_n\\).\nIf \\(m, n\\in A\\) they contribute a factor \\(\\ket{\\Phi^+}\\_{nm}\\bra{\\Phi^+}\\_{nm}\\) (pure)\n\nOnly first case contributes to $  S_A = \\min(4\\lfloor t/2\\rfloor, |A|) \\text{ bits} $\nJust like mutual information in classical version!\n\n\n\n\n\n\nExactly the same behavior for all unitaries satisfying\n\n\n\n\n\nc.f. dual reversible CAs\nProof: apply unitary and dual unitary conditions\nConverse – maximal entanglement growth implies dual unitary gates – recently proved by Zhou and Harrow (2022)\n\n\n\n\n\n\n\\(4\\times 4\\) unitaries are 16-dimensional\nFamily of dual unitaries is 14-dimensional\nIncludes kicked Ising model at particular values of couplings\nDual unitaries not “integrable” but have enough structure to allow many calculations\n\n\n\n\n\n\nHeisenberg picture: \\(Z_n(t)=\\mathcal{U}^\\dagger(t)Z_n \\mathcal{U}(t)\\)\nMight use \\(Z_n(t)\\) to evaluate correlation \\(\\langle Z_n(t)Z_m(0) \\rangle\\)\nHow does \\(Z_n(t)\\) look?\n\n\n\n\n\n\nExpand \\(Z_n(t)\\) in products of local operators \\(X_m\\), \\(Y_m\\), \\(Z_m\\), \\(\\mathbb{1}_m\\)\nTypical term $\\sim \\mathbb{1}_1\\otimes \\cdots X_{8}\\otimes Y_{9} \\otimes Z_{10}\\cdots \\otimes\\mathbb{1}_N$\n\n\\[\nZ_n(t)= \\sum_{\\mu_{1:N}=\\\\{0,1,2,3\\\\}^N} \\mathcal{C}\\_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots\\otimes \\sigma_N^{\\mu_N},\\qquad \\sigma^\\mu = (\\mathbb{1},X,Y,Z)\n\\]\nAs time progresses two things (tend to) increase:\n\nThe number of sites \\(\\neq\\mathbb{1}\\) (known as operator spreading)\nThe number of different contributions (or operator entanglement)\n\n\n\nOperator spreading closely analogous to chaotic fronts in CAs\nIntroduce ensemble of random circuits. \\(\\mathcal{C}\\_{\\mu_{1:N}}(t)\\) become random\nFluctuating signs mean \\(\\langle Z_n(t)Z_m(0) \\rangle\\) will tend to average to zero\nc.f. a single PCA trajectory appears as white noise\n\n\n\n\n\n\\[\n\\operatorname{OTOC}_{nm}(t) \\equiv \\langle Z_n(t)Z_m(0)Z_n(t)Z_m(0)\\rangle.\n\\]\n\nIn terms of operator expansion\n\n$$ \\operatorname{OTOC}_{nm}(t)\\propto \\sum_{\\mu_{1:N}}\\mathcal{C}_{\\mu_{1:N}}^2(t)\\left[\\delta_{\\mu_m,0}+\\delta_{\\mu_m,3}-\\delta_{\\mu_m,1}-\\delta_{\\mu_m,2}\\right]. $$\n\n\\(\\operatorname{OTOC}\\_{nm}(t)\\neq 1\\) when operator \\(Z_n(t)\\) spreads from site \\(n\\) to \\(m\\)\nCharacteristic speed of propagation is “butterfly velocity” \\(v_\\text{B}\\)\nOTOC quantum analog of bitstring differences \\(z_t=x_t\\oplus y_t\\) in CAs.\n\n\n\n\n\n\n\n\nThe measured OTOC for \\(i\\operatorname{SWAP}\\) gates (top) and \\(\\sqrt{i\\operatorname{SWAP}}\\) (bottom) after averaging over single qubit gates.\n\n\n\n\n\n\n\n\\(\\overline{\\operatorname{OTOC}}\\) can be expressed as a Markov process\nEfficiently calculate using Monte Carlo simulations\n\n\nAren’t quantum computers supposed to do things that classical computers find hard?\n\n\n\nAveraging is what enables efficient classical algorithms\nFor a given circuit (no averaging), no probabilistic interpretation\n\n\n\n\n\n\nUnitary evolution not the only game in town!\nWe can also measure, which we expect to reduce entanglement\nConsider measurements with certain rate and density in space\n\n\n\n\n\n\n\\(∃\\) phase transition where entanglement vanishes at finite measurement rate (Y Li, X Chen, MPA Fisher (2019), B Skinner, J Ruhman, A Nahum (2019))\nAlternative viewpoint: an initially mixed state is purified by (strong enough) measurements (MJ Gullans, DA Huse (2020))\n\n\n\n\n\nAll states purify, but on exponentially long times below transition\n\n\n\nMeasurements purify state; analogous to non-injective rules in CA\nIt was a surprise that a mixed state survives finite measurement rate\nBut… a chaotic front survives non-injective rules (up to a point)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCellular Automata\nQuantum Circuits\n\n\n\n\nChaos diagonistic\nDifference \\(z^t=x^t\\oplus y^t\\)\nOTOC \\(\\langle Z_n(t)Z_m(0)Z_n(t)Z_m(0)\\rangle\\)\n\n\nSpread of\nMutual information\nEntanglement entropy\n\n\nTransition via\nNon-injectivity\nMeasurements\n\n\nEnsemble\nRandom maps\nRandom unitaries\n\n\n\n\nThanks to Pieter Claeys, Jonah Herzog-Arbeitman, and Sarang Gopalakrishnan for sharing their ideas\n\n\n\n\n[Links at austen.uk/slides/new-rules] - Review on random circuits Andrew Potter, Romain Vasseur (2021)\n\nTransition to chaos in CA closely linked to synchronization of extended chaotic systems"
  },
  {
    "objectID": "talks/new-rules/index.html#quantum-circuits-cellular-automata-complexity-and-chaos",
    "href": "talks/new-rules/index.html#quantum-circuits-cellular-automata-complexity-and-chaos",
    "title": "New Rules:",
    "section": "",
    "text": "austen.uk/slides/new-rules\nAusten Lamacraft, University of Cambridge\n\n\n\n\n\n\n\n\n\n\n\n\nEach site either dead (0) or alive (1)\nFate of cell determined by eight neighbors\n\nAny live cell with two or three live neighbours survives\nAny dead cell with three live neighbours becomes a live cell\nAll other live cells die in the next generation\n\nComplex behavior!\n\n\n\n\n\n\nDynamical systems with discrete space, time, and degrees of freedom\nInteresting for statistical physics:\n\nWhat kinds of dynamics may occur?\nHow does dynamics determine thermodynamic behavior?\n\n\n\n\n\n\n\nA quantum analog of CAs\nBasis of “quantum supremacy” work by Google and others\n\n\n\n\nA schematic view of the Google Sycamore processor.\n\n\n\n\n\n\n\nWhat are the similarities and differences?\nWhen is quantum dynamics harder?\n\n\nLittle quantum computation per se, though it saturates the field\n\n\n\n\n\n\n“Space” is one dimension with cells \\(x_n=0,1\\) \\(n\\in\\mathbb{Z}\\)\nUpdate cells every time step depending on cells in neighborhood\n\nNeighborhood is cell and two neighbors for elementary CA\n\n\n\n\nUpdate specified by function\n\n\\[\nf:\\\\{0,1\\\\}^3\\longrightarrow \\\\{0,1\\\\}.\n\\]\n\\[\nx^{t+1}_{n} = f(x^{t}\\_{n-1},x^{t}\\_{n},x^{t}\\_{n+1})\n\\]\n\nHow many possible functions?\n\n\n\n\n\n\nDomain of \\(f\\) is \\(2^3=8\\) possible values for three cells\n\\(2^8=256\\) possible choices for the function \\(f\\)\nList outputs corresponding to inputs: 111, 110, … 000\n\n\n\n\n111\n110\n101\n100\n011\n010\n001\n000\n\n\n\n\n0\n1\n1\n0\n1\n1\n1\n0\n\n\n\n\nInterpret as binary number: this one is Rule 110\n\n\n\nMany behaviors, from ordered (Rule 18) to chaotic (Rule 30)\n\n\n\n\n\n\n\n\nRule 110 is capable of universal computation!\n\n\n\n\n\nThat’s Christmas sorted\n\n\n\n\n\n\n\n\n\ngive each pixel a random Pokemon type, and then battle pixels against their neighbors, updating each pixel with the winning type (using the Pokemon type chart)we quickly see areas of fire &gt; water &gt; grass &gt; fire, electric sweeping over, ground frontiers taking over etc etc pic.twitter.com/BHgQuKRApR\n\n— Matt Henderson (@matthen2) July 2, 2022\n\n\n\n\n\n\n\nNotion of a causal “light cone” (45 degree lines)\nVariety of possible behaviors: chaos, periodicity, …\n\n\n\n\n\n\nRapid growth of small differences between two trajectories\n\n\n\n\n\n\n\n\nSmallest change: flip one site and monitor \\(z^t\\equiv x^t\\oplus y^t\\)\n\n\n\n\n\n\nNo exponential growth (c.f. Lyapunov exponent in continuous systems)\nTrack number of differences (Hamming distance) between trajectories\nPropagating “front” cannot exceed “speed of light”: generally slower\n\n\n\n\n\n\nNo chance of solving the dynamics of any one CA\nLooking for generic properties: natural to consider ensembles\n\nof initial conditions\nof rules\n\n\n\n\n\n\n\nChoose rules iid for each site and instant\n\n\n\n\n\n\n\n\nCell values are now white noise\n\n\n\nFluctuations of front are larger and average speed \\(&lt;\\) maximum\nInteresting variation: choose output \\(1\\) with probability \\(p\\)\n\\(p\\neq 1/2\\) makes dynamics less one-to-one. What happens?\n\n\n\n\n\n\nFor \\(0.25\\lesssim p\\lesssim 0.75\\) front propagates to infinity\nOutside this region, front dies out\nIn finite system two copies always merge after exponentially long time\n\n\n\n\n\n\nIf inputs differ, \\(z^{t+1}_n=1\\) with probability \\(2p(1-p)\\) (Derrida and Stauffer (1986))\n\n\n\n\n\n\\(z^{t+1}\\_{n}=1\\) only if at least one of \\(z^t\\_{n\\pm 1}=1\\)\n\n\n\nSeek connected cluster of sites occupied with probability \\(x=2p(1-p)\\)\nThis is (site) directed percolation\n\\(x\\leq 1/2&lt; x_\\text{crit}\\sim 0.706\\) on square lattice: require NN neighbors\n\n\n\n\n\n\nNo elementary CAs are reversible (bijective)!\nReversibility is undecidable above one spatial dimension\n\\(∃\\) reversible constructions\n\n\n\n\n\n\n\n\n\nPartition cells into blocks (Margolus neighborhoods)\nApply invertible mapping to block\nAlternate overlapping partitions\n\n\n\n\n\n\n\n\n\nBlue squares: invertible mapping on states of two sites: 00, 01, 10, 11\n\n\n\n\n\ngiven these four jigsaw pieces, there is only one way to fill in the rest of the puzzle. The solution ends up drawing a Sierpinski triangle. Can you see why? pic.twitter.com/OvxVz2oehy\n\n— Matt Henderson (@matthen2) May 25, 2022"
  },
  {
    "objectID": "talks/new-rules/index.html#reversible-models",
    "href": "talks/new-rules/index.html#reversible-models",
    "title": "New Rules:",
    "section": "",
    "text": "Each block a permutation of 00, 01, 10, 11\n\\(4!=24\\) blocks\nOrder:\n\n\n\n\n\n\n\n(1324), and so on\n\nBlock 2 is the map \\((00, 01, 10, 11) ⟶ (00, 10, 01, 11)\\)\nExchange, or SWAP gate in quantum information\n\n\n\n\n\n\n\n\n\n\n\n\nResults qualitatively similar to chaotic phase of of PCA\nNo phase transition because all blocks are reversible\n\n\n\n\n\n\nCan we find an ensemble where front propagates at maximal speed?\nYes! Dual reversible blocks are bijections in both time and space\nThere are 12 such blocks (out of 24)\nEnsemble is Markov in time and space: must have maximal velocity!\n\n\n\n\n\n\nDisjoint regions \\(A\\) and \\(\\bar A\\): how much does one tell about the other?\nUse mutual information: measure of dependence of random variables\nSuggested in this context by Pizzi et al. (2022)\n\n\n\nMI defined as \\[\nI(X;Y) \\equiv S(X) + S(Y) - S(X,Y)\n\\]\n\n\\(S(X)\\) is entropy of \\(p_X(x)\\); marginal distribution of \\(X\\)\n\\(S(Y)\\) is entropy of \\(p_Y(y)\\); marginal distribution of \\(Y\\)\n\\(S(X,Y)\\) is entropy of joint distribution \\(p_{(X,Y)}(x,y)\\)\n\nVanishes if \\(p_{(X,Y)}(x,y)=p_X(x)p_Y(y)\\)\n\n\n\n\n\n\nSuppose either \\(X=Y=1\\) or \\(X=Y=0\\), with equal probability\n\n$$ \\begin{align} p_{(X,Y)}(0,0)&=p_{(X,Y)}(1,1)=1/2\\\\  p_{(X,Y)}(1,0)&=p_{(X,Y)}(0,1)=0 \\end{align} $$\n\\[\nI(X;Y)=S(X) + S(Y) - S(X,Y)= 1+1-1=1 \\text{ bit}\n\\]\n\n\n\n\n\n\n\n\nInitial distribution factorizes over correlated pairs\nApply SWAPs\n1 bit MI for every pair with one member in \\(A\\) and one in \\(\\bar A\\)\n\n\\[\nI(A;\\bar A) = \\min(4\\lfloor t/2\\rfloor, |A|) \\text{ bits}\n\\]\n\n\\(|A|\\) is (even) number of sites in \\(A\\)\n\n\n\n\n\n\nTotal entropy conserved (c.f Liouville’s theorem)\nEntropy of initial distribution is half max, but entropy \\(S(A)\\) saturates at maximal value (thermalization in time \\(\\sim |A|/2\\))\nThis model is not so special! Any of the dual reversible blocks CAs behaves exactly the same!"
  },
  {
    "objectID": "talks/new-rules/index.html#summary-so-far",
    "href": "talks/new-rules/index.html#summary-so-far",
    "title": "New Rules:",
    "section": "",
    "text": "CAs as dynamical systems: chaotic fronts and information dynamics\nDynamical ensembles as a theoretical tool\n\n\nHow can we extend these ideas to quantum systems?\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlock CA\nQuantum Circuit\n\n\n\n\nBasic unit\nInvertible map\nUnitary operator (gate)\n\n\nLocal variable\n\\(z_n \\in \\\\{0, 1\\\\}\\)\n\\(\\ket{\\psi_n}\\in \\mathbb{C}^2\\)\n\n\nGlobal state\n$z \\{0,1\\}^N $\n\\(\\ket{\\Psi(t)}\\in \\mathbb{C}^{2^N}\\)\n\n\nSimulation\nEasy\nHard\n\n\n\n\n\n\n\n\nModel of universal quantum computation\nExample of discrete time, many body quantum dynamics\n\n\nEveryone’s doing it!\n\n\n\n\n\n\n\\(n\\)-qubit unitary has matrix elements \\(U_{x_1\\ldots x_n,x'_1,\\ldots, x'_n}\\) in computational basis \\(\\ket{0}\\), \\(\\ket{1}\\)\nUnitarity means\n\n\\[\n\\sum\\_{x_1'\\ldots x_N'}U_{x_1\\ldots x_n,x'_1,\\ldots, x'_n} U^\\dagger\\_{x'_1\\ldots x'_n,x''_1,\\ldots, x''_n}=\\delta\\_{x_1,x_1''}\\ldots \\delta\\_{x_N,x_N''},\n\\]\n\nBut we’d like to avoid such awful looking expressions\n\n\n\n\n\n\nGeneral state of \\(N\\) qubits is\n\n$$ \\ket{\\Psi} = \\sum_{x_{1:N}\\in \\{0,1\\}^N} \\Psi_{x_1\\ldots x_N}\\ket{x_1}_1\\ket{x_2}_2\\cdots \\ket{x_N}_N $$\n\nWrite \\(\\ket{x_1}\\_1\\ket{x_2}\\_2\\cdots \\ket{x_N}\\_N =\\ket{x_1\\cdots x_N}=\\ket{x_{1:N}}\\) for brevity\nOperator on \\(N\\) qubits has matrix elements\n\n$$ \\mathcal{O}_{x_{1:N},x'_{1:N}} = \\bra{x_{1:N}}\\mathcal{O}\\ket{x'_{1:N}} $$\n\n\n\n\n\n\n\nSee Pan Zhang’s tutorial\n\n\n\n\n\n\n\n\n\n\nHave causality built in\nQuantum analog of (block) CAs\n\n\n\n\n\n\nWork in the basis \\(\\ket{00}\\), \\(\\ket{01}\\), \\(\\ket{10}\\), \\(\\ket{11}\\)\nSimplest example: SWAP gate\n\n\\[\n\\operatorname{SWAP}=\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\\\n0 & 0 & 1 & 0 \\\\\\\n0 & 1 & 0 & 0 \\\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n\\]\n\nSwitches states. Takes product state to product state\n\n\\[\n\\operatorname{SWAP}\\ket{10} = \\ket{01}\n\\]\n\n\n\n\n\\[\n\\sqrt{\\operatorname{SWAP}}=\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\\\n0 & \\frac{1}{2}(1+i) & \\frac{1}{2}(1-i) & 0 \\\\\\\n0 & \\frac{1}{2}(1-i) & \\frac{1}{2}(1+i) & 0 \\\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}.\n\\]\n\nGenerates entanglement (non product state)\n\n\\[\n\\sqrt{\\operatorname{SWAP}}\\ket{10} = \\frac{1}{2}\\left[(1+i)\\ket{10}+(1-i)\\ket{01}\\right]\n\\]\n\n\\(\\sqrt{\\operatorname{SWAP}}\\) and single qubit unitaries are universal gate set\n\n\n\n\n\n\nWe need both \\(U\\)s and \\(U^\\dagger\\)s (e.g. for \\(\\mathcal{O}(t)=U^\\dagger(t)\\mathcal{O}U(t)\\))\n\n\n\n\n\n\n\n\n\n\n\nMuch better!\n\n\n\n\n\n\n \n\n(left) Schematic view of the Google Sycamore processor (right)\n\n\n\n\n\n\n\nSampling from circuits basis of Google’s “quantum supremacy”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNormally matrix-vector multiplication is \\(O(\\operatorname{dim}^2)=2^{2N}\\)\nGates are sparse so \\(O(\\operatorname{dim})=2^{N}\\), but still exponentially hard\nFor low depth \\(T&lt;N\\) move horizontally instead\n\n\n\n\n\n\nEvaluate \\(\\bra{\\Psi}\\mathcal{O}\\ket{\\Psi}=\\bra{\\Psi_0}\\mathcal{U}^\\dagger\\mathcal{O}\\mathcal{U}\\ket{\\Psi_0}\\) for local \\(\\mathcal{O}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter folding, lines correspond to two indices / 4 dimensions\n\n\n\n\n\n\nCircle denotes \\(\\delta_{ab}\\)\n\n\n\n\n\n\n\n\n\nEmergence of “light cone”\n\n\n\n\n\n\n\n\nExpectation values in region \\(A\\) evaluated using reduced density matrix\n\n\\[\n\\rho_A = \\operatorname{tr}\\_{\\bar A}\\left[\\ket{\\Psi}\\bra{\\Psi}\\right]=\\operatorname{tr}_{\\bar A}\\left[\\mathcal{U}\\ket{\\Psi_0}\\bra{\\Psi_0}\\mathcal{U}^\\dagger\\right]\n\\]\n\n\n\n\n\n\n\n\\(\\rho_A\\) very useful for quantifying entanglement\nIf $\\ket{\\Psi} = \\ket{\\psi}_A \\otimes \\ket{\\phi}_{\\bar A}$ then \\(\\rho_A = \\ket{\\psi}_A\\bra{\\psi}_A\\)`\nAny deviation from product state leads to mixed density matrix\nQuantify by entropy of \\(\\rho_A\\) (the entanglement entropy)\n\n\\[\nS_A \\equiv -\\operatorname{tr}\\left[\\rho_A\\log \\rho_A\\right].\n\\]\n\n\n\n\n\n\n\n\nEach pair in Bell state $ \\ket{\\Phi^+}_{2n, 2n+1} = \\frac{1}{\\sqrt{2}}\\left[\\ket{0}_{2n}\\ket{0}_{2n+1}+ \\ket{1}_{2n}\\ket{1}_{2n+1}\\right] $\nReduced density matrix for one member: $\\operatorname{tr}_{2}\\left[\\ket{\\Phi^+}_{12}\\bra{\\Phi^+}_{12}\\right] = \\frac{1}{2}\\mathbb{1}_1$\nEntanglement entropy of 1 bit\n\n\n\n\n\n\nFor a Bell pair consisting of qubits at sites \\(m\\) and \\(n\\):\n\nIf \\(n\\in A\\), \\(m\\in\\bar A\\), \\(\\rho_A\\) has factor \\(\\mathbb{1}_n\\).\nIf \\(m, n\\in A\\) they contribute a factor \\(\\ket{\\Phi^+}\\_{nm}\\bra{\\Phi^+}\\_{nm}\\) (pure)\n\nOnly first case contributes to $  S_A = \\min(4\\lfloor t/2\\rfloor, |A|) \\text{ bits} $\nJust like mutual information in classical version!\n\n\n\n\n\n\nExactly the same behavior for all unitaries satisfying\n\n\n\n\n\nc.f. dual reversible CAs\nProof: apply unitary and dual unitary conditions\nConverse – maximal entanglement growth implies dual unitary gates – recently proved by Zhou and Harrow (2022)\n\n\n\n\n\n\n\\(4\\times 4\\) unitaries are 16-dimensional\nFamily of dual unitaries is 14-dimensional\nIncludes kicked Ising model at particular values of couplings\nDual unitaries not “integrable” but have enough structure to allow many calculations\n\n\n\n\n\n\nHeisenberg picture: \\(Z_n(t)=\\mathcal{U}^\\dagger(t)Z_n \\mathcal{U}(t)\\)\nMight use \\(Z_n(t)\\) to evaluate correlation \\(\\langle Z_n(t)Z_m(0) \\rangle\\)\nHow does \\(Z_n(t)\\) look?\n\n\n\n\n\n\nExpand \\(Z_n(t)\\) in products of local operators \\(X_m\\), \\(Y_m\\), \\(Z_m\\), \\(\\mathbb{1}_m\\)\nTypical term $\\sim \\mathbb{1}_1\\otimes \\cdots X_{8}\\otimes Y_{9} \\otimes Z_{10}\\cdots \\otimes\\mathbb{1}_N$\n\n\\[\nZ_n(t)= \\sum_{\\mu_{1:N}=\\\\{0,1,2,3\\\\}^N} \\mathcal{C}\\_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots\\otimes \\sigma_N^{\\mu_N},\\qquad \\sigma^\\mu = (\\mathbb{1},X,Y,Z)\n\\]\nAs time progresses two things (tend to) increase:\n\nThe number of sites \\(\\neq\\mathbb{1}\\) (known as operator spreading)\nThe number of different contributions (or operator entanglement)\n\n\n\nOperator spreading closely analogous to chaotic fronts in CAs\nIntroduce ensemble of random circuits. \\(\\mathcal{C}\\_{\\mu_{1:N}}(t)\\) become random\nFluctuating signs mean \\(\\langle Z_n(t)Z_m(0) \\rangle\\) will tend to average to zero\nc.f. a single PCA trajectory appears as white noise\n\n\n\n\n\n\\[\n\\operatorname{OTOC}_{nm}(t) \\equiv \\langle Z_n(t)Z_m(0)Z_n(t)Z_m(0)\\rangle.\n\\]\n\nIn terms of operator expansion\n\n$$ \\operatorname{OTOC}_{nm}(t)\\propto \\sum_{\\mu_{1:N}}\\mathcal{C}_{\\mu_{1:N}}^2(t)\\left[\\delta_{\\mu_m,0}+\\delta_{\\mu_m,3}-\\delta_{\\mu_m,1}-\\delta_{\\mu_m,2}\\right]. $$\n\n\\(\\operatorname{OTOC}\\_{nm}(t)\\neq 1\\) when operator \\(Z_n(t)\\) spreads from site \\(n\\) to \\(m\\)\nCharacteristic speed of propagation is “butterfly velocity” \\(v_\\text{B}\\)\nOTOC quantum analog of bitstring differences \\(z_t=x_t\\oplus y_t\\) in CAs.\n\n\n\n\n\n\n\n\nThe measured OTOC for \\(i\\operatorname{SWAP}\\) gates (top) and \\(\\sqrt{i\\operatorname{SWAP}}\\) (bottom) after averaging over single qubit gates.\n\n\n\n\n\n\n\n\\(\\overline{\\operatorname{OTOC}}\\) can be expressed as a Markov process\nEfficiently calculate using Monte Carlo simulations\n\n\nAren’t quantum computers supposed to do things that classical computers find hard?\n\n\n\nAveraging is what enables efficient classical algorithms\nFor a given circuit (no averaging), no probabilistic interpretation\n\n\n\n\n\n\nUnitary evolution not the only game in town!\nWe can also measure, which we expect to reduce entanglement\nConsider measurements with certain rate and density in space\n\n\n\n\n\n\n\\(∃\\) phase transition where entanglement vanishes at finite measurement rate (Y Li, X Chen, MPA Fisher (2019), B Skinner, J Ruhman, A Nahum (2019))\nAlternative viewpoint: an initially mixed state is purified by (strong enough) measurements (MJ Gullans, DA Huse (2020))\n\n\n\n\n\nAll states purify, but on exponentially long times below transition\n\n\n\nMeasurements purify state; analogous to non-injective rules in CA\nIt was a surprise that a mixed state survives finite measurement rate\nBut… a chaotic front survives non-injective rules (up to a point)"
  },
  {
    "objectID": "talks/new-rules/index.html#summary-of-analogies",
    "href": "talks/new-rules/index.html#summary-of-analogies",
    "title": "New Rules:",
    "section": "",
    "text": "Cellular Automata\nQuantum Circuits\n\n\n\n\nChaos diagonistic\nDifference \\(z^t=x^t\\oplus y^t\\)\nOTOC \\(\\langle Z_n(t)Z_m(0)Z_n(t)Z_m(0)\\rangle\\)\n\n\nSpread of\nMutual information\nEntanglement entropy\n\n\nTransition via\nNon-injectivity\nMeasurements\n\n\nEnsemble\nRandom maps\nRandom unitaries\n\n\n\n\nThanks to Pieter Claeys, Jonah Herzog-Arbeitman, and Sarang Gopalakrishnan for sharing their ideas\n\n\n\n\n[Links at austen.uk/slides/new-rules] - Review on random circuits Andrew Potter, Romain Vasseur (2021)\n\nTransition to chaos in CA closely linked to synchronization of extended chaotic systems"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html",
    "href": "talks/rl4qm-msml/index.html",
    "title": "Austen Lamacraft",
    "section": "",
    "text": "\\[\n\\nonumber\n\\newcommand{\\br}{\\mathbf{r}}\n\\newcommand{\\bR}{\\mathbf{R}}\n\\newcommand{\\bp}{\\mathbf{p}}\n\\newcommand{\\bk}{\\mathbf{k}}\n\\newcommand{\\bq}{\\mathbf{q}}\n\\newcommand{\\bv}{\\mathbf{v}}\n\\newcommand{\\bx}{\\mathbf{x}}\n\\newcommand{\\bz}{\\mathbf{z}}\n\\DeclareMathOperator*{\\E}{\\mathbb{E}}\n\\]"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#quantum-ground-states-from-reinforcement-learning",
    "href": "talks/rl4qm-msml/index.html#quantum-ground-states-from-reinforcement-learning",
    "title": "Austen Lamacraft",
    "section": "Quantum Ground States from Reinforcement Learning",
    "text": "Quantum Ground States from Reinforcement Learning\nWork with Ariel Barr and Willem Gispen"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#schrödinger-equation-n-particles",
    "href": "talks/rl4qm-msml/index.html#schrödinger-equation-n-particles",
    "title": "Austen Lamacraft",
    "section": "Schrödinger Equation: N Particles",
    "text": "Schrödinger Equation: N Particles\n\nBasic object is wavefunction: \\(\\Psi(\\br_1,\\ldots \\br_N)\\)\n\n$$ \\overbrace{\\left[\\sum_i\\left(-\\frac{\\nabla_i^2}{2m_i}+V(\\br_i)\\right)+\\sum_{i&lt;j}U(\\br_i-\\br_j)\\right]}^{\\equiv H \\text{, Hamiltonian}}\\Psi(\\br_1,\\ldots \\br_N) = E\\Psi(\\br_1,\\ldots \\br_N) $$\n\nRequires grid in \\(3N\\) dimensions of \\(L^{3N}\\) points!\nAtoms / molecules are hard; matter (\\(N\\sim N_\\text{A}\\)) is impossible!"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#variational-principle",
    "href": "talks/rl4qm-msml/index.html#variational-principle",
    "title": "Austen Lamacraft",
    "section": "Variational Principle",
    "text": "Variational Principle\n\nFor approximate \\(\\Psi\\) can upper bound ground state \\(E_0\\)\n\n$$ \\begin{align} E_0 &\\leq \\inf_{\\lVert\\Psi\\rVert=1} \\langle \\Psi\\lvert H\\rvert\\Psi\\rangle\\\\ \\langle \\Psi\\lvert H\\rvert\\Psi\\rangle &= \\int d\\br_1\\cdots d\\br_N \\Psi^*(\\br_1,\\ldots,\\br_N)\\left[H \\Psi\\right](\\br_1,\\ldots,\\br_N) \\end{align} $$\nChallenges\n\nForm of \\(\\Psi\\)\nExpectation evaluation\nOptimization"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#form-of-psi-feature-engineering",
    "href": "talks/rl4qm-msml/index.html#form-of-psi-feature-engineering",
    "title": "Austen Lamacraft",
    "section": "Form of \\(\\Psi\\) (‘Feature Engineering’)",
    "text": "Form of \\(\\Psi\\) (‘Feature Engineering’)\nWavefunctions of restricted form\n\nFactorized, leading to Hartree–Fock method\n\n\\[\n\\Psi(\\br_1,\\ldots,\\br_N)=\\psi_1(\\br_1)\\ldots \\psi_N(\\br_N).\n\\]\n\nJastrow factors include pair correlations\n\n$$ \\Psi(\\br_1,\\ldots,\\br_N)\\to \\Psi(\\br_1,\\ldots,\\br_N)\\exp\\left(\\sum_{i&lt;j}\\phi(\\br_i-\\br_j)\\right) $$\n\nMany more…"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#expectation-evaluation",
    "href": "talks/rl4qm-msml/index.html#expectation-evaluation",
    "title": "Austen Lamacraft",
    "section": "Expectation evaluation",
    "text": "Expectation evaluation\n\\(|\\Psi(\\br_1,\\ldots,\\br_N)|^2\\) a probability distribution, so evaluate\n$$ \\frac{\\langle \\Psi\\lvert H\\rvert\\Psi\\rangle}{\\langle\\Psi \\vert\\Psi\\rangle}  =\\int d\\bR\\,|\\Psi(\\bR)|^2\\frac{\\left[H \\Psi\\right](\\bR)}{\\Psi(\\bR)} $$\nby Monte Carlo sampling. This is Variational Monte Carlo (VMC)"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#neural-approaches",
    "href": "talks/rl4qm-msml/index.html#neural-approaches",
    "title": "Austen Lamacraft",
    "section": "Neural Approaches",
    "text": "Neural Approaches\n\\(\\Psi(\\bR)\\sim \\textsf{NN}(\\bR)\\) and optimize!\n\nCarleo and Troyer (2017): lattice models (more later)\n…\nMany electrons: Han et al., Pfau et al., Herman et al. (all 2019)"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#tldr",
    "href": "talks/rl4qm-msml/index.html#tldr",
    "title": "Austen Lamacraft",
    "section": "TL;DR",
    "text": "TL;DR\n\n\\(\\exists\\) other formulations of QM including Feynman’s path integral\nLet’s learn the path integral instead!"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#outline",
    "href": "talks/rl4qm-msml/index.html#outline",
    "title": "Austen Lamacraft",
    "section": "Outline",
    "text": "Outline\n\nTheory\n\nThe path integral\nLoss\nTraining\nArchitectures\n\nExperiments\nFuture directions"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#path-integral",
    "href": "talks/rl4qm-msml/index.html#path-integral",
    "title": "Austen Lamacraft",
    "section": "Path integral",
    "text": "Path integral\n\nFor “Imaginary time” Schrödinger \\[\n\\left[-\\frac{\\nabla^2}{2m}+V(\\br_i)\\right]\\psi(\\br,t) = -\\partial_t\\psi(\\br,t)\n\\]\nFeynman–Kac formula expresses \\(\\psi(\\br,t)\\) as expectation… $$   \\psi(\\br_2,t_2) =  \\E_{\\br_t}\\left[\\exp\\left(-\\int_{t_1}^{t_2}V(\\br_t)dt\\right)\\psi(\\br_{t_1},t_1)\\right] $$\n\n…over Brownian paths with \\(\\br_{t_{2}}=\\br_{2}\\)\n\nFor \\(t\\to\\infty\\): \\(\\psi(\\br,t)\\to e^{-E_0 t}\\varphi_0(\\br)\\)\n\n\n\nPath integral Monte Carlo\n\n\n\n\n\n Ceperley, RMP (1995)"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#loss-function",
    "href": "talks/rl4qm-msml/index.html#loss-function",
    "title": "Austen Lamacraft",
    "section": "Loss function",
    "text": "Loss function\n\nFK formula defines path measure \\(\\mathbb{P}_\\text{FK}\\)\nJamison (1974): process is Markovian \\[\nd\\br_t = d\\mathbf{B}_t + \\bv(\\br_t,t)dt\n\\]\nModel drift \\(\\bv(\\br,t)\\) defines measure \\(\\mathbb{P}_\\bv\\)\n\\(D_\\text{KL}(\\mathbb{P}_\\bv\\lvert\\rvert \\mathbb{P}_\\text{FK})=\\E_{\\mathbb{P}_\\bv}\\left[\\log\\left(\\frac{d\\mathbb{P}_\\bv}{d\\mathbb{P}_\\text{FK}}\\right)\\right]\\) is our loss function\nRL / Optimal Control formulation of QM (Holland, 1977)"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#training",
    "href": "talks/rl4qm-msml/index.html#training",
    "title": "Austen Lamacraft",
    "section": "Training",
    "text": "Training\n\nRelative likelihood (Radon–Nikodym derivative; Girsanov theorem)\n\n$$   \\log\\left(\\frac{d\\mathbb{P}_{\\bv}}{d\\mathbb{P}_\\text{FK}}\\right) =\\ell_T - E_0 T+\\log\\left(\\frac{\\varphi_0(\\br_0)}{\\varphi_0(\\br_T)}\\right) $$ \\[\n   \\ell_T\\equiv \\int_0^T \\bv(\\br_t)\n  \\cdot d\\mathbf{B}_t+\\int_0^T dt\\left(\\frac{1}{2}|\\bv(\\br_t)|^2+V(\\br_t)\\right)\n\\]\n\nMonte Carlo estimate of \\(D_\\text{KL}(\\mathbb{P}_\\bv\\lvert\\rvert \\mathbb{P}_\\text{FK})=\\E_{\\mathbb{P}_\\bv}\\left[\\log\\left(\\frac{d\\mathbb{P}_\\bv}{d\\mathbb{P}_\\text{FK}}\\right)\\right]\\)\n\\(\\br^{(b)}_{t}\\) from SDE discretization. Analogous to reparameterization trick\n\\(D_\\text{KL}(\\mathbb{P}_\\bv\\lvert\\rvert \\mathbb{P}_\\text{FK})\\geq 0\\) so \\(\\E_{\\mathbb{P}_\\bv}\\left[\\ell_T\\right]\\geq E_0T\\)\n\n\n\nSuggests strategy:\n\nRepresent $\\bv_\\theta(\\br) = \\textsf{NN}_\\theta(\\br)$\nIntegrate batch of SDE trajectories\nBackprop through the (MC estimated) cost"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#architectures",
    "href": "talks/rl4qm-msml/index.html#architectures",
    "title": "Austen Lamacraft",
    "section": "Architectures",
    "text": "Architectures\n\nFor identical particles require permutation equivariance\n\n$$  \\bv_{i,\\theta}(\\br_1,\\ldots,\\br_N) = \\bv_{P(i),\\theta}(\\br_{P(1)},\\ldots,\\br_{P(N)}) $$\n\n…for any permutation \\(P\\)\n\n\nNumerous recent proposals e.g. DeepSets (Zaheer et al., 2017)"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#pairdrift",
    "href": "talks/rl4qm-msml/index.html#pairdrift",
    "title": "Austen Lamacraft",
    "section": "PairDrift",
    "text": "PairDrift\n\nSingle particle and pair features $$ \\mathbf{h}_i = \\boldsymbol{\\sigma}_1(\\mathbf{r}_i) + \\sum_j \\boldsymbol{\\pi}_1(\\mathbf{r}_i-\\mathbf{r}_j)\\qquad  \\mathbf{h}_{ij} = \\boldsymbol{\\Pi}_1(\\mathbf{r}_i-\\mathbf{r}_j). $$ \\(\\boldsymbol{\\sigma}, \\boldsymbol{\\pi}:\\mathbb{R}^d\\to \\mathbb{R}^H\\) and \\(\\boldsymbol{\\Pi}:\\mathbb{R}^d\\to \\mathbb{R}^{H\\times H}\\) NNs $$ \\tilde{\\mathbf{h}}_i = \\boldsymbol{\\sigma}_2(\\mathbf{h}_i) + \\sum_j \\boldsymbol{\\pi}_2(\\mathbf{h}_{ij})\\qquad \\tilde{\\mathbf{h}}_{ij} = \\boldsymbol{\\Pi}_2(\\mathbf{h}_{ij}). $$\nDrift function is then $$ \\bv_i = \\boldsymbol{\\sigma}_3(\\tilde{\\mathbf{h}}_i) + \\sum_j \\boldsymbol{\\pi}_3(\\tilde{\\mathbf{h}}_{ij}). $$"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#experiments",
    "href": "talks/rl4qm-msml/index.html#experiments",
    "title": "Austen Lamacraft",
    "section": "Experiments",
    "text": "Experiments\n\nHydrogen and Helium atoms\nHydrogen molecule\n2D Bosons in harmonic potential with Gaussian interactions\n\n\nSingle hidden layer (width 64 or 256)\nHardTanh activation\nNo additional use made of symmetries\n\n\nPyTorch code at  https://github.com/AustenLamacraft/QuaRL"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#helium-2-electrons",
    "href": "talks/rl4qm-msml/index.html#helium-2-electrons",
    "title": "Austen Lamacraft",
    "section": "Helium: 2 electrons",
    "text": "Helium: 2 electrons\n\\[\nH = -\\frac{\\nabla_1^2+\\nabla_2^2}{2} - \\frac{2}{|\\br_1|} - \\frac{2}{|\\br_2|} + \\frac{1}{|\\br_1-\\br_2|}\n\\]\n\nGround state spins antisymmetric; spatial wavefunction symmetric\n\\(\\varphi_0(\\br_1,\\br_2)\\) not known exactly but \\(E_0=-2.903386\\)\nKato’s cusp condition implemented with skip connections"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#hydrogen-molecule",
    "href": "talks/rl4qm-msml/index.html#hydrogen-molecule",
    "title": "Austen Lamacraft",
    "section": "Hydrogen Molecule",
    "text": "Hydrogen Molecule\n$$ H = -\\frac{\\nabla_1^2+\\nabla_2^2}{2}+ \\frac{1}{|\\br_1-\\br_2|}- \\sum_{i=1,2}\\left[\\frac{1}{|\\br_i-\\hat{\\mathbf{z}} R/2|} + \\frac{1}{|\\br_i+\\hat{\\mathbf{z}}R/2|}\\right] $$\n\nEquilibrium proton separation \\(R=1.401\\), \\(E_0= -1.174476\\)"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#atomic-molecular-results",
    "href": "talks/rl4qm-msml/index.html#atomic-molecular-results",
    "title": "Austen Lamacraft",
    "section": "Atomic / Molecular results",
    "text": "Atomic / Molecular results\n\n\n\n\n\n\n\n\n\n\nMethod\nH atom\nHe atom\nH2 molecule\nH2 molecule (R=2.8)\n\n\n\n\nNumerically exact\n-0.5\n-2.903\n-1.173\n-1.071\n\n\nHartree–Fock\nN/A\n-2.862(1.4%)\n-1.129(3.8%)\n\n\n\nOurs\n-0.497(0.6%)\n-2.898(0.2%)\n-1.169(0.3%)\n-1.068(0.3%)"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#d-gaussian-bosons",
    "href": "talks/rl4qm-msml/index.html#d-gaussian-bosons",
    "title": "Austen Lamacraft",
    "section": "2D Gaussian Bosons",
    "text": "2D Gaussian Bosons\n$$ \\begin{align} H&=\\frac{1}{2}\\sum_i \\left[-\\nabla_i^2 +\\br_i^2\\right]+\\sum_{i&lt;j}U(\\br_i-\\br_j)\\\\ U(\\br) &=\\frac{g}{\\pi s^2}e^{-\\br^2/s^2} \\end{align} $$\n\nMujal et al., PRA 2017 model for ultracold atoms\n\n\n\n\n\n\nDrift Visualization (\\(g=15\\), $s=1/2$)\n\n\n\n\n\n\nDifferences &lt;1% even with strong interaction"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#outlook",
    "href": "talks/rl4qm-msml/index.html#outlook",
    "title": "Austen Lamacraft",
    "section": "Outlook",
    "text": "Outlook\n\nExcited states; angular momentum ↔︎ non-reversible drift\nFermions? Dealing with the sign problem\nLattice models"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#next-up-lattice-models",
    "href": "talks/rl4qm-msml/index.html#next-up-lattice-models",
    "title": "Austen Lamacraft",
    "section": "Next Up: Lattice Models",
    "text": "Next Up: Lattice Models"
  },
  {
    "objectID": "talks/rl4qm-msml/index.html#xy-model",
    "href": "talks/rl4qm-msml/index.html#xy-model",
    "title": "Austen Lamacraft",
    "section": "XY model",
    "text": "XY model\n\nOn chain / square / cubic lattice\n\n$$ \\begin{align} \\partial_t \\Psi_{\\Huge\\circ\\Huge\\bullet\\Huge\\circ} &= \\Psi_{\\Huge\\bullet\\Huge\\circ\\Huge\\circ}+\\Psi_{\\Huge\\circ\\Huge\\circ\\Huge\\bullet}\\\\ &=\\overbrace{ \\Psi_{\\Huge\\bullet\\Huge\\circ\\Huge\\circ}+\\Psi_{\\Huge\\circ\\Huge\\circ\\Huge\\bullet}-2\\Psi_{\\Huge\\circ\\Huge\\bullet\\Huge\\circ}}^{\\text{master / forward eq.}} +2 \\Psi_{\\Huge\\circ\\Huge\\bullet\\Huge\\circ} \\end{align} $$\n\nc.f. imaginary time Schrödinger\n\n\\[\n  \\frac{\\partial\\psi(\\br,t)}{\\partial t} = \\left[\\frac{\\nabla^2}{2}-V(\\br_i)\\right]\\psi(\\br,t)\n\\]\n\n\\(\\exists\\) Feynamn–Kac representation!"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#outline",
    "href": "talks/planted-directed-polymer/index.html#outline",
    "title": "The Planted Directed Polymer",
    "section": "Outline",
    "text": "Outline\n\nInferring a path in a noisy image\nRelation to directed polymer\nNumerics in d=1+1\nAnalytic solution on tree"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#bayes-rule",
    "href": "talks/planted-directed-polymer/index.html#bayes-rule",
    "title": "The Planted Directed Polymer",
    "section": "Bayes’ rule",
    "text": "Bayes’ rule\n\nMeasure y, infer x based on prior p(x) and model p(y|x) \n\\begin{align*}\np(x|y) = \\frac{p(y|x)p(x)}{p(y)}\\\\\np(y) = \\int dx \\,p(y|x)p(x)\n\\end{align*}"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#inference-in-hmm",
    "href": "talks/planted-directed-polymer/index.html#inference-in-hmm",
    "title": "The Planted Directed Polymer",
    "section": "Inference in HMM",
    "text": "Inference in HMM\n\n\n\\begin{align*}\np(x_t|y_{1:t})&=\\frac{p(y_t|x_t)p(x_t|y_{1:t-1})}{p(y_t)}\\\\\n&=\\frac{p(y_t|x_t)}{p(y_t)}\\sum_{x_{t-1}}p(x_t|x_{t-1})p(x_{t-1}|y_{1:t-1})\n\\end{align*}\n\n\nSeparate update of x by p(x_t|x_{t-1}) and reweighting due to measurement outcome y_t"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#filtering-smoothing-etc.",
    "href": "talks/planted-directed-polymer/index.html#filtering-smoothing-etc.",
    "title": "The Planted Directed Polymer",
    "section": "Filtering, smoothing, etc.",
    "text": "Filtering, smoothing, etc.\n\nFiltering is estimation of current state x_t based on past history of y_{1:t} i.e. p(x_t|y_{1:t})\nSmoothing uses all measurements y_{1:T} up to some time horizon T i.e. p(x_t|y_{1:T})"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#example-kalman-filter",
    "href": "talks/planted-directed-polymer/index.html#example-kalman-filter",
    "title": "The Planted Directed Polymer",
    "section": "Example: Kalman filter",
    "text": "Example: Kalman filter\n\n\n\n\n\\begin{align*}\nx_{t} = x_{t-1} + w_t\\qquad y_{t} = x_t + v_t \\\\\nw_t\\sim \\mathcal{N}(0,\\sigma^2)\\qquad v_t\\sim\\mathcal{N}(0,\\sigma_y^2)\\\\\np(x_t|x_{t-1}, y_t) = \\frac{p(x_t|x_{t-1})p(y_t|x_t)}{p(y_t)}\n\\end{align*}\n\n\nPrediction is Gaussian!"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#image-model",
    "href": "talks/planted-directed-polymer/index.html#image-model",
    "title": "The Planted Directed Polymer",
    "section": "“Image” model",
    "text": "“Image” model\n\nTake x_t\\in \\mathbb{Z} simple random walk\n“Pixel” values \\phi_{x,t}\\sim \\mathcal{N}(\\epsilon\\delta_{x,x_t}, \\sigma^2)\nNonlinear! (c.f. Kalman)\nWhat is p(x_t|\\phi_{1:t})?"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#application-road-tracking",
    "href": "talks/planted-directed-polymer/index.html#application-road-tracking",
    "title": "The Planted Directed Polymer",
    "section": "Application: road tracking",
    "text": "Application: road tracking\n\nYuille and Coughlan (2000)\n\n\n\nOffer (2018): Phase Transition in Bayesian Tracking in Clutter"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#image-distribution",
    "href": "talks/planted-directed-polymer/index.html#image-distribution",
    "title": "The Planted Directed Polymer",
    "section": "Image distribution",
    "text": "Image distribution\n\n\\begin{align*}\np(\\varphi_t|x_t) &= \\prod_{\\xi\\in\\mathbb{Z}}\\frac{1}{\\sqrt{2\\pi \\sigma_\\varphi^2 }} \\exp\\left[-\\frac{\\left(\\varphi_{\\xi,t}-\\epsilon \\delta_{x_t,\\xi}\\right)^2}{2\\sigma_\\varphi^2}\\right]\\\\\n&= \\pi(\\varphi_t)\\prod_{\\xi\\in\\mathbb{Z}}\\exp\\left[\\frac{\\delta_{x_t,\\xi}\\left(\\epsilon\\varphi_{x,t}-\\frac{\\epsilon^2}{2}\\right)}{\\sigma_\\varphi^2}\\right]\\\\\n&= \\pi(\\varphi_t)\\exp\\left[-h(x_t,\\varphi_{x_t,t})\\right]\n\\end{align*}\n\n\n\\exp(-h(x_t,\\varphi_{x_t,t}) represents change in Gaussian measure due to presence of walker (“polymer”)"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#directed-polymer",
    "href": "talks/planted-directed-polymer/index.html#directed-polymer",
    "title": "The Planted Directed Polymer",
    "section": "Directed Polymer",
    "text": "Directed Polymer\n\nClassic problem in statistical physics of disordered systems\nWalker x_t (“polymer”) weighted by Boltzmann weight \n\\exp\\left[-\\beta\\sum_t \\varphi_{x_t,t}\\right]\n (inverse temperature \\beta)\nIid random “potential” \\varphi_{x,t}\\sim \\mathcal{N(0,\\sigma_\\varphi^2)}"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#phenomenology",
    "href": "talks/planted-directed-polymer/index.html#phenomenology",
    "title": "The Planted Directed Polymer",
    "section": "Phenomenology",
    "text": "Phenomenology\n\nHigh temperature phase (\\beta small, weak potential): random walk with wandering exponent 1/2 (x\\sim t^{1/2})\nLow temperature phase: polymer pinned by disorder\nd=1+1 always in low temperature phase. Wandering exponent z=2/3 (superdiffusion)"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#planting",
    "href": "talks/planted-directed-polymer/index.html#planting",
    "title": "The Planted Directed Polymer",
    "section": "Planting",
    "text": "Planting\n\np(\\varphi_{1:T}) determined by “ground truth”\nPlanting: generate samples by sampling x_t from prior and using observation model p(\\varphi_{1:T}|x_{1:T}) (see Zdeborová & Krzakala (2016))"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#teacher-student-setting",
    "href": "talks/planted-directed-polymer/index.html#teacher-student-setting",
    "title": "The Planted Directed Polymer",
    "section": "“Teacher-Student” setting",
    "text": "“Teacher-Student” setting\n\nSimulate “true” trajectory x^*_{1:T}; generate measurements from p(\\varphi_{t}|x_{1:T}^*); infer posterior p(x_{1:T}|\\varphi_{1:T})\n\n\n\\begin{align*}\np(X,X^*,\\Phi) &= p(X|\\Phi)p(\\Phi|X^*)p(X^*)\\\\\n&= \\frac{p(\\Phi|X)p(X)p(\\Phi|X^*)p(X^*)}{p(\\Phi)}\\\\\n\\end{align*}\n\n\nX and X^* are conditionally independent given \\Phi"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#non-optimal-case",
    "href": "talks/planted-directed-polymer/index.html#non-optimal-case",
    "title": "The Planted Directed Polymer",
    "section": "Non-optimal case",
    "text": "Non-optimal case\n\np(\\varphi_{1:T}) depends on teacher parameter \\epsilon_\\text{t}\n\n\np(\\varphi_{1:T}) = \\frac{\\pi(\\varphi_{1:T})}{\\mathcal{N}_T}\\sum_{x_{1:T}} \\exp\\left[\\sigma_\\varphi^{-2}\\sum_{t=1}^T \\left(\\epsilon_\\text{t}\\varphi_{x_t,t}-\\frac{\\epsilon_\\text{t}^2}{2}\\right)\\right]\n\n\nWhen \\epsilon_\\text{t}=0 iid disorder: directed polymer!"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#measures",
    "href": "talks/planted-directed-polymer/index.html#measures",
    "title": "The Planted Directed Polymer",
    "section": "Measures",
    "text": "Measures\n\nMean square error\n\n\n\\text{MSE}_t \\equiv \\operatorname{\\mathbb{E}}\\left[\\left(x_t-x_t^*\\right)^2\\right]\n\n\nOverlap (for discrete variables)\n\n\n\\text{O} \\equiv \\frac{1}{T}\\operatorname{\\mathbb{E}}\\left[\\sum_{t=1}^T\\delta_{x_t,x_t^*}\\right]"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#data-assimilation",
    "href": "talks/planted-directed-polymer/index.html#data-assimilation",
    "title": "The Planted Directed Polymer",
    "section": "Data Assimilation",
    "text": "Data Assimilation\n\np(x_t|x_{t-1}, y_t) = \\frac{p(x_t|x_{t-1})p(y_t|x_t)}{p(y_t)}\n\n\nApplies also to deterministic dynamics x_t = f(x_{t_1})\n\n\np(x_t|x_{t-1}) = \\begin{cases}\n1 & x_t = f(x_{t_1})\\\\\n0 & \\text{otherwise}\n\\end{cases}"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#quantum-systems",
    "href": "talks/planted-directed-polymer/index.html#quantum-systems",
    "title": "The Planted Directed Polymer",
    "section": "Quantum systems",
    "text": "Quantum systems\n\nDescribed by density matrix \\rho, playing role of p(x_t)\nUpdated after some measurement M_\\alpha\n\n\n\\rho\\longrightarrow \\frac{M_\\alpha\\rho M_\\alpha^\\dagger}{\\operatorname{tr}\\left[M_\\alpha \\rho M^\\dagger_\\alpha\\right]}\n\n\nSimilar to Bayesian update \np(x_t|x_{t-1}, y_t) = \\frac{p(x_t|x_{t-1})p(y_t|x_t)}{p(y_t)}"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#measurement-induced-phase-transition",
    "href": "talks/planted-directed-polymer/index.html#measurement-induced-phase-transition",
    "title": "The Planted Directed Polymer",
    "section": "Measurement induced phase transition",
    "text": "Measurement induced phase transition\n\nSkinner, Ruhman, Nahum (2019), Li, Chen, Fisher (2019)\n\n\n\n\nSource: Gullans and Huse (2020)"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#numerics-in-d11",
    "href": "talks/planted-directed-polymer/index.html#numerics-in-d11",
    "title": "The Planted Directed Polymer",
    "section": "Numerics in d=1+1",
    "text": "Numerics in d=1+1"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#conjectured-phase-diagram",
    "href": "talks/planted-directed-polymer/index.html#conjectured-phase-diagram",
    "title": "The Planted Directed Polymer",
    "section": "Conjectured phase diagram",
    "text": "Conjectured phase diagram"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#walking-on-a-tree-soluble-case",
    "href": "talks/planted-directed-polymer/index.html#walking-on-a-tree-soluble-case",
    "title": "The Planted Directed Polymer",
    "section": "Walking on a tree: soluble case",
    "text": "Walking on a tree: soluble case\n\n\n\nSource: Derrida and Spohn (1988)\n\n\n\nBranching number K=2 here"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#recursion-relation-for-zepsilon_textt-t",
    "href": "talks/planted-directed-polymer/index.html#recursion-relation-for-zepsilon_textt-t",
    "title": "The Planted Directed Polymer",
    "section": "Recursion relation for Z(\\epsilon_\\text{t}, t)",
    "text": "Recursion relation for Z(\\epsilon_\\text{t}, t)\n\nTree of depth t formed from K trees of depth t-1\n\n\n\n\n\nUnplanted case (\\epsilon_\\text{t}=0): K copies are iid \nZ(0, t) = \\exp(\\varphi)\\sum_{i=1}^K Z_i(0, t-1)\\qquad \\varphi \\sim\\mathcal{N}(0,\\epsilon_\\text{s}^2\\sigma_\\text{t}^2/\\sigma_\\text{s}^4)"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#continuous-time-limit",
    "href": "talks/planted-directed-polymer/index.html#continuous-time-limit",
    "title": "The Planted Directed Polymer",
    "section": "Continuous time limit",
    "text": "Continuous time limit\n\n\n\n\n\\partial_t G_{\\epsilon_{\\text{t}}}=D\\partial_x^2 G_{\\epsilon_{\\text{t}}}-v_\\epsilon\\partial_x G_{\\epsilon_{\\text{t}}} + \\lambda\\left(G_{0}-1\\right)G_{\\epsilon_{\\text{t}}}\n\n\nG_0(x,t) satisfies Fisher KPP equation\n\n\n\\partial_t G_{0}=D\\partial_x^2 G_{0}+ \\lambda\\left(G_{0}-1\\right)G_{0}"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#traveling-wave-solutions",
    "href": "talks/planted-directed-polymer/index.html#traveling-wave-solutions",
    "title": "The Planted Directed Polymer",
    "section": "Traveling wave solutions",
    "text": "Traveling wave solutions\n\nWeak planting: v_\\epsilon &lt; c_\\beta, speed of unplanted wave\n\n\n\n\n\nStep in G_{\\epsilon_T} “sticks” to step in G_{0}"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#overlap",
    "href": "talks/planted-directed-polymer/index.html#overlap",
    "title": "The Planted Directed Polymer",
    "section": "Overlap",
    "text": "Overlap\n\nZ(\\epsilon_\\text{t},t) = \\exp\\left(\\varphi+\\epsilon\\right)\\left[Z(\\epsilon_\\text{t},t-1)+\\sum_{i=1}^{K-1} Z_i(0,t-1)\\right]\n\n\nPartition function is weighted sum of contributions with different overlaps Y=\\sum_{t} \\delta_{x_t, x_t^*} \n\\begin{align*}\nZ(\\epsilon_\\text{t},t) = \\sum_{Y=1}^T e^{\\epsilon Y} Z_Y(t) \\\\\n\\langle Y\\rangle = \\frac{\\partial \\log Z(\\epsilon_\\text{t}, t)}{\\partial \\epsilon}\n\\end{align*}"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#phase-diagram",
    "href": "talks/planted-directed-polymer/index.html#phase-diagram",
    "title": "The Planted Directed Polymer",
    "section": "Phase diagram",
    "text": "Phase diagram"
  },
  {
    "objectID": "talks/planted-directed-polymer/index.html#summary",
    "href": "talks/planted-directed-polymer/index.html#summary",
    "title": "The Planted Directed Polymer",
    "section": "Summary",
    "text": "Summary\n\nInferring path from images related to directed polymer\nPhase transition in inference success, at least on tree (and perhaps d&gt;1+1?)\nRelation to data assimilation and quantum systems?"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html",
    "href": "talks/superdiffusion-kitp/index.html",
    "title": "Austen Lamacraft",
    "section": "",
    "text": "\\[\n\\nonumber\n\\newcommand{\\bra}[1]{\\langle{#1}\\rvert}\n\\newcommand{\\ket}[1]{\\lvert{#1}\\rangle}\n\\newcommand{\\braket}[2]{\\langle{#1}\\vert{#2}\\rangle}\n\\newcommand{\\br}{\\mathbf{r}}\n\\newcommand{\\bR}{\\mathbf{R}}\n\\newcommand{\\bp}{\\mathbf{p}}\n\\newcommand{\\bk}{\\mathbf{k}}\n\\newcommand{\\bq}{\\mathbf{q}}\n\\newcommand{\\bv}{\\mathbf{v}}\n\\newcommand{\\bx}{\\mathbf{x}}\n\\newcommand{\\bz}{\\mathbf{z}}\n\\DeclareMathOperator*{\\E}{\\mathbb{E}}\n\\]"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#absence-of-superdiffusion-in-certain-random-spin-models",
    "href": "talks/superdiffusion-kitp/index.html#absence-of-superdiffusion-in-certain-random-spin-models",
    "title": "Austen Lamacraft",
    "section": "Absence of superdiffusion in certain random spin models",
    "text": "Absence of superdiffusion in certain random spin models\nWork with Pieter Claeys and Jonah Herzog-Arbeitman\n\n  \n\n\n austen.uk/slides/superdiffusion-kitp/"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#embarrassingly-simple-question",
    "href": "talks/superdiffusion-kitp/index.html#embarrassingly-simple-question",
    "title": "Austen Lamacraft",
    "section": "Embarrassingly simple question",
    "text": "Embarrassingly simple question\n\nWhat is nature of spin transport in Heisenberg chain? \\[\nH = \\sum_j \\left[X_j X_{j+1}+Y_j Y_{j+1}+ Z_j Z_{j+1}\\right]\n\\]\nAll 3 components conserved\n(Naive) expectation: diffusion at \\(T&gt;0\\) (including \\(T=\\infty\\))"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#simple",
    "href": "talks/superdiffusion-kitp/index.html#simple",
    "title": "Austen Lamacraft",
    "section": "Simple?",
    "text": "Simple?\n\n\n\n\n\n\n\nExcept: nonabelian, low dimension, integrability, …"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#recent-predictions",
    "href": "talks/superdiffusion-kitp/index.html#recent-predictions",
    "title": "Austen Lamacraft",
    "section": "Recent predictions",
    "text": "Recent predictions\n\n(Very) good evidence for KPZ(ish) behavior \\(\\ell\\sim t^{2/3}\\) in integrable, nonabelian models, classical and quantum\nRecent review Bulchandani, Gopalakrishnan, Ilievski (2021)\n\n\n\nDe Nardis et al. (2020) \\(D(t)\\sim (\\log t)^{4/3}\\) in classical Heisenberg chain\n\n\n\n\n\n\nMcRoberts et al. (2021) on classical FM (blue) and AFM (orange)\n\n\n\n\n\nAt finite \\(T\\) FM looks anomalous (KPZish); AFM looks normal\n\n\n\nDe Nardis et al. (2021) \\(D(t)\\sim \\log t\\) with noisy exchange coupling"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#lack-of-theory-tools",
    "href": "talks/superdiffusion-kitp/index.html#lack-of-theory-tools",
    "title": "Austen Lamacraft",
    "section": "Lack of theory tools",
    "text": "Lack of theory tools\n\nNo integrability; “weak integrability breaking” in its infancy\nAbsence of small parameters: exchange coupling \\(J\\) is only scale"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#this-work-noisy-exchange-coupling",
    "href": "talks/superdiffusion-kitp/index.html#this-work-noisy-exchange-coupling",
    "title": "Austen Lamacraft",
    "section": "This work: noisy exchange coupling",
    "text": "This work: noisy exchange coupling\n\\[\\begin{equation}\nH = \\sum_{j,a} \\left[(J + \\xi_j(t))\\sigma^a_j \\sigma^a_{j+1}\\right]\n\\end{equation}\\]\n\nStudied numerically in De Nardis et al. (2021)\n\\(SU(2)\\) invariance but no energy conservation\nExpect (nonabelian) hydrodynamics of spin modes to play major role\nCan develop perturbation theory in \\(J\\)"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#correlation-function",
    "href": "talks/superdiffusion-kitp/index.html#correlation-function",
    "title": "Austen Lamacraft",
    "section": "Correlation function",
    "text": "Correlation function\n\nSpin-1/2 chain of \\(N\\) sites with spin \\(\\boldsymbol{\\sigma}_j=(X_j, Y_j, Z_j)\\) at site \\(j\\)\nInfinite temperature spin-spin correlator\n\n\\[\nC^{ab}_{jk}(t)\\equiv\\frac{1}{2^N}\\mathop{\\mathrm{tr}}\\left[\\sigma^a_j(0) \\sigma^b_k(t)\\right]\\qquad \\sigma^b_k(t)=\\mathcal{U}^\\dagger_t \\sigma^b_k \\mathcal{U}_t.\n\\]\n\n\\(SU(2)\\) invariance: \\(C^{ab}\\_{jk}(t)\\equiv\\delta_{ab}C_{jk}(t)\\) with \\(\\sum_{k=1}^N C_{jk}(t)=1\\)\nFrom now on fix \\(a=b=z\\)"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#expansion-in-pauli-basis",
    "href": "talks/superdiffusion-kitp/index.html#expansion-in-pauli-basis",
    "title": "Austen Lamacraft",
    "section": "Expansion in Pauli basis",
    "text": "Expansion in Pauli basis\n\\[\nZ_j(t)= \\sum_{\\mu_{1:N}=\\{0,1,2,3\\}^N} \\mathcal{C}_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots \\sigma_N^{\\mu_N},\\qquad \\sigma^\\mu = (\\mathbb{1},X,Y,Z)\n\\]\n\nWith initial condition\n\n\\[\n\\begin{equation}\n\\mathcal{C}\\_{\\mu_{1:N}}(0)=\\begin{cases}\n1 & \\mu_j=z, \\mu_k=0,\\forall k\\neq j \\\\\\\\\n0 & \\text{otherwise},\n\\end{cases}\n\\end{equation}\n\\]\n\nSpin correlation function is \\(C_{jk}(t) = \\mathcal{C}_{0\\cdots \\mu_k=z \\cdots 0}(t)\\)"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#model",
    "href": "talks/superdiffusion-kitp/index.html#model",
    "title": "Austen Lamacraft",
    "section": "Model",
    "text": "Model\n\nFluctuating exchange coupling gives stochastic Schrödinger equation\n\n\\[\\begin{equation}\\label{eq:sse}\nd\\ket{\\psi} = \\sum_j \\left[-i(J dt + \\sqrt{\\eta}dW_j)P_{j,j+1}-\\frac{\\eta}{2}dt\\right]\\ket{\\psi}.\n\\end{equation}\\]\n\n\\(P_{j,j+1}=\\frac{1}{2}\\left[1+\\sum_a \\sigma^a_j \\sigma^a_{j+1}\\right]\\) is exchange operator\n\\(W_j\\) independent Brownian motions (white noise \\(\\propto dW_j\\))\nItô stochastic differential equation: last term preserves \\(\\braket{\\psi}{\\psi}\\)"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#operator-dynamics",
    "href": "talks/superdiffusion-kitp/index.html#operator-dynamics",
    "title": "Austen Lamacraft",
    "section": "Operator dynamics",
    "text": "Operator dynamics\n\nHeisenberg equation of motion (\\(\\eta=1\\))\n\n\\[\\begin{multline}\\label{eq:hberg}\nd\\mathcal{O} = \\sum_j \\left[i\\left(J dt + dW_j\\right)\\left[P_{j,j+1},\\mathcal{O}\\right]+dt\\left(P_{j,j+1}\\mathcal{O}P_{j,j+1}-\\mathcal{O}\\right)\\right].\n\\end{multline}\\]\n\n\\(\\bar{\\mathcal{O}}\\equiv\\E \\mathcal{O}\\) obeys the (adjoint) Lindblad equation\n\n\\[\\begin{equation}\n\\frac{d\\bar{\\mathcal{O}}}{dt} = \\sum_j \\left[iJ \\left[P_{j,j+1},\\bar{\\mathcal{O}}\\right]+\\left(P_{j,j+1}\\bar{\\mathcal{O}}P_{j,j+1}-\\bar{\\mathcal{O}}\\right)\\right].\n\\label{eq:eom}\n\\end{equation}\\]"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#circuit-viewpoint",
    "href": "talks/superdiffusion-kitp/index.html#circuit-viewpoint",
    "title": "Austen Lamacraft",
    "section": "Circuit viewpoint",
    "text": "Circuit viewpoint\n\n\n\n\n\\(SU(2)\\) preserving gate\n\n\\[\nU_{j,j+1} = \\cos\\theta \\mathbb{1}_{j,j+1} - i\\sin\\theta P_{j.j+1}\n\\]"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#operator-dynamics-1",
    "href": "talks/superdiffusion-kitp/index.html#operator-dynamics-1",
    "title": "Austen Lamacraft",
    "section": "Operator Dynamics",
    "text": "Operator Dynamics\n\\[\nU_{j,j+1} = \\cos\\theta \\mathbb{1}_{j,j+1} - i\\sin\\theta P_{j.j+1}\n\\]\n\\[\\begin{multline}\n\\mathcal{O} \\longrightarrow U^\\dagger_{j,j+1}\\mathcal{O}U_{j,j+1} = \\cos^2\\theta \\\\, \\mathcal{O} + \\sin^2\\theta \\\\, P_{j.j+1}\\mathcal{O} P_{j.j+1} \\\\\\\\\n+i\\sin\\theta\\cos\\theta \\left[P_{j.j+1}, \\mathcal{O}\\right]\n\\end{multline}\\]\n\nTake distribution \\(\\theta=\\pm \\theta_0\\) with \\(p(\\theta_0)-p(-\\theta_0)\\equiv \\delta &gt; 0\\)"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#average-dynamics",
    "href": "talks/superdiffusion-kitp/index.html#average-dynamics",
    "title": "Austen Lamacraft",
    "section": "Average dynamics",
    "text": "Average dynamics\n\\[\\begin{multline}\n\\overline{U^\\dagger_{j,j+1}\\mathcal{O}U_{j,j+1}} = \\cos^2\\theta_0 \\\\, \\mathcal{O} + \\sin^2\\theta_0 \\\\, P_{j.j+1}\\mathcal{O} P_{j.j+1} \\\\\\\\\n+i\\delta \\sin\\theta_0\\cos\\theta_0 \\left[P_{j.j+1}, \\mathcal{O}\\right]\n\\end{multline}\\]\n\nInterpretation:\n\nOperators on sites \\(j\\) and \\(j+1\\) switch with probability \\(\\sin^2\\theta_0\\)\nAsymmetry \\(\\delta\\) governs strength of “quantum” dynamics\n\nTaking \\(\\theta_0=\\sqrt{dt}\\), \\(\\delta= J\\sqrt{dt}\\) gives continuous time evolution"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#back-to-continuous-time",
    "href": "talks/superdiffusion-kitp/index.html#back-to-continuous-time",
    "title": "Austen Lamacraft",
    "section": "Back to continuous time",
    "text": "Back to continuous time\n\\[\n\\frac{d\\bar{\\mathcal{O}}}{dt} = \\sum_j \\left[iJ \\left[P_{j,j+1},\\bar{\\mathcal{O}}\\right]+\\left(P_{j,j+1}\\bar{\\mathcal{O}}P_{j,j+1}-\\bar{\\mathcal{O}}\\right)\\right].\n\\]\n\n\\(J=0\\): master equation describing random adjacent transpositions\nPreserves subspaces corresponding to fixed numbers of each of the \\(\\sigma^\\mu\\): 1 operator sector, 2 operator sector, …"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#j0-1-operator-sector",
    "href": "talks/superdiffusion-kitp/index.html#j0-1-operator-sector",
    "title": "Austen Lamacraft",
    "section": "\\(J=0\\): 1 operator sector",
    "text": "\\(J=0\\): 1 operator sector\n\nWriting \\(\\mathcal{C}^a_{0\\cdots \\mu_k=a\\cdots 0}\\equiv C^a_k\\) we have equation of motion\n\n\\[\n\\partial_t C^a_k = C^a_{k+1} + C^a_{k-1} - 2 C^a_k\\equiv \\Delta_k C^a_k\n\\]\n\nDiffusion of single \\(\\sigma^a\\) (\\(\\Delta_k\\) is 1D discrete Laplacian)"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#j0-2-operator-sector",
    "href": "talks/superdiffusion-kitp/index.html#j0-2-operator-sector",
    "title": "Austen Lamacraft",
    "section": "\\(J=0\\): 2 operator sector",
    "text": "\\(J=0\\): 2 operator sector\n\n\\(C^{bc}\\_{j,k}\\equiv \\mathcal{C}\\_{0\\cdots \\mu\\_j=b\\cdots \\mu\\_k=c\\cdots 0}\\)\n\n\\[\n\\partial_t C^{xy}\\_{m,n}= \\Delta_m C^{xy}\\_{m,n}+ \\Delta_n C^{xy}\\_{m,n} + \\delta_{|m-n|-1}C^{xy}_{m,n}\n\\]\n\nLast term plus condition \\(C^{xy}_{m,m}=0\\) from hardcore condition"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#perturbation-theory",
    "href": "talks/superdiffusion-kitp/index.html#perturbation-theory",
    "title": "Austen Lamacraft",
    "section": "Perturbation theory",
    "text": "Perturbation theory\n\\[\n\\frac{d\\bar{\\mathcal{O}}}{dt} = \\sum_j \\left[iJ \\left[P_{j,j+1},\\bar{\\mathcal{O}}\\right]+\\left(P_{j,j+1}\\bar{\\mathcal{O}}P_{j,j+1}-\\bar{\\mathcal{O}}\\right)\\right].\n\\]\n\\[\\begin{align}\ni[P,\\sigma^a\\otimes 1]&=-\\epsilon^{abc}\\sigma^b\\otimes\\sigma^c\\nonumber\\\\\\\\\ni[P,1\\otimes \\sigma^a]&=\\epsilon^{abc}\\sigma^b\\otimes\\sigma^c\\nonumber\\\\\\\\\ni[P,\\sigma^a\\otimes \\sigma^b]&=\\epsilon^{abc}\\left(\\sigma^c\\otimes 1- 1\\otimes \\sigma^c\\right).\n\\label{eq:split-merge}\n\\end{align}\\]\n\nSum of first two expressions vanishes by spin conservation\nDescribe operator “splitting” (\\(1\\to 2\\)) and “merging” (\\(2\\to 1\\))."
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#equation-of-motion",
    "href": "talks/superdiffusion-kitp/index.html#equation-of-motion",
    "title": "Austen Lamacraft",
    "section": "Equation of motion",
    "text": "Equation of motion\n\nIn component form\n\n\\[\n\\begin{align}\n\\partial_t \\mathcal{C}\\_{\\mu_{1:N}} = \\sum_j \\left[J\\epsilon_{\\alpha\\beta \\mu_j \\mu_{j+1}} \\mathcal{C}\\_{\\mu_1\\cdots \\alpha\\beta \\cdots \\mu_N} + \\mathcal{C}\\_{\\mu_1\\cdots \\mu_{j+1}\\mu_j \\cdots \\mu_N} - \\mathcal{C}\\_{\\mu_1\\cdots \\mu_{j}\\mu_{j+1} \\cdots \\mu_N}\\right].\n\\end{align}\n\\]"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#simple-approximation",
    "href": "talks/superdiffusion-kitp/index.html#simple-approximation",
    "title": "Austen Lamacraft",
    "section": "Simple approximation",
    "text": "Simple approximation\n\n1 and 2 operator sectors, dropping coupling to higher sectors\n\n\\[\n\\begin{align}\n  \\partial_t C^z_n = J\\left[C^{xy}\\_{n-1,n}-C^{xy}\\_{n,n-1}-C^{xy}\\_{n,n+1}+C^{xy}\\_{n+1,n}\\right]  +\\Delta_n C^z_n,\n  \\end{align}\n\\]\n\\[\n  \\begin{align}\n  \\partial_t C^{xy}\\_{m,n}& = J \\left[\\delta_{m+1,n}\\left(C^z_m-C^z_{m+1}\\right)+\\delta_{m,n+1}\\left(C^z_{n+1}-C^z_n\\right)\\right] \\nonumber\\\\\\\\\n  &\\qquad+\\Delta_m C^{xy}\\_{m,n}+ \\Delta_n C^{xy}\\_{m,n} + \\delta_{|m-n|-1}C^{xy}\\_{m,n}\n  \\end{align}\n\\]"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#result-for-correlator",
    "href": "talks/superdiffusion-kitp/index.html#result-for-correlator",
    "title": "Austen Lamacraft",
    "section": "Result for correlator",
    "text": "Result for correlator\n\n\\(C^z(\\eta,\\omega)=\\left[i\\omega - \\Omega(\\eta)-\\Sigma(\\eta,\\omega)\\right]^{-1}\\) in terms of self-energy\n\n\n\n\n\\[\\begin{equation}\n  \\Sigma(\\eta,\\omega) =  \\frac{4J^2}{N} \\sum_{\\eta_1+\\eta_2=\\eta} \\frac{\\left[\\cos(\\eta_1)-\\cos(\\eta_2)\\right]^2}{\\Omega(\\eta_1)+\\Omega(\\eta_2)-i\\omega},\\qquad \\Omega(\\eta)\\equiv 4\\sin^2(\\eta/2)\n\\end{equation}\\]\n\nHardcore constraint plays no role due to antisymmetry of vertex"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#hydrodynamic-limit",
    "href": "talks/superdiffusion-kitp/index.html#hydrodynamic-limit",
    "title": "Austen Lamacraft",
    "section": "Hydrodynamic limit:",
    "text": "Hydrodynamic limit:\n\nFor \\(\\Omega(\\eta)\\to \\eta^2\\) and \\(\\omega=O(\\eta^2)\\)\n\n\\[\\begin{equation}\n  \\Sigma(\\eta, \\omega) = J^2\\eta^2\\left[1+\\frac{1}{2}\\sqrt{\\eta^2-2i\\omega}\\right].\n  \\label{eq:se-final-low}\n\\end{equation}\\]\n\nThe diffusion pole at \\(\\omega=-i\\eta^2\\) becomes a pair\n\\[\\begin{equation}\n  \\omega_\\pm = -i(1+J^2)\\eta^2 \\pm |\\eta|^3\\frac{J^2}{2}\\sqrt{1+2J^2} + O(\\eta^4).\n  \\label{eq:poles}\n\\end{equation}\\]\nBranch point \\(\\omega=-i\\eta^2/2\\): min. \\(\\omega(\\eta_1)+\\omega(\\eta_2)\\) when \\(\\eta_{1,2}\\to\\eta/2\\)."
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#analytic-structure",
    "href": "talks/superdiffusion-kitp/index.html#analytic-structure",
    "title": "Austen Lamacraft",
    "section": "Analytic structure",
    "text": "Analytic structure\n\nc.f. Xinyi Chen-Lin, Luca V. Delacrétaz, and Sean A. Hartnoll (2019)"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#enhanced-diffusion",
    "href": "talks/superdiffusion-kitp/index.html#enhanced-diffusion",
    "title": "Austen Lamacraft",
    "section": "Enhanced diffusion",
    "text": "Enhanced diffusion\n\\[\\begin{equation}\n    \\omega = -i(1+J^2)\\eta^2 \\pm |\\eta|^3\\frac{J^2}{2}\\sqrt{1+2J^2} + O(\\eta^4).\n\\end{equation}\\]\n\n\\(J\\) enhances ordinary diffusion\nFind transient diffusion constant using \\(D(t) = -\\frac{1}{2} \\left. \\partial_t\\partial^2_\\eta C^z(\\eta;t) \\right\\vert_{\\eta=0}\\)\n\n\\[\\begin{align}\n  D(t) = 1 + J^2 - J^2 e^{-4t}\\left[I_0(4t)+I_1(4t)\\right]\\\\ \\underset{t\\to\\infty}{\\longrightarrow}  1 + J^2 - \\frac{J^2}{\\sqrt{2\\pi t}}\n  \\end{align}\\]"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#numerics",
    "href": "talks/superdiffusion-kitp/index.html#numerics",
    "title": "Austen Lamacraft",
    "section": "Numerics",
    "text": "Numerics\n\nRepresent \\(Z_j(t)\\) using MPO and evolve using TEBD (based on TeNPy)\n$= 400$, truncation error \\(\\epsilon = 10^{−12}\\), \\(\\delta t = 10^{-2}\\)\nExact for \\(J=0\\) (\\(\\chi=2\\))"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#diffusion-constant",
    "href": "talks/superdiffusion-kitp/index.html#diffusion-constant",
    "title": "Austen Lamacraft",
    "section": "Diffusion constant",
    "text": "Diffusion constant\n\n100 spins\n\n\n\n\n\nAnalytic calculation (dashed) upper bounds \\(D(t)\\)"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#profile",
    "href": "talks/superdiffusion-kitp/index.html#profile",
    "title": "Austen Lamacraft",
    "section": "Profile",
    "text": "Profile\n\\[\\begin{equation}\n    \\omega = -i(1+J^2)\\eta^2 \\pm |\\eta|^3\\frac{J^2}{2}\\sqrt{1+2J^2} + O(\\eta^4).\n\\end{equation}\\]\n\nAssuming poles dominate profile saddle point analysis yields\n\n\\[\\begin{align}\\label{eq:saddlepointprofile}\n  C(x;t) \\propto \\exp\\left(-\\frac{x^2}{2Dt}\\right)\\exp\\left(-\\frac{J^2 \\sqrt{2J^2+1}}{2 D^3}\\frac{|x|^3}{t^2}\\right)\n  \\end{align}\\]\n\n2nd factor hints at \\(\\ell\\sim t^{2/3}\\) for KPZ!\n\n\n\n\n\n\\[\\begin{align}\n  C(x;t) \\propto \\exp\\left(-\\frac{x^2}{2Dt}\\right)\\exp\\left(-\\frac{J^2 \\sqrt{2J^2+1}}{2 D^3}\\frac{|x|^3}{t^2}\\right)\n  \\end{align}\\]"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#nonabelian-hydrodynamics",
    "href": "talks/superdiffusion-kitp/index.html#nonabelian-hydrodynamics",
    "title": "Austen Lamacraft",
    "section": "Nonabelian hydrodynamics",
    "text": "Nonabelian hydrodynamics\n\nGlorioso et al. (2020): corrections to current\n\n\\[\nJ^a = -D\\nabla s^a + \\lambda \\epsilon_{abc} s^b \\nabla s^c\n\\]\n\nImplies \\(\\sim \\lambda^2/\\sqrt{t}\\) corrections to diffusion constant\nConsistent with \\(D(t) \\underset{t\\to\\infty}{\\longrightarrow}  1 + J^2 - \\frac{J^2}{\\sqrt{2\\pi t}}\\)"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#higher-orders",
    "href": "talks/superdiffusion-kitp/index.html#higher-orders",
    "title": "Austen Lamacraft",
    "section": "Higher orders?",
    "text": "Higher orders?\n\nRecall 2nd order result\n\n\\[\\begin{equation}\n  \\Sigma(\\eta, \\omega) = J^2\\eta^2\\left[1+\\frac{1}{2}\\sqrt{\\eta^2-2i\\omega}\\right]\n\\end{equation}\\]\n\nBranch point \\(\\omega=-i\\eta^2/2\\): min. \\(\\omega(\\eta_1)+\\omega(\\eta_2)\\) when \\(\\eta_{1,2}\\to\\eta/2\\).\nOn kinematic grounds: at order \\(J^{2n}\\) branch point at \\(\\omega=-i\\eta^2/n\\): minimum \\(\\omega(\\eta_1)+\\omega(\\eta_2)+\\cdots +\\omega(\\eta_n)\\) for \\(\\eta_{1,2,\\ldots n}\\to\\eta/n\\)."
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#diffuson-cascade",
    "href": "talks/superdiffusion-kitp/index.html#diffuson-cascade",
    "title": "Austen Lamacraft",
    "section": "Diffuson cascade?",
    "text": "Diffuson cascade?\n\nLuca V. Delacrétaz (2020)\n\n\n\n\n\nContribution of \\(n\\)-diffusons is \\(\\sim n! (k\\ell_\\text{th})^{nd}\\exp\\left(-\\frac{Dk^2t}{n}\\right)\\)\nOptimal \\(n\\) gives contribution \\(\\sim \\exp\\left(-\\alpha\\sqrt{Dk^2|t|}\\right)\\)\nWould be interesting to see this in a microscopic model!"
  },
  {
    "objectID": "talks/superdiffusion-kitp/index.html#penrose-colouring",
    "href": "talks/superdiffusion-kitp/index.html#penrose-colouring",
    "title": "Austen Lamacraft",
    "section": "Penrose colouring",
    "text": "Penrose colouring\n\nRecall each vertex has \\(\\epsilon\\_{abc}\\). For planar graph this counts 3-colorings\n\n\n\n\n\n\n\n\n Biamonte and Bergholm (2017) \n\n\n\nSome graphs can’t be 3-colored\n\n\n\n\n\n\nSome non-planar graphs give zero"
  },
  {
    "objectID": "talks/dual-unitaries-pcts/index.html",
    "href": "talks/dual-unitaries-pcts/index.html",
    "title": "Quantum Circuits of Dual Unitary Gates",
    "section": "",
    "text": "\\[\n\\nonumber\n\\newcommand{\\br}{\\mathbf{r}}\n\\newcommand{\\bR}{\\mathbf{R}}\n\\newcommand{\\bp}{\\mathbf{p}}\n\\newcommand{\\bk}{\\mathbf{k}}\n\\newcommand{\\bq}{\\mathbf{q}}\n\\newcommand{\\bv}{\\mathbf{v}}\n\\newcommand{\\bx}{\\mathbf{x}}\n\\newcommand{\\bz}{\\mathbf{z}}\n\\DeclareMathOperator*{\\E}{\\mathbb{E}}\n\\]"
  },
  {
    "objectID": "talks/dual-unitaries-pcts/index.html#outline",
    "href": "talks/dual-unitaries-pcts/index.html#outline",
    "title": "Quantum Circuits of Dual Unitary Gates",
    "section": "Outline",
    "text": "Outline\n\nOrigins of dual unitarity: entanglement\nCorrelation functions\nOTOCs"
  },
  {
    "objectID": "talks/dual-unitaries-pcts/index.html#origins-of-dual-unitarity",
    "href": "talks/dual-unitaries-pcts/index.html#origins-of-dual-unitarity",
    "title": "Quantum Circuits of Dual Unitary Gates",
    "section": "Origins of dual unitarity",
    "text": "Origins of dual unitarity\n\nSarang Gopalakrishnan and AL (2019) interpreted earlier results of Bertini, Kos, Prosen PRX (2019) on the kicked Ising model in terms of dual unitarity\nSimultaneously, Bertini, Kos, Prosen PRL (2019) showed how to compute correlations for general dual unitarities\n\n\n\nKicked Ising Model\n\nTime dependent Hamiltonian with kicks at \\(t=0,1,2,\\ldots\\).\n\n$$ \\begin{aligned} H_{\\text{KIM}}(t) = H_\\text{I}[\\mathbf{h}] + \\sum_{m}\\delta(t-n)H_\\text{K}\\\\ H_\\text{I}[\\mathbf{h}]=\\sum_{j=1}^L\\left[J Z_j Z_{j+1} + h_j Z_j\\right],\\qquad H_\\text{K} &= b\\sum_{j=1}^L X_j, \\end{aligned} $$\n\n“Stroboscopic” form of \\(U(t)=\\mathcal{T}\\exp\\left[-i\\int^t H_{\\text{KIM}}(t') dt'\\right]\\)\n\n$$ \\begin{aligned}   U(n_+) = \\left[U(1_+)\\right]^n,\\qquad U(1_-) = K I_\\mathbf{h}\\\\   I_\\mathbf{h} = e^{-iH_\\text{I}[\\mathbf{h}]}, \\qquad K &= e^{-iH_\\text{K}}, \\end{aligned} $$\n\n\n\nEntanglement Growth for Self-Dual KIM\n\nBertini, Kos, Prosen (2019)\n\n\\[\n\\lim_{L\\to\\infty} S^{(n)}_A(t) =\\min(2t-2,N)\\log 2,\n\\]\n\nAny \\(h_j\\); initial \\(Z_j\\) product state\n\n\n\n\n\n\n\nEntanglement Spectrum\n\nRényi entropies depend on eigenvalues of reduced density matrix\n\n$$   S^{(n)}_A = \\frac{1}{1-n}\\log \\text{tr}\\left[\\rho^n\\right]=\\frac{1}{1-n}\\sum_\\alpha \\lambda_\\alpha^n $$\n\nFor SDKIM have \\(2^{\\min(2t-2,N)}\\) non-zero eigenvalues all equal\n\n\\[\n\\lambda_\\alpha = \\left(\\frac{1}{2}\\right)^{\\min(2t-2,N)}\n\\]\n\n\n\nKIM as a circuit\n\n\n\n$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]. \\end{aligned} $$\n\n\n\nProperties of KIM gate\n\nWhen \\(|J|=|b|=\\pi/4\\) KIM gate is dual unitary\nThis allows for simple proof of entanglement dynamics!\n\n\n Gopalakrishnan and Lamacraft (2019) \n\n\n\n\nGraphical representation of density matrix\n\n\\(\\rho(t) = U\\rho_0 U^\\dagger\\), working from middle out\n\n\n\n\n\n\nFolded picture\n\nReduced density matrix: trace over all but \\(N\\) sites (here \\(N=6\\)) \n\n\n\n\n\n\n\nUsing unitarity…\n\n\n\n\n\nGo further with dual unitarity?\n\n\n\n\n\n\n\n\nInitial conditions\n\nFor SDKIM we have in addition\n\n\n\nJust the thing for \\(\\rho_0 = \\otimes_j |Z_j\\rangle\\langle Z_j|\\)! \n\n\n\n\n…Using dual unitary gates\n\n\n\nA unitary applied to\n\n\\[\n\\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1} \\otimes\\overbrace{|Z_1\\rangle\\langle Z_1|\\otimes |Z_2\\rangle\\langle Z_2| \\cdots }^{N-2t+2 } \\otimes \\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1}\n\\]\n\n\n\nResult for RDM\n\nSpectrum of RDM same as spectrum of\n\n\\[\n\\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1} \\otimes\\overbrace{|Z_1\\rangle\\langle Z_1|\\otimes |Z_2\\rangle\\langle Z_2| \\cdots }^{N-2t-2 } \\otimes \\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1}\n\\]\n\n\\(2^{\\min(2t-2,N)}\\) non-zero eigenvalues all equal to \\(\\left(\\frac{1}{2}\\right)^{\\min(2t-2,N)}\\)\n\n\n\n\nMore general initial conditions\n\nPiroli, et al., (2020) considered 2-site MPS initial conditions that allow for solution in similar way\nFor $2t&gt;N $ result is the same: \\(\\infty\\)-temperature RDM\nAt earlier times structure of initial state important"
  },
  {
    "objectID": "talks/dual-unitaries-pcts/index.html#correlation-functions-tinfty",
    "href": "talks/dual-unitaries-pcts/index.html#correlation-functions-tinfty",
    "title": "Quantum Circuits of Dual Unitary Gates",
    "section": "Correlation functions (\\(T=\\infty\\))",
    "text": "Correlation functions (\\(T=\\infty\\))\n$$ c(x,y,t)=\\mathop{\\text{tr}}\\left[U(t)^\\dagger O(x)U(t) O(y)\\right] $$\n\n\n\n\n Chan, De Luca, Chalker (2018) \n\n\n\nUsing unitarity\n\n\n\n\n\n\n“Folded” picture\n\n\n\n\nLater operator must be in “future light cone” of earlier\n\n\n\n\nOn the light cone\n\n\n\n\n\n\nLight cone quantum channel\n\n\n\n\n$$ \\begin{align} c_\\nu^{\\alpha\\beta}(\\nu t,t) = \\frac{1}{q} {\\rm tr}\\left[\\mathcal M_{\\nu}^{2t}(a^\\beta)a^\\alpha\\right]\\\\ \\mathcal M_{+}(a) = \\frac{1}{q} {\\rm tr}_1\\left[U^\\dagger (a\\otimes\\mathbb{1}) U\\right] \\end{align} $$\n\nUnitarity means map is CPTP and unital (identity fixed)\nSee Bertini, Kos, Prosen (2019) for dual unitary case, but construction is general\n\n\n\n\n‘Typical’ correlations\n\n\n\n\nGeneric: decay governed by dominant eigenvalue of channel\nCan evaluate correlations inside light cone, just need a bigger channel (see later)!\n\n\n\n\nDual unitary case\n\nUnitarity implies future and past lightcones up and down\nDual unitarity implies future and past left and right\nConclusion: correlations only on light cone\n\n\n Bertini, Kos, Prosen (2019)"
  },
  {
    "objectID": "talks/dual-unitaries-pcts/index.html#otocs",
    "href": "talks/dual-unitaries-pcts/index.html#otocs",
    "title": "Quantum Circuits of Dual Unitary Gates",
    "section": "OTOCs",
    "text": "OTOCs\n\\[\n  C_{\\alpha \\beta}(x,t) = \\langle \\sigma_{\\alpha}(0,t) \\sigma_{\\beta}(x,0) \\sigma_{\\alpha}(0,t) \\sigma_{\\beta}(x,0) \\rangle.\n\\] - \\(C_{\\alpha \\beta}(|x|&gt;t,t)=1\\) since \\(\\left[\\sigma_{\\alpha}(0,t),\\sigma_{\\beta}(x,0)\\right]=0\\) for \\(|x|&gt;t\\)\n\nFor smaller \\(|x|\\) OTOC deviates from 1.\nLimiting value of \\(|x|/t\\) where this occurs defines butterfly velocity\nExample: random unitary circuits with local dimension \\(q\\) have \\[\nv_\\text{B} = \\frac{q^2-1}{q^2+1}\n\\] \\(v_\\text{B}\\to 1\\) as \\(q\\to\\infty\\)\n\n\n\nMaximum velocity quantum circuits\n\nWhich circuits have the largest butterfly velocity \\(v_\\text{B}=1\\)?\nNatural guess: dual-unitary circuits!\n\n\n\n\nOTOC for SDKIM\n\n\n\n\n(and no broadening)\n\n\n\n\nDerivation\n\n\n\n\n\n\nFold it up…\n\nLight cone coordinates \\(n_+ = (t+ x)/2\\), \\(n_- = (t- x+2)/2\\)\n\n\n\n\n$$ \\begin{align} C^{+}_{\\alpha \\beta }(x,t) = \\left(L(\\sigma_{\\alpha})\\right|\\left(T_{n_-}\\right)^{n_+}\\left|R^{-}(\\sigma_{\\beta})\\right), \\nonumber\\\\ \\end{align} $$\n\nThis is for \\(x-t\\) even, similar expression for \\(x-t\\) odd\n\n\n\n\nTransfer matrix\n\n\n\n\n\nUsing only unitarity\n\nFind eigenstate of transfer matrix with eigenvalue one\nShow that \\(\\lim_{m\\to \\infty} \\left(L_n(\\sigma_{\\alpha})\\right|\\left(T_n\\right)^m\\left|R^{\\pm}(\\sigma_{\\beta})\\right)  = 1\\)\n\nThis is the value outside light cone, so \\(v_\\text{B}&lt;1\\) generically\n\\(v_\\text{B}=1\\) requires additional eigenstates with eigenvalue one\n\n\n\n\nUsing dual unitarity…\n\nFind \\(n+1\\) eigenvectors with eigenvalue 1\nFor even \\(n\\), $C^{+}_{\\alpha \\beta}(x,t)$ vanishes inside light cone $$ \\begin{align} \\lim_{(x+t) \\to \\infty }C^{+}_{\\alpha \\beta}(x,t) =  \\begin{cases} -\\frac{1}{q^2-1} \\qquad &\\text{if} \\quad x=t,\\\\ 0 \\qquad &\\text{if} \\quad x \\neq t. \\end{cases} \\end{align} $$ \n\n\n\n\n\n\nFor odd \\(n\\), $C^{-}_{\\alpha \\beta}(x,t)$ can be found in terms of channel $\\mathcal M_{\\pm}(\\cdot)$ describing light cone correlator\nRange of behaviour moving inside light cone\n\n\n\n\n\n\n\nFurther special cases…\n\nIntegrable SDKIM: Exponentially many eigenvectors with eigenvalue one. OTOC immediately saturates to constant value inside light cone.\nAre all maximal velocity circuits dual unitary? No! Found a kicked XY model with \\(v_\\text{B}=1\\)"
  },
  {
    "objectID": "talks/dual-unitaries-pcts/index.html#conclusion",
    "href": "talks/dual-unitaries-pcts/index.html#conclusion",
    "title": "Quantum Circuits of Dual Unitary Gates",
    "section": "Conclusion",
    "text": "Conclusion\n\nDual unitary circuits are a big solvable family with a diverse phenomenology that includes integrable and chaotic behaviour…\n… but maybe not that diverse for such a big family! \\(v_\\text{B}=1\\) always, for example\nStill more to do: effect of measurements, coding, computational complexity…"
  },
  {
    "objectID": "posts/ml-stat-mech-1/index.html",
    "href": "posts/ml-stat-mech-1/index.html",
    "title": "Machine Learning and Statistical Mechanics I",
    "section": "",
    "text": "In these lectures we are going to explore some connections between machine learning (ML) and (classical) statistical mechanics (SM). To be precise, we are going to see how the appearance of probabilistic models with large numbers of variables in both fields means that certain theoretical concepts and tools can be applied in both. To get things going, let’s see how this probabilistic viewpoint arises in the two settings.\n\\[\n\\DeclareMathOperator*{\\E}{\\mathbb{E}}\n\\newcommand{\\cE}{\\mathcal{E}}\n\\]\n\n\nThe basic problem of SM is to describe the thermodynamic properties of a macroscopic system probabilistically in terms its microscopic constituents.\n\n\n\n\n\n\nNote\n\n\n\nNote that we say probabilistically, not statistically. What’s the difference? In probability we have a definite model for randomness in mind (the Boltzmann distribution, say), whereas in statistics we are interested in inferring these probabilities from observation. Statistics is thus inverse probability, and statistical mechanics is really a misnomer.\n\n\nThe probabilistic model is normally the Boltzmann distribution\n\\[\np(\\mathbf{x})=\\frac{\\exp\\left[-\\beta \\mathcal{E}(\\mathbf{x})\\right]}{Z},\n\\]\nwhere \\(Z\\) is a normalizing constant called the partition function, \\(\\mathcal{E}(\\mathbf{x})\\) is the energy of the configuration \\(\\mathbf{x}\\), and \\(\\beta=1/T\\) is the inverse temperature (setting the Boltzmann constant \\(k_\\text{B}=1\\)).\nThe central problem of statistical mechanics is computing ensemble averages of physical quantities, and the principle difficulty is the intractability of those averages for large systems. For example, if we are dealing with a classical gas, the configuration space point \\(\\mathbf{x}\\) corresponds to the positions of each of the gas molecules \\(\\mathbf{x}=(\\mathbf{x}_1,\\ldots \\mathbf{x}_N)\\) and an average is a \\(3N\\)-dimensional integral. The only situation in which this integral is tractable is when the gas is noninteracting (ideal), in which case the energy function takes the form\n\\[\n\\mathcal{E}(\\mathbf{x}) = \\sum_{n=1}^N \\mathcal{E}_1(\\mathbf{x}_n)\n\\]\nwhere \\(\\mathcal{E}_1(\\mathbf{x})\\) is the single particle energy. In this case the integral factorizes. As soon as we introduce interactions between particles of the form\n\\[\n\\mathcal{E}(\\mathbf{x}) = \\sum_{n&lt;m}^N \\mathcal{E}_2(\\mathbf{x}_n,\\mathbf{x}_m)\n\\]\nthings get a lot harder. The same issue arises in models involving discrete random variables. The canonical example is the Ising model, in which a configuration corresponds to fixing the values of \\(N\\) “spins” \\(\\sigma_n=\\pm 1\\) with an energy function of the form\n\\[\n\\mathcal{E}(\\sigma)=\\sum_n h_n\\sigma_n + \\sum_{n,m} J_{mn}\\sigma_m\\sigma_n.\n\\]\nThe two terms correspond to a (magnetic) field that acts on each spin and a coupling between spins. As in the gas, it’s the latter that causes problems / interest.\nThe Ising model comes in a great many flavours according to how the fields and couplings are chosen. They may reflect a lattice structure: \\(J_{mn}\\neq 0\\) for nearest neighbours, say, or longer range. They may be fixed or random, defining an ensemble of models. You’ve probably seen lots of examples already.\nThe most pessimistic assessment is that to calculate an average we are going to have sum over \\(2^N\\) configurations. You probably know, however, that over the years physicists have developed lots of methods to solve the problem approximately, including mean field theory and Monte Carlo simulations. We’ll return to this stuff later.\nIf you ever find yourself talking to a probabilist, you may find it helpful to know that these kind of models are called (undirected) graphical models, because their probability distribution is defined by a graph, called a factor graph.\n\n\n\nWhat about ML? Let’s take computer vision, one of the problems in which ML has made great progress in recent years. A (static) image is defined by a set of \\((R,G,B)\\) values at each pixel, each defined by eight bits i.e. an integer in \\([0,255]\\). The basic hypothesis on which probabilistic machine learning rests is that a dataset represents a set of independent and identically distributed (iid) samples of some random variables. In the case of an image, the random variables are the RGB values of all the pixels. The distribution of these variables has to be highly correlated and have a great deal of complex structure: rather than generating white noise for each sample we instead get (say) cats and dogs.\nWhile this may seem like a funny way of thinking about a stack of photos it does conceptually have a lot in common with the way probability is often used in physics. After all, classical statistical mechanics is built on the notion that the motion of gas molecules is completely deterministic but incredibly complicated. While detailed knowledge of the dynamics is completely beyond our reach it is also irrelevant for the thermodynamic behaviour of interest: two boxes of gas behave in exactly the same way despite the underlying configurations of the molecules being completely different. Physics is used, however, to constrain our probability model. For example, collisions between molecules are elastic and momentum conserving.\nThe difference from the SM situation is that we don’t know the probability distribution up front. The goal is to infer the distribution from data. Conceptually then, probabilistic ML is the same as statistical inference. The different terms mostly reflect the differing background of practitioners: ML comes from computer science; statistical inference from mathematics. It all comes down to the tools you use: in recent years probabilistic ML has made great strides using models based on neural networks together with the associated training algorithms, which have allowed very rich probability distributions, describing datasets of images or audio signals, to be successfully modelled."
  },
  {
    "objectID": "posts/ml-stat-mech-1/index.html#probability-in-statistical-mechanics",
    "href": "posts/ml-stat-mech-1/index.html#probability-in-statistical-mechanics",
    "title": "Machine Learning and Statistical Mechanics I",
    "section": "",
    "text": "The basic problem of SM is to describe the thermodynamic properties of a macroscopic system probabilistically in terms its microscopic constituents.\n\n\n\n\n\n\nNote\n\n\n\nNote that we say probabilistically, not statistically. What’s the difference? In probability we have a definite model for randomness in mind (the Boltzmann distribution, say), whereas in statistics we are interested in inferring these probabilities from observation. Statistics is thus inverse probability, and statistical mechanics is really a misnomer.\n\n\nThe probabilistic model is normally the Boltzmann distribution\n\\[\np(\\mathbf{x})=\\frac{\\exp\\left[-\\beta \\mathcal{E}(\\mathbf{x})\\right]}{Z},\n\\]\nwhere \\(Z\\) is a normalizing constant called the partition function, \\(\\mathcal{E}(\\mathbf{x})\\) is the energy of the configuration \\(\\mathbf{x}\\), and \\(\\beta=1/T\\) is the inverse temperature (setting the Boltzmann constant \\(k_\\text{B}=1\\)).\nThe central problem of statistical mechanics is computing ensemble averages of physical quantities, and the principle difficulty is the intractability of those averages for large systems. For example, if we are dealing with a classical gas, the configuration space point \\(\\mathbf{x}\\) corresponds to the positions of each of the gas molecules \\(\\mathbf{x}=(\\mathbf{x}_1,\\ldots \\mathbf{x}_N)\\) and an average is a \\(3N\\)-dimensional integral. The only situation in which this integral is tractable is when the gas is noninteracting (ideal), in which case the energy function takes the form\n\\[\n\\mathcal{E}(\\mathbf{x}) = \\sum_{n=1}^N \\mathcal{E}_1(\\mathbf{x}_n)\n\\]\nwhere \\(\\mathcal{E}_1(\\mathbf{x})\\) is the single particle energy. In this case the integral factorizes. As soon as we introduce interactions between particles of the form\n\\[\n\\mathcal{E}(\\mathbf{x}) = \\sum_{n&lt;m}^N \\mathcal{E}_2(\\mathbf{x}_n,\\mathbf{x}_m)\n\\]\nthings get a lot harder. The same issue arises in models involving discrete random variables. The canonical example is the Ising model, in which a configuration corresponds to fixing the values of \\(N\\) “spins” \\(\\sigma_n=\\pm 1\\) with an energy function of the form\n\\[\n\\mathcal{E}(\\sigma)=\\sum_n h_n\\sigma_n + \\sum_{n,m} J_{mn}\\sigma_m\\sigma_n.\n\\]\nThe two terms correspond to a (magnetic) field that acts on each spin and a coupling between spins. As in the gas, it’s the latter that causes problems / interest.\nThe Ising model comes in a great many flavours according to how the fields and couplings are chosen. They may reflect a lattice structure: \\(J_{mn}\\neq 0\\) for nearest neighbours, say, or longer range. They may be fixed or random, defining an ensemble of models. You’ve probably seen lots of examples already.\nThe most pessimistic assessment is that to calculate an average we are going to have sum over \\(2^N\\) configurations. You probably know, however, that over the years physicists have developed lots of methods to solve the problem approximately, including mean field theory and Monte Carlo simulations. We’ll return to this stuff later.\nIf you ever find yourself talking to a probabilist, you may find it helpful to know that these kind of models are called (undirected) graphical models, because their probability distribution is defined by a graph, called a factor graph."
  },
  {
    "objectID": "posts/ml-stat-mech-1/index.html#probability-in-machine-learning",
    "href": "posts/ml-stat-mech-1/index.html#probability-in-machine-learning",
    "title": "Machine Learning and Statistical Mechanics I",
    "section": "",
    "text": "What about ML? Let’s take computer vision, one of the problems in which ML has made great progress in recent years. A (static) image is defined by a set of \\((R,G,B)\\) values at each pixel, each defined by eight bits i.e. an integer in \\([0,255]\\). The basic hypothesis on which probabilistic machine learning rests is that a dataset represents a set of independent and identically distributed (iid) samples of some random variables. In the case of an image, the random variables are the RGB values of all the pixels. The distribution of these variables has to be highly correlated and have a great deal of complex structure: rather than generating white noise for each sample we instead get (say) cats and dogs.\nWhile this may seem like a funny way of thinking about a stack of photos it does conceptually have a lot in common with the way probability is often used in physics. After all, classical statistical mechanics is built on the notion that the motion of gas molecules is completely deterministic but incredibly complicated. While detailed knowledge of the dynamics is completely beyond our reach it is also irrelevant for the thermodynamic behaviour of interest: two boxes of gas behave in exactly the same way despite the underlying configurations of the molecules being completely different. Physics is used, however, to constrain our probability model. For example, collisions between molecules are elastic and momentum conserving.\nThe difference from the SM situation is that we don’t know the probability distribution up front. The goal is to infer the distribution from data. Conceptually then, probabilistic ML is the same as statistical inference. The different terms mostly reflect the differing background of practitioners: ML comes from computer science; statistical inference from mathematics. It all comes down to the tools you use: in recent years probabilistic ML has made great strides using models based on neural networks together with the associated training algorithms, which have allowed very rich probability distributions, describing datasets of images or audio signals, to be successfully modelled."
  },
  {
    "objectID": "posts/ml-stat-mech-1/index.html#some-mathematical-background",
    "href": "posts/ml-stat-mech-1/index.html#some-mathematical-background",
    "title": "Machine Learning and Statistical Mechanics I",
    "section": "Some mathematical background",
    "text": "Some mathematical background\n\nProbabilities: joint and conditional\nProbabilities are real positive numbers \\(p(x)\\geq 0\\) satisfying\n\\[\n\\sum_x p(x)=1\n\\]\nFor continuous variables we have an integral of a probability density function\n\\[\n\\int p(x) dx=1,\n\\]\nbut for brevity we’ll use the discrete notation throughout.\nJoint probability distributions of several variables are denoted \\(p(x_1,\\ldots x_N)\\). By summing over some subset of the variables, we arrive at a marginal distribution of the remaining variables:\n\\[\np(x)= \\sum_{y} p(x,y).\n\\]\nA related notion is the conditional probability \\(p(x|y)\\): the probability distribution of \\(x\\) given a fixed value of random variable \\(y\\). The relation between joint and conditional probabilities is\n\\[\np(x,y)=p(x|y)p(y)\n\\tag{1}\n\\label{eq:joint}\n\\]\n\n\n\n\n\n\nNote\n\n\n\nWe should write \\(p_X(x)\\) for the distribution of random variable \\(X\\) and \\(p_Y(y)\\) for random variable \\(Y\\). Instead, we just let the name of the argument tell us it’s a different distribution. Everyone does this.\n\n\nFor a joint probability of many variables, we have\n\\[\np(x_1,\\ldots x_N)=p(x_1)p(x_2|x_1)p(x_3|x_2,x_1)\\cdots p(x_N|x_1,\\ldots x_{N-1}),\n\\tag{2}\n\\label{eq:chain}\n\\]\nwhich is sometimes called the chain rule of probability. Although it’s always possible in principle to express a joint probability like this, there’s no guarantee it’s easy to do or useful. One situation in which one may expect it to be a convenient description is when there is a natural order to the variables. For example, words or characters in text or any kind of time series. In this case the model may still be useful if the conditional probabilities involve only a fixed number \\(p\\) of the preceding variables, even as \\(N\\to\\infty\\). Such models are called autoregressive, although a physicist may be tempted to call them causal.\nSampling from a highly complex joint distribution \\(p(x_1,\\ldots x_N)\\) is generally difficult. One of the benefits of formulating a model as in \\(\\eqref{eq:chain}\\) is that producing samples is much easier. First you sample \\(x_1\\) using \\(p(\\cdot)\\), then sample \\(x_2\\) using \\(p(\\cdot|x_1)\\), and so on. You never have to sample more than one variable at once!\n\n\nPriors and posteriors\nAnother way to express the joint probability \\(\\eqref{eq:joint}\\) is\n\\[\np(x,y)=p(y|x)p(x)\n\\]\nWe deduce Bayes’ theorem\n\\[\np(y|x)=\\frac{p(x|y)p(y)}{p(x)}\n\\]\nNote that if we are dealing with continuous variables, any change in dimensions in going from a distribution over \\(x\\) to a distribution over \\(y\\) is handled by the ratio \\(p(y)/p(x)\\).\nBayes’ theorem is the workhorse of Bayesian statistics. The idea to to regard any parameters \\(z\\) in your probability model as random variables taken from some initial distribution \\(p(z)\\), called the prior distribution (or just the prior).\n\nExample: if your model distribution is a Gaussian normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), then your parameters are \\(z=(\\mu,\\sigma^2)\\). For a prior you could choose a normal distribution for \\(\\mu\\) with its own mean \\(\\mu_\\mu\\) and variance \\(\\sigma^2_\\mu\\) (we write \\(\\mu\\sim \\mathcal{N}(\\mu_\\mu,\\sigma^2_\\mu))\\). For \\(\\sigma^2\\) you’d need a distribution of a positive quantity: the inverse gamma distribution is a popular choice.\n\nOnce these parameters are fixed, you have a model distribution for your data that can be thought of as the conditional distribution \\(p(x|z)\\). What does an observation of \\(x\\) tell me? Just use Bayes:\n\\[\np(z|x) = \\frac{p(x|z)p(z)}{p(x)}.\n\\]\nThis is called the posterior distribution (or just posterior). Note that the denominator doesn’t depend on \\(z\\), it just provides a normalization. If you have lots of data points then\n\\[\np(z|x_1,\\ldots x_N) \\propto  p(x_1,\\ldots x_N|z)p(z).\n\\]\nBayes’ theorem lets us update our beliefs about parameters based on our initial beliefs and any evidence we receive. This process is called inference.\n\n{{&lt; tweet 1325474361407660034 &gt;}}\n\n\n\nLatent variables; generative models\nBayesian inference also underlies models involving latent (or hidden, or unobserved) variables. The idea here is that instead of the data telling us about the distribution of \\(z\\)s whose values may describe the entire dataset i.e. \\(p(x_1,\\ldots x_N|z)\\), we allow the \\(z\\)s to have different distributions for different data points \\(p(z_n|x_n)\\). Equivalently, our model is defined by a joint distribution \\(p(x,z)\\).\nThe simplest example of a latent variable model is a mixture model, which describes a distribution of a variable \\(x\\) as arising from \\(M\\) different components, each with their own distribution \\(p(x|m)\\) and occurring with probability \\(p(m)\\), so that\n\\[\np(x) = \\sum_m p(m)p(x|m).\n\\]\nAn observation \\(x\\) will give me information about \\(p(m|x)\\), telling which of the \\(M\\) components that observation belongs to. This may bring insight, if the latent variables lend themselves to interpretation. Alternatively, it may simply give a more powerful model.\nLatent variables are a route to perform structure learning: uncovering meaningful structures in the data. A lot of effort has gone into trying to build models that “discover” such structures automatically. For example, for a dataset of images of people walking we’d like to find latent variables parameterize a manifold of different poses.\nLatent variable models are also the basis of generative modelling: sampling from a distribution \\(p(x)\\) learnt from data. If the model has been formulated in terms of a prior \\(p(z)\\) over latent variables and a generative model \\(p(x|z)\\), sampling is straightforward in principle.\n\n\nEntropy\nIn SM we’re familiar with the entropy associated with a probability distribution. This quantity arrived in ML from information theory and is given the symbol \\(H\\) (for Hartley?)\n\\[\nH[p]=- \\sum_x p(x)\\log_2p(x).\n\\]\nTaking the logarithm base 2 means we measure in bits (the natural logarithm that is normally used for the Gibbs entropy is measured in “nats”). In the following we’ll normally drop the base.\nThere are lots of ways to think about the entropy so I’ll just describe one that’s quite useful in our setting.  Suppose we have \\(N\\) iid variables with distribution \\(p(x)\\). The probability of observing a sequence \\(x_1,\\ldots x_N\\) is\n\\[\n\\begin{equation}\np(x_1,\\ldots x_N)=\\prod_{n=1}^N p(x_n).\n\\end{equation}\n\\tag{3}\n\\label{eq:seq}\n\\]\nThis probability is obviously exponentially small as \\(N\\to\\infty\\), but how small? The answer is\n\\[\n\\lim_{N\\to\\infty} \\frac{1}{N}\\log p(x_1,\\ldots x_N) = -H[p].\n\\]\nThis is called the asymptotic partition property. It probably looks a bit strange. Shouldn’t the probability depend on what you actually get? After all, some outcomes are more likely than others. Suppose you have a biased coin that gives heads with probability \\(p_H&gt;0.5\\) and tails with probability \\(p_T=1-p_H\\). In a very long sequence of tosses the chance of getting half heads and half tails becomes exponentially small. What you’re going to get instead is\n\\[\n\\frac{N_H}{N}\\to p_H\\qquad \\frac{N_T}{N}\\to p_T\\qquad .\n\\]\nWhat is the probability of such a sequence? From \\(\\eqref{eq:seq}\\) it is \\(p_H^{N_H}p_T^{N_T}\\), but this can be rewritten\n\\[\n\\log_2\\left(p_H^{N_H}p_T^{N_T}\\right)= N_H\\log_2 p_H + N_T\\log_2 p_T = -N H[p_H, p_T].\n\\]\n\n\nEntropy and information\nThis property of entropy provides a way to quantify the amount of information in a signal. If the coin is really biased, returning a head almost every time, you won’t be surprised when you get heads, but will be surprised when you get tails. Note that the entropy of such a sequence is lower than for a fair coin, which has the maximum entropy \\(H=1\\) . If you wanted to describe such sequence, like\n\nHHHHHHHHHHHHHHHHHHHHHTHHHHHHHHHHHHHTHHHHT\n\nyou might find yourself saying something like “21 H, 13 H, 4 H”, with the understanding that between each string of heads there’s one tail. Such a description is shorter than the original sequence, which is possible because of the high degree of predictability. This isn’t a like for like comparison, however, because we’ve introduced extra symbols including the digits 0-9 and some delimiter like the comma. We should instead compare with a binary code of only two symbols. How can we exploit the lower entropy of the sequence to come up with an encoding that is better than the “literal” one? One (not very practical) way is to use the fact that we expect \\(N_H=Np_H\\) heads and \\(N_T=N p_T\\) tails, so we can just give the ordering of these heads and tails, which is one of\n\\[\n\\frac{N!}{N_H! N_T!}\n\\]\npossibilities. If we label each of these with a binary number, we end up with a description of length\n\\[\n\\log_2\\left(\\frac{N!}{N_H! N_T!}\\right)\\sim N H[p]\\leq N\n\\]\n(where we used Stirling’s approximation \\(\\log n! \\sim n\\log n -n\\)). Now of course, we are unlikely to get exactly this number of heads and tails, but correcting for this requires a number of bits that can be neglected in the large \\(N\\) limit (i.e. it is \\(o(N)\\)).\nThis example is the simplest illustration of Shannon’s source coding theorem:\n\nN i.i.d. random variables each with entropy H(X) can be compressed into more than N H(X) bits with negligible risk of information loss, as N → ∞; but conversely, if they are compressed into fewer than N H(X) bits it is virtually certain that information will be lost.\n\nShannon’s theorem is the core idea that underlies (lossless) data compression: the more predictable a signal (i.e. the lower the entropy) the more it can be compressed, with the entropy setting a fundamental limit on the number of bits required.\nHow is this idea applied in the real world? It’s probably clear that real binary data doesn’t have a preponderance of 1s or 0s, that would obviously be inefficient. It all hinges on what you regard as your iid random variables. For example, text consists of strings of characters, of which there are 143,859 in the Unicode standard, including scripts from different languages and Screaming Cat 🙀. These obviously don’t occur with the same frequency, so the entropy is going to be much less than \\(\\log_2(143859)\\approx 17.1\\) bits per character. Very roughly, a compression scheme involves choosing short codewords for common characters and long codewords for rare characters. Immediately you’ll notice there’s an issue in deciding where one character ends and the next begins. If you’re interested in how this works in practice, see Huffman coding, arithmetic coding, and asymmetric numeral systems, or the book Understanding Compression.\nThe bigger issue, however, is that text doesn’t consists of iid characters, even if drawn with the right frequencies. A Markov model would be the natural next step, in which the probability of each character is conditional on the preceding character: \\(p(x_{n+1}|x_{n})\\). You’re likely (in English) to encounter a u after a q, for instance. Next you can go to a “second order” Markov model, with \\(p(x_{n+1}|x_{n}, x_{n-1})\\), and so on. Shannon’s original paper is wonderfully clear and provides examples of experiments on these models. He calls the character frequency model “first order” and the Markov model “second order”.\nWhat really matters, then, is how good your model is. Suppose you want to compress data that consists of (unrelated) images. Each image is described by the RGB values of all the pixels: we’ll denote these values collectively by \\(\\mathbf{x}\\). If you choose your encoding according to some model probabilities \\(p_\\text{M}(\\mathbf{x})\\), the encoding of image \\(\\mathbf{x}\\) will have length \\(-\\log_2\\left[p_\\text{M}(\\mathbf{x})\\right]\\) bits. When you encode your data you get on average\n\\[\n-\\frac{1}{N}\\sum_{\\mathbf{x}} \\log_2\\left[p_\\text{M}(\\mathbf{x})\\right] = -\\sum_{\\mathbf{x}} p_\\text{D}(\\mathbf{x})\\log_2\\left[p_\\text{M}(\\mathbf{x})\\right]\n\\]\nbits per image, where \\(p_\\text{D}(\\mathbf{x})\\) is the empirical distribution of the data. The quantity on the RHS is called the cross entropy (or relative entropy) \\(H(p_\\text{D}, p_\\text{M})\\). As we’ll see in the next section, it has the key property that is it bounded from below by the entropy \\(H(p_\\text{D})\\)\n\\[\nH(p_\\text{D}, p_\\text{M})\\geq H(p_\\text{D}).\n\\]\nThe trade-off, then, is\n\nBy considering bigger chunks of data you approach closer to the iid situation to which Shannon’s theorem applies, but\nThese big chunks (images in our example) will have correspondingly more complicated distributions \\(p_\\text{D}\\), which your model \\(p_\\text{M}\\) will have to match if you want to approach optimal encoding.\n\n\n\nDivergences\nThe above discussion should make it clear that we need some way of talking about the degree to which two distributions differ. The most common measure in use in ML is the Kullback–Leibler divergence (KL)\n\\[\nD_\\text{KL}(p||q)=\\sum_x p(x)\\log\\left(\\frac{p(x)}{q(x)}\\right)=\\E_{x\\sim p}\\log\\left(\\frac{p(x)}{q(x)}\\right).\n\\]\n\n\n\n\n\n\nNote\n\n\n\nMore notation. \\(\\E\\) denotes the expectation and \\(x\\sim p\\) means that \\(x\\) follows the distribution \\(p\\). Thus \\[\n\\E_{x\\sim p}\\left[f(x)\\right]=\\sum_x p(x)f(x)\n\\]\n\n\nIt’s not hard to show that the KL is related to the cross entropy we just introduced by\n\\[\nH(p,q)= D_\\text{KL}(p||q)+ H(p).\n\\]\nThus the statement that the cross entropy \\(H(p,q)\\) is bounded from below by the entropy \\(H(p)\\) is equivalent to the KL being non-negative\n\\[\nD_\\text{KL}(p||q)\\geq 0\n\\]\nThis is simple consequence of Jensen’s inequality, which is the statement that for a convex function \\(\\varphi(x)\\)\n\\[\n\\E\\left[\\varphi(x))\\right]\\geq \\varphi\\left(\\E\\left[x\\right]\\right)\n\\]\nIf we apply this to the KL then, using the convexity of \\(\\varphi(x)=-\\log(x)\\)\n\\[\nD_\\text{KL}(p||q)=-\\E_{x\\sim p}\\log\\left(\\frac{q(x)}{p(x)}\\right)\\geq -\\log\\left(\\E_{x\\sim p}\\left[\\frac{q(x)}{p(x)}\\right]\\right)=-\\log(1)=0,\n\\]\nwith equality if and only if \\(p=q\\)."
  },
  {
    "objectID": "posts/ml-stat-mech-1/index.html#variational-inference-vi",
    "href": "posts/ml-stat-mech-1/index.html#variational-inference-vi",
    "title": "Machine Learning and Statistical Mechanics I",
    "section": "Variational inference (VI)",
    "text": "Variational inference (VI)\nAfter introducing Bayes’ theorem we discussed how you might go about fitting a model to data. It’s not as easy we made it sound. Recall that Bayes’ says the posterior distribution is\n\\[\np(z|x) = \\frac{p(x|z)p(z)}{p(x)}=\\frac{p(x,z)}{p(x)}.\n\\]\nThe denominator \\(p(x)=\\sum_z p(x,z)\\) normalizes the distribution \\(p(z|x)\\), just like the partition function of a SM model. If we are dealing with a complicated latent variable model where \\(z\\) and \\(x\\) are both high dimensional, and \\(p(x,z)\\) has a complex structure, this is intractable.\n\nIn this section we’ll see that it’s possible to develop a variational formulation of the problem that returns the “best” posterior given a family of models. It’s basically a straight copy of physicists’ mean field theory, so we’ll review that first using the language of probability.\n\nMean field theory\nFor an SM model like the Ising model the probability has the form\n\\[\np(\\sigma) = \\frac{\\exp\\left[-\\beta\\cE(\\sigma)\\right]}{Z}.\n\\tag{4}\n\\label{eq:boltzmann}\n\\]\nThe goal is to find expectations, for example the average energy \\(\\E_{\\sigma\\sim p}\\left[\\cE(\\sigma)\\right]\\). Since this is difficult for the \\(p(\\sigma)\\) nature gives us we are going to try and approximate \\(p(\\sigma)\\) by a simpler class of distributions \\(q_\\phi(\\sigma)\\), where \\(\\phi\\) denote the parameters that define the family, and find the best approximation.\nWhat does simpler mean? It means one where we can actually calculate expectations (with the resources we have available). Probably the most drastic simplification we can take is to suppose that the variables are independent, so that the probability distribution factorizes\n\\[\nq_\\phi(\\sigma)=\\prod_n q_{\\phi_n}(\\sigma_n).\n\\tag{5}\n\\label{eq:factor}\n\\]\nWe are allowing for the single spin distributions to be different, which will be appropriate for an inhomogeneous model, the kind of thing you would use to describe a disordered spin system.\nWhat does best mean? We’ve seen that the KL quantifies the difference between distributions, so it’s natural to try to minimize\n\\[\nD_\\text{KL}(q||p)=\\E_{\\sigma\\sim q_\\phi}\\left[\\log\\left(\\frac{q_\\phi(\\sigma)}{p(\\sigma)}\\right)\\right].\n\\]\nWhy do we minimize \\(D(q||p)\\) and not \\(D(p||q)\\)? The pragmatic answer is: \\(D(q||p)\\) is the one we can calculate, as it involves an expectation with respect to the tractable trial distribution. Substituting in the Boltzmann distribution \\(\\eqref{eq:boltzmann}\\) we find\n\\[\nD_\\text{KL}(q||p)= \\log Z - H[q_\\phi] + \\beta \\E_{\\sigma\\sim q_\\phi}\\left[\\cE(\\sigma)\\right]\\geq 0,\n\\]\nor in usual SM language\n\\[\n\\E_{\\sigma\\sim q_\\phi}\\left[\\cE(\\sigma)\\right]-TH[q_\\phi] \\geq F,\n\\tag{6}\n\\label{eq:mft}\n\\]\nwhere \\(F=-T\\log Z\\) is the Helmholtz free energy. This is known as variously as the Bogoliubov or Gibbs inequality. By optimizing the left hand side over \\(\\phi\\) we can find the best approximation within our family, and it will achieve a free energy closest to the true value.\nFor Ising spins our factorized distributions \\(\\eqref{eq:factor}\\) are defined by fields on each site\n\\[\nq_{\\phi_n}(\\sigma_n) = \\frac{\\exp\\left[-\\beta\\phi_n\\sigma_n\\right]}{2\\cosh (\\beta\\phi_n)},\n\\]\nwith average spin\n\\[\n\\E_{\\sigma_n\\sim q_n}\\left[\\sigma_n\\right] = -\\tanh\\left(\\beta\\phi_n\\right).\n\\]\nOptimizing \\(\\eqref{eq:mft}\\) with respect to \\(\\phi_n\\) reproduces the equations of mean field theory. The optimal values of \\(\\phi_n\\) are interpreted as the “mean fields” due to the applied field and the other spins coupled to \\(\\sigma_n\\).\n\n\nVI in latent variable models\nThe only thing we need to do to apply the same idea to latent variable models is to replace \\(\\eqref{eq:boltzmann}\\) with\n\\[\np(z|x) =\\frac{p(x,z)}{p_\\text{M}(x)}.\n\\]\n(we add the subscript “M” for model) The role of the spins \\(\\sigma\\) is now played by the latent variables. Following exactly the same steps leads us to\n\\[\n\\log p_\\text{M}(x) \\geq \\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log p(x,z)\\right]+ H[q_\\phi(\\cdot|z)].\n\\tag{7}\n\\label{eq:elbo}\n\\]\nThe right hand side is called the Evidence lower bound or ELBO (because the marginalized probability \\(p(x)\\) on the left is sometimes called the model evidence).\nIt’s possible to re-write \\(\\eqref{eq:elbo}\\) as\n\\[\n\\log p_\\text{M}(x) \\geq \\log p_\\text{M}(x) - D_\\text{KL}(q_\\phi(\\cdot|x)||p(\\cdot|x)),\n\\]\nso the bound is saturated when the variational posterior for the latent variables coincides with the true posterior \\(p(z|x)=p(x,z)/p_\\text{M}(x)\\).\nFor complicated models it isn’t practical to optimize the ELBO for each data point \\(x\\) to obtain the best \\(\\phi(x)\\). Instead, we average over the entire data set (this is called amortization, a pretty confusing term). I like to think of this as follows. We have two representations of the same joint distribution. One (“forward”) in terms of the generative model and the prior\n\\[\np_\\text{F}(x,z)= p(x|z)p(z)\n\\]\nand the other (“backward”) in terms of the data distribution \\(p_\\text{D}(x)\\) and the posterior\n\\[\np_\\text{B}(x,z)= q_\\phi(z|x)p_\\text{D}(x).\n\\]\nTo make the two equal we should minimize the KL over joint distributions\n\\[\nD_\\text{KL}(q||p)(p_\\text{B}||p_\\text{F})=\\E_{x\\sim \\text{Data}}\\left[\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log\\left(\\frac{q_\\phi(z|x)p_\\text{D}(x)}{p(x|z)p(z)}\\right)\\right]\\right]\\geq 0,\n\\]\nor\n\\[\nH[p_\\text{D}]\\leq H(p_\\text{D}, p_\\text{M}) \\leq \\E_{x\\sim \\text{Data}}\\left[\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log\\left(\\frac{q_\\phi(z|x)}{p(x|z)p(z)}\\right)\\right]\\right].\n\\]\nBy improving our posterior we can saturate the second equality. By improving our generative model \\(p(x|z)\\) we can saturate the first.\nA popular modern approach is to introduce models \\(q_\\phi(x|z)\\) and \\(p_\\theta(z|x)\\), often parameterized in terms of neural networks, and optimize both sets of parameters \\(\\theta\\) and \\(\\phi\\) simultaneously. This is the basis of the Variational Autoencoder, which we’ll meet in the next lecture."
  },
  {
    "objectID": "posts/quarto-and-pyodide/index.html",
    "href": "posts/quarto-and-pyodide/index.html",
    "title": "Quarto and Pyodide",
    "section": "",
    "text": "Having recently switched these pages over to Quarto, I was keen to see how easy it was to build interactive pages. Support for Observable comes out of the box for JS people, but I was also thrilled to discover the extension quarto-pyodide which makes it easy to incorporate Pyodide – aka Python in the browser – into Quarto projects.\nThis is a Pyodide-enabled code cell in a Quarto HTML document.\nAt the moment I can’t do animations using Pyodide see this issue\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHow would I run a simulation and see the results in real time?"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Add links to computational physics course and TQM"
  },
  {
    "objectID": "posts/ml-stat-mech-2/index.html",
    "href": "posts/ml-stat-mech-2/index.html",
    "title": "Machine Learning and Statistical Mechanics II",
    "section": "",
    "text": "In Lecture 1 we introduced the idea of Variational Inference (VI), which turns the problem of inference in latent variable models into one of optimization. That was a rather high-level view: in this lecture we are going to see in more detail how this works in practice in modern approaches that leverage neural networks and automatic differentiation. Specifically, we going to look at one class of versatile models, with many generalizations, called Variational Autoencoders.\n\\[\n\\DeclareMathOperator*{\\E}{\\mathbb{E}}\n\\newcommand{\\cE}{\\mathcal{E}}\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\bx}{\\mathbf{x}}\n\\newcommand{\\bz}{\\mathbf{z}}\n\\newcommand{\\br}{\\mathbf{r}}\n\\newcommand{\\bv}{\\mathbf{v}}\n\\newcommand{\\bmu}{\\boldsymbol{\\mu}}\n\\newcommand{\\bSigma}{\\boldsymbol{\\Sigma}}\n\\newcommand{\\bzeta}{\\boldsymbol{\\zeta}}\n\\]"
  },
  {
    "objectID": "posts/ml-stat-mech-2/index.html#vi-redux",
    "href": "posts/ml-stat-mech-2/index.html#vi-redux",
    "title": "Machine Learning and Statistical Mechanics II",
    "section": "VI redux",
    "text": "VI redux\nSuppose we have a model defined by a prior \\(p(z)\\) over latent variables and a generative model \\(p_\\phi(x|z)\\) for our data \\(x\\) with parameters \\(\\phi\\). We introduce a similar model for the posterior distribution of the latent variables \\(q_\\theta(z|x)\\). This establishes two representations of the joint distribution of observed and latent variables. We’ll call the model expressed in terms of the generative model and the prior the forward model\n\\[\np_\\text{F}(x,z)= p_\\theta(x|z)p(z),\n\\]\nand the model expressed in terms of the data distribution \\(p_\\text{D}(x)\\) and the posterior the backward model\n\\[\np_\\text{B}(x,z)= q_\\phi(z|x)p_\\text{D}(x).\n\\]\nThe KL between these two models is\n\\[\nD_\\text{KL}(p_\\text{B}||p_\\text{F})= \\E_{x\\sim \\text{Data}}\\left[\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log\\left(\\frac{q_\\phi(z|x)p_\\text{D}(x)}{p_\\theta(x|z)p(z)}\\right)\\right]\\right]\\geq 0.\n\\]\nThis inequality can be rearranged to\n\\[\nH[p_\\text{D}]\\leq \\E_{x\\sim \\text{Data}}\\left[\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log\\left(\\frac{q_\\phi(z|x)}{p_\\theta(x|z)p(z)}\\right)\\right]\\right].\n\\tag{1}\n\\label{eq:kl-loss}\n\\]\nIt doesn’t matter that we don’t have the explicit form of the data distribution \\(p_\\text{D}(x)\\), because the right hand side only involves the expectation over this distribution (that’s why we chose this KL and not the reverse). This is implemented as an empirical average over (batches of) the data.\nThe right hand side of \\(\\eqref{eq:kl-loss}\\) is often presented as\n\\[\n\\E_{x\\sim \\text{Data}}\\left[D_\\text{KL}(q_\\phi(\\cdot|x)||p)-\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log p_\\theta(x|z)\\right]\\right].\n\\]\nThe first term is small when the posterior matches the prior, while the second is small when the output of the generative model matches the data (the reconstruction error). Using \\(\\eqref{eq:kl-loss}\\) as a loss function for optimization therefore represents a trade-off between these two contributions.\nThere is considerable freedom in this formulation. Given a data distribution, we could change the forward and backward model, keeping \\(p_\\text{F}=p_\\text{B}\\) but changing the prior \\(p(z)\\). Even after fixing the prior, the joint distribution \\(p(x,z)\\) is not fixed, being determined by an unspecified Copula between the two sets of variables. In practice, the parameterization of the forward and backward models, as well as the details of the optimization, will determine what you get. Additional terms are sometimes added to an objective function, particularly for overparameterized models like deep neural nets, to “encourage” certain behaviour in the parameters. This is called regularization."
  },
  {
    "objectID": "posts/ml-stat-mech-2/index.html#variational-autoencoder",
    "href": "posts/ml-stat-mech-2/index.html#variational-autoencoder",
    "title": "Machine Learning and Statistical Mechanics II",
    "section": "Variational autoencoder",
    "text": "Variational autoencoder\nKingma and Welling noticed that the above description fits neatly into an exisiting class of ML models called Autoencoders. In their original incarnation these are deterministic models that use neural nets (NNs) to map the original data \\(x\\) to some lower dimensional representation in terms of some latent variables \\(h\\) (this part is called the encoder), and then map \\(h\\) to an output \\(x'\\) of the same format as the original data (decoder).\n\n\n\nSchematic view of an autoencoder. Source: Wikipedia\n\n\nAn autoencoder is trained to return outputs close to the inputs. Because of the lower dimensional hidden layer, it cannot do this in a trivial way by learning the identity mapping in the data space. Instead, the idea is that if the data lives close to some lower dimensional manifold embedded in the high dimensional data space – an idea called the manifold hypothesis – the trained autoencoder can map this data manifold to the hidden layer.\nTo perform VI in the autoencoder framework – giving a Variational Autoencoder (VAE) – we need two things\n\nA way to parameterize \\(p_\\theta(x|z)\\) and \\(q_\\phi(z|x)\\) using NNs.\nA way to take gradients of the loss function \\[\n\\mathcal{L}(\\theta,\\phi)=\\E_{x\\sim \\text{Data}}\\left[D_\\text{KL}(q_\\phi(\\cdot|x)||p)-\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log p_\\theta(x|z)\\right]\\right]\n\\tag{2}\n\\label{eq:VAE-loss}\n\\] to perform optimization.\n\nLet’s look at these in turn.\n\nParameterization\nSuppose our latent variables are \\(\\bz\\in \\R^{H}\\) ( we switch to bold notation to emphasize that we are dealing with a vector of continuous variables). For the encoder \\(q_\\phi(\\bz|\\bx)\\), it’s normal to choose the multivariate normal distribution \\(\\mathcal{N}(\\bmu_\\phi(\\bx),\\bSigma_\\phi(\\bx))\\) with mean \\(\\bmu_\\phi(\\bx)\\in \\R^{H}\\) and symmetric covariance matrix \\(\\bSigma(\\bx)\\in \\R^{H\\times H}\\) dependent on the input \\(\\bx\\in \\R^D\\). If the prior is also normal – the choice \\(\\mathcal{N}(0,\\mathbb{1})\\) is common – the KL term in \\(\\eqref{eq:VAE-loss}\\) can be evaluated explicitly in terms of \\(\\bmu_\\phi(\\bx)\\) and \\(\\bSigma_\\phi(\\bx)\\).\nIn practice the covariance matrix \\(\\bSigma_\\phi(\\bx)\\) is usually chosen to be diagonal for simplicity. The functions \\(\\bmu_\\phi(\\bx)\\) and \\(\\bSigma_\\phi(\\bx)\\) are then parameterized using NNs, with an architecture that is adapted to the data. Convolutional neural networks are widely used for images, for example.\nIf we make a similar model for the decoder \\(p_\\theta(\\cdot|\\bz)=\\mathcal{N}(\\bmu'_\\theta(\\bz),\\bSigma'_\\theta(\\bz))\\), then the second term of \\(\\eqref{eq:VAE-loss}\\) involves\n\\[\n-\\log p_\\theta(\\bx|\\bz) = \\frac{1}{2}(\\bx-\\bmu'_\\theta(\\bz))^T\\bSigma'^{-1}_\\theta(\\bz)(\\bx-\\bmu'_\\theta(\\bz))+\\frac{1}{2}\\log\\det\\bSigma_\\theta'(\\bz)+\\text{const.},\n\\]\nwhich encourages the mean output \\(\\bmu'_\\theta(\\bz)\\) for \\(\\bz\\sim q_\\phi(\\cdot|\\bx)\\) to be close to the data point \\(\\bx\\) (reconstruction error).\nThe required expectation over \\(\\bz\\) cannot be taken in closed form, however, if we want to model a complex decoder function \\(p_\\theta\\). It has to be done by Monte Carlo, but the expectation depends on parameters \\(\\phi\\), and we want to take derivatives with respect to these parameters. What do we do?\n\n\nReparameterization trick\nFor continuous variables there is a nice solution, which you’d probably think of fairly quickly, though it has its own name: the reparameterization trick.\nIf you want to generate samples from \\(\\mathcal{N}(\\mu,\\sigma^2)\\) and you have at your disposal a random variable \\(\\zeta\\sim\\mathcal{N}(0,1)\\) then \\(\\sigma \\zeta +\\mu\\) does the job. The nice thing about this observation is that it separates the parameters from the sampling, so that a Monte Carlo estimate of an expectation\n\\[\n\\E_{x\\sim \\mathcal{N}(\\mu,\\sigma^2)}\\left[f(x)\\right]\\approx \\frac{1}{S}\\sum_{s=1}^S f(\\sigma z_s + \\mu)\n\\]\nis explicitly a function of \\(\\sigma\\) and \\(\\mu\\), so that derivatives with respect to these parameters may be calculated. This generalizes straightforwardly to the multivariate Gaussian we use in the decoder as \\(\\bz\\sim \\bSigma_\\phi^{1/2}(\\bx)\\bzeta+\\mu_\\phi(\\bx)\\). For other distributions the required functional mapping may become more complicated.\nIt’s clear that the reparameterization trick is limited to continuous variables. Monte Carlo gradient estimation for discrete variables is an active area of research.\n\n\nMore practicalities\nAt this point we understand how to evaluate the loss function on a data point \\(\\bx\\) using Monte Carlo estimation for the encoder \\(\\bz\\sim q_\\phi(\\cdot|\\bx)\\), in such a way that the estimate is differentiable. In practice a single \\(\\bz\\) sample is usually found to provide useful gradients for optimization. Large datasets are usually split into batches (sometimes called mini-batches, confusingly), so for a batch of size \\(B\\) the loss function is estimated as\n\\[\n\\mathcal{L}(\\theta,\\phi)\\approx\\frac{1}{B}\\sum_{b=1}^B\\left[D_\\text{KL}(q_\\phi(\\cdot|\\bx_b)||p)-\\log p_\\theta(\\bx_b|\\bSigma_\\phi^{1/2}(\\bx_b)\\bzeta_b+\\mu_\\phi(\\bx_b))\\right]\\qquad \\bzeta_b\\sim \\mathcal{N}(0,\\mathbb{1})\n\\]\nFor optimization, gradients are calculated by automatic differentiation, implemented in all modern deep learning libraries. There’s a great deal of craft to this business, but that’s enough detail for now.\n\n\nInterpretability\nOne of the promises of latent variable models like the VAE is that, as well as providing a good generative model for making new samples, or a way of assessing the likelihood of inputs, the latent space may be interpretable. That is, moving in a lower dimensional latent space \\(\\R^H\\) may allow us to explore the manifold on which the data is embedded in \\(\\R^D\\). Developing models and training protocols that encourage this structure learning is an area of active research, but here are some of the issues:\n\nNothing about the loss function \\(\\eqref{eq:VAE-loss}\\) actually requires that the latent space is used at all. If the decoder model \\(p_\\theta(\\bx|\\bz)\\) is rich enough it’s possible that it approaches the data distribution for any \\(\\bz\\): \\(p_\\theta(\\bx|\\bz)\\approx p_\\text{D}(\\bx)\\), meaning that by Bayes’ theorem the posterior is \\[\n\\frac{p_\\theta(\\bx|\\bz)p(\\bz)}{p_\\text{D}(\\bx)}\\approx p(\\bz),\n\\] the same as the prior! This is known as posterior collapse. You may have a good generative model, but you don’t learn anything about your data.\nEven if the latent space is used by the trained model, there’s no guarantee that it’s used nicely, with different latent variables corresponding to meaningfully different qualities of the data: colour, shape, position, etc.. This is called disentangling. Part of the problem is that the prior \\(\\mathcal{N}(0,\\mathbb{1})\\) is rotationally invariant, so lifting this symmetry is necessary.\n\n\n\nCompression with VAEs: bits back\nIn Lecture 1 we discussed the entropy as a fundamental bound on the compression of data, and I suggested that good probabilistic models tailored to a particular kind of data would give better compression. How can we deliver on this promise for latent variable models like the VAE? The problem, as always, is that the model doesn’t supply an explicit expression for \\(p_\\text{M}(x)\\): marginalizing over the latent variables is intractable.\nThere is a beautiful idea called bits back coding that is particularly well suited to the encoder-decoder formulation of latent variable models, and allows the unavailability of \\(p_\\text{M}(x)\\) to be circumvented. Recall that the loss function of the VAE is based on the inequality\n\\[\nH[p_\\text{D}]\\leq \\E_{x\\sim \\text{Data}}\\left[\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log\\left(\\frac{q_\\phi(z|x)}{p_\\theta(x|z)p(z)}\\right)\\right]\\right].\n\\]\nLet’s split the right hand side up into three terms\n\\[\n\\E_{x\\sim \\text{Data}}\\left[\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log\\left(q_\\phi(z|x)\\right)-\\log\\left(p_\\theta(x|z)\\right)-\\log\\left(p(z)\\right)\\right]\\right].\n\\tag{3}\n\\label{eq:loss-3-terms}\n\\]\nRecall that \\(-\\log_2 p(x)\\) is the length in bits of the optimal encoding of \\(x\\). The last two terms could be interpreted as follows\n\nGiven data \\(x\\) we sample \\(z\\sim q_\\phi(\\cdot|x)\\).\nWe encode \\(x\\) using the distribution \\(p_\\theta(\\cdot|z)\\), then\nEncode \\(z\\) using the prior \\(p(\\cdot)\\).\n\nWhen it comes to decoding, we go in reverse: decoding \\(z\\) using the prior and then \\(x\\) using \\(p_\\theta(\\cdot|z)\\). We’ll never reach the Shannon bound this way, however, because of the negative first term in \\(\\eqref{eq:loss-3-terms}\\). We need to make the code shorter. How? At this point we need to remember that the idea of entropy as a lower bound applies in the limit of \\(N\\to\\infty\\) iid data. Imagine a semi-infinite bit stream that we are mid-way through encoding. Here’s the big idea: we decode part of already encoded bitstream using the model \\(q_\\phi(\\cdot|x)\\). The result is a \\(z\\sim q_\\phi(\\cdot|x)\\) which we then use for encoding \\(x\\) as described above. These are the bits back: we will remove \\(H(q_\\phi(\\cdot|x))\\) bits on average, which allows us to reach the Shannon bound (in reality the separate encoding and decoding stages are not perfect). When decoding data, the last thing we do for each \\(x\\) is encode \\(z\\) back to the bitstream using \\(q_\\phi(\\cdot|x)\\)\nI’m of course skipping over many issues to do with the implementation, including quantizing the data of a continuous VAE, and the fact that the stack-like nature of the encoder had to await the development of asymmetric numeral systems to become practical. See the original paper for more details."
  },
  {
    "objectID": "posts/ml-stat-mech-2/index.html#related-models",
    "href": "posts/ml-stat-mech-2/index.html#related-models",
    "title": "Machine Learning and Statistical Mechanics II",
    "section": "Related Models",
    "text": "Related Models\nThe VAE framework is quite general, and in recent years has been elaborated in various ways.\n\nMarkov Model autoencoders\nSo our encoder and decoder were just Gaussian models, albeit with a potentially complicated dependence of the mean and covariance. Can we produce a model with a richer distribution? One straightforward way is to make the forward and backward models Markov processes with \\(T\\) steps, with latent variables \\(z_0,\\ldots z_{T-1}\\). It’s easier to write if we identify \\(x=z_T\\), so that\n\\[\np_\\text{F}(z_0,\\ldots x=z_T) = p_\\theta(x=z_T|z_{T-1})p_\\theta(z_{T-1}|z_{T-2})\\cdots p_\\theta(z_1|z_{0})p(z_0)\n\\]\n\\[\np_\\text{B}(z_0,\\ldots \\ldots x=z_T) = q_\\phi(z_0|z_{1})\\cdots q_\\phi(z_{T-2}|z_{T-1})q_\\phi(z_{T-1}|z_T)p_\\text{D}(x=z_T)\n\\]\n(We could have different kernels at each time step, and different dimensionalities, but I’m suppressing this for now). The loss function comes from a straightforward generalization of \\(\\eqref{eq:kl-loss}\\)\n\\[\nH[p_\\text{D}]\\leq \\E_{z\\sim p_\\text{B}}\\left[\\log \\left(\\frac{q_\\phi(z_0|z_1)}{p(z_0)}\\right)+\\sum_{t=0}^{T-2}\\log\\left(\\frac{q_\\phi(z_{t+1}|z_{t+2})}{p_\\theta(z_{t+1}|z_t)}\\right)\\right].\n\\]\nThis loss is an expectation (with respect to the backward model) of the log-likelihood ratio of the forward and backward Markov processes. Note that this model has a large amount of “gauge” freedom: the intermediate dynamics is completely unspecified by the loss function so will be determined by the details of the parameterization and optimization.\n\nWe can even imagine passing to the continuous time limit, in which case \\(z_t\\) becomes a continuous time stochastic process described by a stochastic differential equation (SDE).\n\\[\ndz_t = \\mu_\\theta(z_t)dt + dW_t\n\\]\nwhere \\(W_t\\) denotes a \\(\\R^H\\) dimensional Brownian motion. and \\(\\mu_\\theta(z_t)\\) is a parameterized drift (it could have an explicit time dependence too). More precisely, there are two SDEs, one describing the forward process and one the backward, each with their own drift (for technical reasons the volatilities of the two processes have to match, which is why they’ve been set to one here). In the continuum limit the KL involves the log of the Radon–Nikodym derivative.\nA nice feature of the SDE formulation is that the model is separated from the implementation of the dynamics. You can solve the SDE by whatever method you like: as long as you can differentiate the solution with respect to the parameters it can be plugged into the loss and optimized.\nOne possible application of this kind of model is to infer the trajectories that led to some measured outcomes in stochastic dynamics. If the forward model is fixed and describes a simulation of a physical system – for example a molecular dynamics simulation of a biomolecule – the backward model can be used to infer the trajectories that led up to some measured states \\(z_T\\).\nAlternatively, one can fix the backward model and just learn the forward model. This seems a bit strange from our original point of view of finding the posterior, but one can obtain perfectly good generative models this way. See Denoising Diffusion Probabilistic Models for a recent example.\n\n\n\n(Top) Model architecture and (Bottom) generated samples from Denoising Diffusion Probabilistic Models.\n\n\n\n\nNormalizing flows\nAutoencoders were originally conceived to learn a low dimensional latent representation of the data. By taking the latent space and the data space to be identical \\(\\R^H=\\R^D\\), however, we can make contact with another kind of model called a Normalizing Flow. In this setting, let’s take the covariances of the Gaussian models for the encoder (\\(\\bSigma_\\phi\\)) and decoder (\\(\\bSigma'_\\theta\\)) to zero, so that \\(q_\\phi(\\bz|\\bx)\\) and \\(p_\\theta(\\bx|\\bz)\\) become deterministic maps given by\n\\[\n\\bz = \\mu_\\phi(\\bx),\\qquad \\bx = \\mu'_\\theta(\\bz).\n\\tag{4}\n\\label{eq:bij}\n\\]\nThe only way for the KL to be nonzero in this limit is if these maps are inverses of each other. What value does the KL take in this case? The multivariate Gaussian distribution for the encoder is\n\\[\nq_\\phi(\\cdot|\\bx) = \\frac{1}{\\sqrt{(2\\pi)^{D} \\det\\bSigma_\\phi(\\bx)}} \\exp\\left[-\\frac{1}{2}(\\bz-\\bmu_\\phi(\\bx))^T\\bSigma^{-1}_\\phi(\\bx)(\\bz-\\bmu_\\phi(\\bx))\\right],\n\\]\nwith a similar expression for the decoder. The KL involves the ratio\n\\[\n\\frac{q_\\phi(\\bz|\\bx)}{p_\\theta(\\bx|\\bz)}\n\\]\nwhich, when \\(\\bz\\) and \\(\\bx\\) are related by \\(\\eqref{eq:bij}\\), takes on the value\n\\[\n\\frac{q_\\phi(\\bz|\\bx)}{p_\\theta(\\bx|\\bz)}\\longrightarrow \\sqrt{\\frac{\\det\\bSigma'_\\theta(\\bz)}{\\det\\bSigma_\\phi(\\bx)}}=\\det \\left(\\frac{\\partial\\bx}{\\partial\\bz}\\right).\n\\]\nThe appearance of the Jacobian is more easily understood starting from first principles. If \\(\\bz\\) is described by a probability density \\(p(\\bz)\\) then \\(\\bx=\\mu'_\\theta(\\bz)\\) has density\n\\[\n\\det\\left(\\frac{\\partial\\bz}{\\partial\\bx}\\right) p(\\mu_\\phi(\\bx)).\n\\]\nIn words: to evaluate the probability density at \\(\\bx\\) we map to \\(\\bz\\) and evaluate the density there, accounting for the Jacobian of the transformation.\nIn the deterministic limit, the KL becomes\n\\[\nD_\\text{KL}(p_\\text{B}||p_\\text{F})\\longrightarrow -\\E_{x\\sim \\text{Data}}\\left[\\log\\det \\left(\\frac{\\partial\\bz}{\\partial\\bx}\\right)+\\log p(\\mu_\\phi(\\bx))\\right].\n\\]\nConceptually, normalizing flows are perhaps a bit simpler than VAEs. The challenge in implementing this scheme is constructing flexible, invertible models with tractable Jacobians (since computing the determinant is \\(O(D^3)\\) and has to be done for every data point). In practice this is done by stacking together simpler transformations, each of which is invertible with known Jacobian."
  },
  {
    "objectID": "posts/ml-stat-mech-2/index.html#learning-the-path-integral",
    "href": "posts/ml-stat-mech-2/index.html#learning-the-path-integral",
    "title": "Machine Learning and Statistical Mechanics II",
    "section": "Learning the path integral",
    "text": "Learning the path integral\nFinally, we’ll look at an application of these methods from Barr, Gispen, Lamacraft (2020) that is squarely in the domain of physics: finding the ground states of quantum systems.\n\nThe Feynman–Kac formula\nOne of the many connections between quantum mechanics and stochastic processes is provided by the Feynman–Kac formula (FK), which is a fully rigorous path integral formula exists for the heat-type equations\n\\[\n  \\frac{\\partial\\psi(\\br,t)}{\\partial t} = -\\left[H\\psi\\right](\\br,t),\n  \\tag{5}\n  \\label{eq:im-time}\n\\]\nalso known as the imaginary time Schrödinger equation. The FK formula expresses the solution as an expectation over Brownian paths\n\\[\n  \\psi(\\br_2,t_2) =  \\E_{\\br(t_2)=\\br_2}\\left[\\exp\\left(-\\int_{t_1}^{t_2}V(\\br(t))dt\\right)\\psi(\\br(t_1),t_1)\\right],\n\\]\nwhere the paths must finish at \\(\\br_2\\) at time \\(t_2\\). If you’ve seen the path integral before and are asking yourself what happened to the term in the exponent that derives from the kinetic energy: that’s what describes the distribution over Brownian paths.\nIn this way quantum mechanics is brought into the realm of stochastic processes, albeit in “imaginary time”. Whilst this formulation is therefore not of direct utility in studying quantum dynamics, it provides a very useful tool for studying ground states. This is because the propagator \\(K(\\br_2,t_2;\\br_1,t_1)\\) for \\(\\eqref{eq:im-time}\\) has a spectral representation in terms of the eigenfunctions \\(\\varphi_n\\) and eigenenergies \\(E_n\\) of the time independent Schrödinger equation \\(H\\varphi_n = E_n\\varphi_n\\) as\n\\[\nK(\\br_2,t_2;\\br_1,t_1) = \\sum_n \\varphi_n(\\br_2)\\varphi^*_n(\\br_1)e^{-E_n(t_2-t_1)}.\n\\]\nThus, as \\(t_2-t_1\\to\\infty\\), only the ground state contributes.\n\\[\nK(\\br_2,t_2;\\br_1,t_1)\\longrightarrow \\varphi_0(\\br_2)\\varphi^*_0(\\br_1)e^{-E_0(t_2-t_1)} \\qquad \\text{ as } t_2-t_1\\to\\infty.\n\\]\nThe FK formula defines a new path measure \\(\\mathbb{P}_\\text{FK}\\) that differs from the Brownian measure \\(\\mathbb{P}_0\\) by the Radon–Nikodym derivative\n\\[\n\\frac{d\\mathbb{P}_{\\text{FK}}}{d\\mathbb{P}_{0}} = \\mathcal{N}\\exp\\left(-\\int_{t_1}^{t_2}V(\\br(t))dt\\right)\n\\tag{6}\n\\label{eq:RN}\n\\]\nwhere \\(\\mathcal{N}\\) is a normalization factor. Think of \\(\\eqref{eq:RN}\\) as a Boltzmann factor that describes paths that spend more time in the attractive regions of the potential (\\(V(\\br)&lt;0\\)) and less time in the repulsive regions (\\(V(\\br)&gt;0\\)).\nAs \\(T\\equiv t_2-t_1\\to\\infty\\), the distribution of \\(\\br(0)\\) under this measure coincides with the ground state probability distribution \\(|\\varphi_0(\\br)|^2\\) from the Born rule. To see that this is the case, consider a path that passes through \\((\\br_-,-T/2)\\), \\((\\br,0)\\) and \\((\\br_+,T/2)\\) for some arbitrary initial and final point \\(\\br_\\pm\\). The overall propagator is then\n\\[\n  K(\\br_+,T/2;\\br,0)K(\\br,0;\\br_-,-T/2;)\\sim  |\\varphi_0(\\br)|^2\\varphi_0(\\br_+)\\varphi^*_0(\\br_-)e^{-E_0T}.\n\\]\nApart from a normalization factor that depends on \\(\\br_\\pm\\) and \\(T\\), this is just the expected ground state distribution \\(|\\varphi_0(\\br)|^2\\). Thus, the ability to sample from the FK measure for long trajectories would also allow us to sample from the ground state distribution. One technique for doing this is Path integral Monte Carlo, which performs Monte Carlo sampling the space of Feynman trajectories.\n\n\n\nSource: Ceperley (1995).\n\n\n\n\nThe loss function\nA different way to turn the above connection into a calculational tool, is to use the fact that the path measure defined by the FK formula is Markovian, meaning that the trajectories are solutions of the SDE\n\\[\nd\\br_t = d\\mathbf{B}_t + \\bv(\\br_t,t)dt\n\\]\nfor some drift function \\(\\bv(\\br_t,t)\\). In fact for \\(T\\to\\infty\\) the drift is time independent and related to the ground state wavefunction \\(\\varphi_0(\\br)\\) by \\(\\bv(\\br)=\\nabla\\varphi_0(\\br)\\).\nNow, we don’t know the ground state wavefunction, but we can turn this observation into a variational principle by introducing a (NN) parameterized drift \\(\\bv_\\theta(\\br) = \\textsf{NN}_\\theta(\\br)\\) and attempting to minimize the KL between the measure defined by this drift and the FK measure. The log likelihood ratio (log Radon–Nikodym derivative) of the two measures obeys\n\\[\n  \\log\\left(\\frac{d\\mathbb{P}_{\\bv}}{d\\mathbb{P}_\\text{FK}}\\right) =\\ell_T - E_0 T+\\log\\left(\\frac{\\varphi_0(\\br_0)}{\\varphi_0(\\br_T)}\\right)\n\\]\n\\[\n   \\ell_T\\equiv \\int \\bv(\\br_t)\n  \\cdot d\\vec{B}_t+\\int dt\\left(\\frac{1}{2}|\\bv(\\br_t)|^2+V(\\br_t)\\right).\n\\]\nThe KL of the two measures is then obtained by taking the expectation over trajectories of the SDE\n\\[\n    D_{\\text{KL}}\\left(\\mathbb{P}_{\\bv} \\middle\\| \\mathbb{P}_\\text{FK}\\right)=\\E_{\\mathbb{P}_{\\bv}}\\left[\\ell_T-E_0 T+\\log\\left(\\frac{\\varphi_0(\\br_0)}{\\varphi_0(\\br_T)}\\right)\\right].\n    \\tag{7}\n    \\label{eq:full-KL}\n\\]\n(as usual, we choose this KL rather than the reverse because it’s the one we can evaluate) Note that \\(\\eqref{eq:full-KL}\\) is true for any \\(\\br_0\\). If we additionally average over \\(\\br_0\\) drawn from the stationary distribution of the SDE, then the distributions of \\(\\br_T\\) and \\(\\br_0\\) coincide, and the final term vanishes. Because the KL divergence is positive \\(D_{\\text{KL}}\\left(\\mathbb{P}_{\\bv} \\middle\\| \\mathbb{P}_\\text{FK}\\right)\\geq 0\\) we then have \\(\\E_{\\mathbb{P}_{\\bv}}\\left[\\ell_T\\right]\\geq E_0 T\\), with equality when the two measures match. This is the variational principle that forms the basis of our approach. For \\(T\\to\\infty\\) we can ignore the final term so that\n\\[\n    \\lim_{T\\to\\infty} \\frac{\\E_{\\mathbb{P}_{\\bv}}\\left[\\ell_T\\right]}{T}\\geq E_0,\n\\]\nirrespective of the initial state distribution (as \\(T\\to\\infty\\) the final state distribution will be the stationary state of the SDE, assuming ergodicity).\n\n\nTraining\nFor details of how the model is parameterized and trained see our paper."
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks",
    "section": "",
    "text": "Quantum Circuits of Dual Unitary Gates\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantum Ground States from Reinforcement Learning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbsence of superdiffusion in certain random spin models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nML and SM 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Planted Directed Polymer\n\n\n\n\n\n\n\n\n\n\n\nAusten Lamacraft (Cambridge) and Sun Woo Kim (KCL)\n\n\n\n\n\n\n\n\n\n\n\n\nNew Rules:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantum Ground States from Reinforcement Learning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantum Circuits II\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNew Rules:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantum Circuits I\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpace-time dual cat models\n\n\nSubtitle goes here\n\n\n\nQuantum Circuits\n\n\nPhysics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantum Circuits II\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning and Statistical Mechanics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCircuit Models of Many Body Quantum Dynamics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNew Rules\n\n\nQuantum Circuits, Cellular Automata, Complexity and Chaos\n\n\n\n\n\n\n\n\nAusten Lamacraft (Cambridge)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantum Circuits\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuperdiffusion in spin chains\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Dual Unitarity to Biunitarity\n\n\nA 2-categorical model for exactly-solvable many-body quantum dynamics arXiv:2302.07280 (J Phys A, to appear)\n\n\n\n\n\n\n\n\nJul 18, 2024\n\n\nPieter Claeys (MPI-PKS), Austen Lamacraft, Jamie Vicary\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html",
    "href": "talks/rl4qm-deepmind/index.html",
    "title": "Austen Lamacraft",
    "section": "",
    "text": "\\[\n\\nonumber\n\\newcommand{\\br}{\\mathbf{r}}\n\\newcommand{\\bR}{\\mathbf{R}}\n\\newcommand{\\bp}{\\mathbf{p}}\n\\newcommand{\\bk}{\\mathbf{k}}\n\\newcommand{\\bq}{\\mathbf{q}}\n\\newcommand{\\bv}{\\mathbf{v}}\n\\newcommand{\\bx}{\\mathbf{x}}\n\\newcommand{\\bz}{\\mathbf{z}}\n\\DeclareMathOperator*{\\E}{\\mathbb{E}}\n\\]"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#quantum-ground-states-from-reinforcement-learning",
    "href": "talks/rl4qm-deepmind/index.html#quantum-ground-states-from-reinforcement-learning",
    "title": "Austen Lamacraft",
    "section": "Quantum Ground States from Reinforcement Learning",
    "text": "Quantum Ground States from Reinforcement Learning\nWork with Ariel Barr and Willem Gispen"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#schrödinger-equation-1-particle",
    "href": "talks/rl4qm-deepmind/index.html#schrödinger-equation-1-particle",
    "title": "Austen Lamacraft",
    "section": "Schrödinger Equation: 1 Particle",
    "text": "Schrödinger Equation: 1 Particle\n\nSchrödinger picture: basic object is wavefunction \\(\\psi(\\br)\\)\n\n\\[\n\\overbrace{\\left[-\\frac{\\nabla^2}{2m}+V(\\br_i)\\right]}^{\\equiv H\\text{, Hamiltonian}}\\psi(\\br) = E\\psi(\\br)\n\\]\n\nDiscretize on real-space grid \\(L\\times L\\times L\\)"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#schrödinger-equation-n-particles",
    "href": "talks/rl4qm-deepmind/index.html#schrödinger-equation-n-particles",
    "title": "Austen Lamacraft",
    "section": "Schrödinger Equation: N Particles",
    "text": "Schrödinger Equation: N Particles\n\nWavefunction now has \\(N\\) variables: \\(\\Psi(\\br_1,\\ldots \\br_N)\\)\n\n$$ \\overbrace{\\left[\\sum_i\\left(-\\frac{\\nabla_i^2}{2m_i}+V(\\br_i)\\right)+\\sum_{i&lt;j}U(\\br_i-\\br_j)\\right]}^{\\equiv H}\\Psi(\\br_1,\\ldots \\br_N) = E\\Psi(\\br_1,\\ldots \\br_N) $$\n\nRequires grid in \\(3N\\) dimensions of \\(L^{3N}\\) points!\nAtoms / molecules are hard; matter (\\(N\\sim N_\\text{A}\\)) is impossible!"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#variational-principle",
    "href": "talks/rl4qm-deepmind/index.html#variational-principle",
    "title": "Austen Lamacraft",
    "section": "Variational Principle",
    "text": "Variational Principle\n\nFor approximate \\(\\Psi\\) can upper bound ground state \\(E_0\\)\n\n$$ \\begin{align} E_0 &\\leq \\inf_{\\lVert\\Psi\\rVert=1} \\langle \\Psi\\lvert H\\rvert\\Psi\\rangle\\\\ \\langle \\Psi\\lvert H\\rvert\\Psi\\rangle &= \\int d\\br_1\\cdots d\\br_N \\Psi^*(\\br_1,\\ldots,\\br_N)\\left[H \\Psi\\right](\\br_1,\\ldots,\\br_N) \\end{align} $$\nChallenges\n\nForm of \\(\\Psi\\)\nExpectation evaluation\nOptimization"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#form-of-psi-feature-engineering",
    "href": "talks/rl4qm-deepmind/index.html#form-of-psi-feature-engineering",
    "title": "Austen Lamacraft",
    "section": "Form of \\(\\Psi\\) (‘Feature Engineering’)",
    "text": "Form of \\(\\Psi\\) (‘Feature Engineering’)\nWavefunctions of restricted form\n\nFactorized, leading to Hartree–Fock method\n\n\\[\n\\Psi(\\br_1,\\ldots,\\br_N)=\\psi_1(\\br_1)\\ldots \\psi_N(\\br_N).\n\\]\n\nJastrow factors include pair correlations\n\n$$ \\Psi(\\br_1,\\ldots,\\br_N)\\to \\Psi(\\br_1,\\ldots,\\br_N)\\exp\\left(\\sum_{i&lt;j}\\phi(\\br_i-\\br_j)\\right) $$\n\nMany more…"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#expectation-evaluation",
    "href": "talks/rl4qm-deepmind/index.html#expectation-evaluation",
    "title": "Austen Lamacraft",
    "section": "Expectation evaluation",
    "text": "Expectation evaluation\n\\(|\\Psi(\\br_1,\\ldots,\\br_N)|^2\\) a probability distribution, so evaluate\n$$ \\frac{\\langle \\Psi\\lvert H\\rvert\\Psi\\rangle}{\\langle\\Psi \\vert\\Psi\\rangle}  =\\int d\\bR\\,|\\Psi(\\bR)|^2\\frac{\\left[H \\Psi\\right](\\bR)}{\\Psi(\\bR)} $$\nby Monte Carlo sampling. This is Variational Monte Carlo (VMC)"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#neural-approaches",
    "href": "talks/rl4qm-deepmind/index.html#neural-approaches",
    "title": "Austen Lamacraft",
    "section": "Neural Approaches",
    "text": "Neural Approaches\n\\(\\Psi(\\bR)\\sim \\textsf{NN}(\\bR)\\) and optimize!\n\nCarleo and Troyer (2017): lattice models (more later)\nmany more…\nPfau et al. (2019): Fermi Net"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#tldr",
    "href": "talks/rl4qm-deepmind/index.html#tldr",
    "title": "Austen Lamacraft",
    "section": "TL;DR",
    "text": "TL;DR\n\n\\(\\exists\\) other formulations of QM including Feynman’s path integral\nLet’s learn the path integral instead!"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#outline",
    "href": "talks/rl4qm-deepmind/index.html#outline",
    "title": "Austen Lamacraft",
    "section": "Outline",
    "text": "Outline\n\nThe path integral\nQuantum mechanics and optimal control\nLearning the ground state process\nFirst experiments\nNext directions"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#path-integral",
    "href": "talks/rl4qm-deepmind/index.html#path-integral",
    "title": "Austen Lamacraft",
    "section": "Path integral",
    "text": "Path integral\n\n\n\n\nSolution of time-dependent Schrödinger equation\n\n$$ \\begin{align} i\\frac{\\partial \\psi}{\\partial t} &= H\\psi\\\\ \\psi(\\br_2,t_2) &= \\int d\\br_1 \\mathcal{K}(\\br_2,t_2;\\br_1,t_1)\\psi(\\br_1,t_1),\\\\   \\mathcal{K}(\\br_2,t_2;\\br_1,t_1) &= \\int_{\\br(t_1)=\\br_1 \\atop \\br(t_2)=\\br_2} \\mathcal{D}\\br(t)\\exp\\left(i\\int_{t'}^t L(\\br(t),\\dot{\\br})\\right) \\end{align} $$\n\n\\(L(\\br,\\bv) = \\frac{1}{2}\\bv^2 - V(\\br)\\) is the classical Lagrangian\n\n\nMy machines came from too far away"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#trouble-with-feynman",
    "href": "talks/rl4qm-deepmind/index.html#trouble-with-feynman",
    "title": "Austen Lamacraft",
    "section": "Trouble with Feynman?",
    "text": "Trouble with Feynman?\n\n“Integration over paths” has never been defined\nKac (1949) found a workaround for heat-type equations\n\n\\[\\begin{align}\n  \\frac{\\partial\\psi(\\br,t)}{\\partial t} = \\left[\\frac{\\nabla^2}{2}-V(\\br_i)\\right]\\psi(\\br,t)\n\\end{align}\\]\n\n“Imaginary time” Schrödinger. Exponent in PI becomes real\n\n\\[\n\\exp\\left(-\\int_{t'}^t \\left[\\frac{1}{2}\\dot\\br^2 + V(\\br)\\right]\\right)\n\\]"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#feynmankac-fk-formula",
    "href": "talks/rl4qm-deepmind/index.html#feynmankac-fk-formula",
    "title": "Austen Lamacraft",
    "section": "Feynman–Kac (FK) Formula",
    "text": "Feynman–Kac (FK) Formula\n…expresses \\(\\psi(\\br,t)\\) as expectation…\n$$   \\psi(\\br_2,t_2) =  \\E_{\\br(t)}\\left[\\exp\\left(-\\int_{t_1}^{t_2}V(\\br(t))dt\\right)\\psi(\\br(t_1),t_1)\\right] $$\n\n…over Brownian paths finishing at \\(\\br_2\\) at time \\(t_2\\)."
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#ground-state-from-pi",
    "href": "talks/rl4qm-deepmind/index.html#ground-state-from-pi",
    "title": "Austen Lamacraft",
    "section": "Ground State from PI",
    "text": "Ground State from PI\n\nFor \\(t\\to\\infty\\) only ground state contributes\nSpectral representation in terms of \\(H\\varphi_n = E_n\\varphi_n\\)\n\n\\begin{align}   K(\\br_2,t_2;\\br_1,t_1) &= \\sum_n \\varphi_n(\\br_2)\\varphi^*_n(\\br_1)e^{-E_n(t_2-t_1)}\\\\   &\\longrightarrow \\varphi_0(\\br_2)\\varphi^*_0(\\br_1)e^{-E_0(t_2-t_1)} \\qquad \\text{ as } t_2-t_1\\to\\infty. \\end{align}"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#bosons-and-fermions",
    "href": "talks/rl4qm-deepmind/index.html#bosons-and-fermions",
    "title": "Austen Lamacraft",
    "section": "Bosons and Fermions",
    "text": "Bosons and Fermions\n\nFor identical particles \\(|\\Psi(\\br_1,\\ldots,\\br_N)|^2\\) permutation invariant\n\\(\\Psi(\\br_1,\\ldots,\\br_N)\\) completely symmetric (Bosons) or antisymmetric (Fermions)\n\\(t\\to\\infty\\) limit picks out nodeless (bosonic) ground states"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#path-integral-monte-carlo",
    "href": "talks/rl4qm-deepmind/index.html#path-integral-monte-carlo",
    "title": "Austen Lamacraft",
    "section": "Path integral Monte Carlo",
    "text": "Path integral Monte Carlo\n\n\n\n\nCeperley, RMP (1995)"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#the-path-measure",
    "href": "talks/rl4qm-deepmind/index.html#the-path-measure",
    "title": "Austen Lamacraft",
    "section": "The Path Measure",
    "text": "The Path Measure\n\nRelative weight of FK paths given by Radon-Nikodym derivative\n\n$$   \\frac{d\\mathbb{P}_\\text{FK}}{d\\mathbb{P}_\\text{B}} = \\mathcal{N}\\exp\\left(-\\int_{t_1}^{t_2}V(\\br(t))dt\\right) $$\n\n\\(\\mathcal{N}\\) is a normalization factor. \\(\\mathcal{N}\\sim e^{E_0 (t_2-t_1)}\\) for \\(t_2\\gg t_1\\)\nMore time in \\(V(\\br)&lt;0\\) regions; less in \\(V(\\br)&gt;0\\)."
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#born-rule-in-pi",
    "href": "talks/rl4qm-deepmind/index.html#born-rule-in-pi",
    "title": "Austen Lamacraft",
    "section": "Born Rule in PI?",
    "text": "Born Rule in PI?\n\n\\(|\\psi(\\br)|^2\\) is probability distribution. Connection to path measure?\nConsider path passing through $(\\br_-,-T/2)$, \\((\\br,0)\\) and $(\\br_+,T/2)$\nOverall propagator is\n\n$$   K(\\br_+,T/2;\\br,0)K(\\br,0;\\br_-,-T/2;)\\sim  |\\varphi_0(\\br)|^2\\varphi_0(\\br_+)\\varphi^*_0(\\br_-)e^{-E_0T}. $$\n\nSample from FK measure ↔︎ sample from \\(|\\varphi_0(\\br)|^2\\)"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#schrödinger-problem-1931",
    "href": "talks/rl4qm-deepmind/index.html#schrödinger-problem-1931",
    "title": "Austen Lamacraft",
    "section": "Schrödinger Problem (1931)",
    "text": "Schrödinger Problem (1931)\n\n\n\n\nDiffusion between two distributions \\(p_{\\pm T/2}(\\br)\\) ?\nSolution written $p_t(\\br) = \\varphi_\\text{F}(\\br,t)\\varphi_\\text{B}(\\br,t)$\n\\(\\varphi_\\text{F/B}(\\br,t)\\) obeys forward / backward heat equation\nJamison (1974): process is Markov\n\n\\[\nd\\br_t = d\\mathbf{B}_t + \\bv(\\br_t,t)dt,\n\\]\n\nDrift \\(\\mathbf{v}(\\br_t,t)\\) determined by potential $V(\\br)$ and $p_{\\pm T/2}(\\br)$"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#optimal-control-formulation",
    "href": "talks/rl4qm-deepmind/index.html#optimal-control-formulation",
    "title": "Austen Lamacraft",
    "section": "Optimal Control Formulation",
    "text": "Optimal Control Formulation\n\nCost function\n\n\\[\n  C_T[\\mathbf{v}] = \\frac{1}{T}\\E\\left[\\int_0^T\\left[\\frac{1}{2}(\\mathbf{v}(\\br_t,t))^2 + V(\\br_t)\\right]dt\\right],\n\\]\n\nHolland (1977) showed that\n\n$$ E_0 = \\lim_{T\\to\\infty} \\min_{\\bv} C_T[\\bv(\\br)] $$"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#probabilistic-interpretation",
    "href": "talks/rl4qm-deepmind/index.html#probabilistic-interpretation",
    "title": "Austen Lamacraft",
    "section": "Probabilistic interpretation",
    "text": "Probabilistic interpretation\n$$ C_T[\\mathbf{v}]-E_0  = \\lim_{T\\to\\infty} \\frac{1}{T} \\E_{\\mathbb{P}_\\bv}\\left[\\log\\left(\\frac{d\\mathbb{P}_\\bv}{d\\mathbb{P}_\\text{FK}}\\right)\\right] = \\lim_{T\\to\\infty} \\frac{1}{T} D_\\text{KL}(\\mathbb{P}_\\bv\\lvert\\rvert \\mathbb{P}_\\text{FK}) $$\n\nWhen \\(C_T[\\mathbf{v}]/T=E_0\\), SDE samples from the FK path measure!\nDon’t just get \\(E_0\\), but samples from \\(|\\varphi_0|^2\\)"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#proof-sketch",
    "href": "talks/rl4qm-deepmind/index.html#proof-sketch",
    "title": "Austen Lamacraft",
    "section": "Proof Sketch",
    "text": "Proof Sketch\n\nWe have seen\n\n$$   \\frac{d\\mathbb{P}_\\text{FK}}{d\\mathbb{P}_\\text{B}} = \\mathcal{N}\\exp\\left(-\\int_{t_1}^{t_2}V(\\br(t))dt\\right) $$\n\n\\(\\mathcal{N}\\sim e^{E_0 (t_2-t_1)}\\) for \\(t_2\\gg t_1\\)\n\n`\n\nGirsanov theorem tells us\n\n$$   \\frac{d\\mathbb{P}_\\bv}{d\\mathbb{P}_{\\text{B}}}=\\exp\\left(\\int \\bv(\\br_t)\\cdot d\\br_t - \\frac{1}{2}\\int |\\bv(\\br_t)|^2 dt\\right). $$\n\nEvaluate the KL divergence\n$$ \\begin{align}   \\E_{\\mathbb{P}_\\bv}\\left[\\log\\left(\\frac{d\\mathbb{P}_\\bv}{d\\mathbb{P}_\\text{FK}}\\right)\\right]&=\\E_{\\mathbb{P}_v}\\left[\\int \\bv(\\br_t)\\cdot d\\br_t+\\int dt\\left(-\\frac{1}{2}|\\bv(\\br_t)|^2+V(\\br_t)\\right)\\right] - E_0 T\\\\   &=\\E_{\\mathbb{P}_\\bv}\\left[\\int \\bv(\\br_t)\\cdot d\\mathbf{B}_t+\\int dt\\left(\\frac{1}{2}|\\bv(\\br_t)|^2+V(\\br_t)\\right)\\right] - E_0 T\\\\   &=\\E_{\\mathbb{P}_\\bv}\\left[\\int dt\\left(\\frac{1}{2}|\\bv(\\br_t)|^2+V(\\br_t)\\right)\\right] - \\lambda T\\\\   &\\geq 0 \\end{align} $$\n\nBoué and Dupuis (1998)"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#fokkerplanck",
    "href": "talks/rl4qm-deepmind/index.html#fokkerplanck",
    "title": "Austen Lamacraft",
    "section": "Fokker–Planck",
    "text": "Fokker–Planck\n\nConsider SDE with drift \\(v(x) = -U'(x)\\)\n\n\\[\ndx_t = dB_t + v(X_t)dt\n\\]\n\nFokker–Planck equation describing probability density\n\n\\[\n  \\frac{\\partial\\rho}{\\partial t} =\\frac{\\partial}{\\partial x}\\left[\\frac{1}{2}\\frac{\\partial \\rho}{\\partial x} + U'(x)\\rho\\right].\n\\]\n\nStationary state is Boltzmann distribution\n\n\\[\n  \\rho_0(x) \\propto \\exp(-2U(x)).\n\\]"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#schrödinger-fokkerplanck",
    "href": "talks/rl4qm-deepmind/index.html#schrödinger-fokkerplanck",
    "title": "Austen Lamacraft",
    "section": "Schrödinger ↔︎ Fokker–Planck",
    "text": "Schrödinger ↔︎ Fokker–Planck\n\\[\n  \\psi(x,t) = \\frac{\\rho(x,t)}{\\sqrt{\\rho_0(x)}},\n\\]\n\n…satisfies the (imaginary time) Schrödinger equation with Hamiltonian\n\n$$   H = -\\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}+ \\overbrace{\\frac{U'^2- U''}{2}}^{\\equiv V(x)}. $$\n\nZero energy ground state \\(\\varphi_0(x) = \\sqrt{\\rho_0(x)}\\propto \\exp(-U(x))\\)\nDrift \\(v(x) = \\varphi_0'(x)/\\varphi_0(x)\\)"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#examples",
    "href": "talks/rl4qm-deepmind/index.html#examples",
    "title": "Austen Lamacraft",
    "section": "Examples",
    "text": "Examples"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#oscillator-ornsteinuhlenbeck",
    "href": "talks/rl4qm-deepmind/index.html#oscillator-ornsteinuhlenbeck",
    "title": "Austen Lamacraft",
    "section": "Oscillator = Ornstein–Uhlenbeck",
    "text": "Oscillator = Ornstein–Uhlenbeck\n\\[\nH = \\frac{1}{2}\\left[-\\frac{d^2}{dx^2} + x^2\\right]\n\\]\n\nGround state $\\varphi_0(x)=\\pi^{-1/4}e^{-x^2/2}$; $E_0=1/2$\nDrift \\(v(x) = - x\\) gives OU process"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#calogero-dyson-bm",
    "href": "talks/rl4qm-deepmind/index.html#calogero-dyson-bm",
    "title": "Austen Lamacraft",
    "section": "Calogero = Dyson BM",
    "text": "Calogero = Dyson BM\n$$ H = \\sum_i \\frac{1}{2}\\left[-\\frac{\\partial^2}{\\partial x_i^2}+x^2\\right] + \\lambda(\\lambda-1)\\sum_{i&lt;j} \\frac{1}{(x_i-x_j)^2} $$\n\nGround state exactly of Jastrow form\n\n$$ \\Phi_0(x_1,\\ldots x_N) = \\prod_{i&lt;j}|x_i-x_j|^{\\lambda}\\exp\\left(-\\frac{1}{2}\\sum_i x_i^2\\right) $$\n\nDrift is \\(v_i = \\partial_i \\log\\Phi_0\\)\n\n$$ v_i = - x_i + \\lambda \\sum_{j\\neq i} \\frac{1}{x_i-x_j} $$\n\n\nParticles drift away from each other\n\n\n\n\n\nBut of course we don’t usually know the wavefunction…"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#reinforcement-learning",
    "href": "talks/rl4qm-deepmind/index.html#reinforcement-learning",
    "title": "Austen Lamacraft",
    "section": "Reinforcement Learning",
    "text": "Reinforcement Learning\n\nRecall cost\n\n\\[\n  C_T[\\mathbf{v}] = \\frac{1}{T}\\E\\left[\\int_0^T\\left[\\frac{1}{2}(\\mathbf{v}(\\br_t,t))^2 + V(\\br_t)\\right]dt\\right],\n\\]\n\nSuggests strategy:\n\nRepresent $\\bv_\\theta(\\br) = \\textsf{NN}_\\theta(\\br)$\nIntegrate batch of SDE trajectories\nBackprop through the (MC estimated) cost"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#drift-representation",
    "href": "talks/rl4qm-deepmind/index.html#drift-representation",
    "title": "Austen Lamacraft",
    "section": "Drift Representation",
    "text": "Drift Representation\n\nFor identical particles require permutation equivariance\n\n$$  \\bv_{i,\\theta}(\\br_1,\\ldots,\\br_N = \\bv_{P(i),\\theta}(\\br_{P(1)},\\ldots,\\br_{P(N)}) $$\n\n…for any permutation \\(P\\)\n\n\nNumerous recent proposals e.g. Deep Sets (Zaheer et al., 2017)"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#integrate-sde",
    "href": "talks/rl4qm-deepmind/index.html#integrate-sde",
    "title": "Austen Lamacraft",
    "section": "Integrate SDE",
    "text": "Integrate SDE\n\nSimplest scheme is Euler–Maruyama\n\n$$     \\br_{t+1} = \\br_{t+1} + \\Delta\\mathbf{B}_t + \\bv_\\theta(\\br_t)\\Delta t, $$\n\n\\(\\Delta\\mathbf{B}_t\\sim \\mathcal{N}(0,t)\\)\nWe use SOSRA (Rackaukas and Nie, 2018)\nCan regard as (recurrent) resnet Neural ODE, (Chen et al., 2018)\nEvolve batch of trajectories from final state of previous batch\nBatch tracks stationary state of current \\(\\bv_\\theta\\)"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#stochastic-backprop",
    "href": "talks/rl4qm-deepmind/index.html#stochastic-backprop",
    "title": "Austen Lamacraft",
    "section": "Stochastic Backprop",
    "text": "Stochastic Backprop\n\\[\n  C_T[\\mathbf{v}] = \\frac{1}{T}\\E\\left[\\int_0^T\\left[\\frac{1}{2}(\\mathbf{v}(\\br_t,t))^2 + V(\\br_t)\\right]dt\\right],\n\\]\n\nMonte Carlo estimate from batch of \\(B\\) trajectories\n\n$$     C_T[\\bv_\\theta] \\approx \\frac{1}{B T} \\sum_{b,t}\\left[\\frac{1}{2}\\bv_\\theta\\left(\\br^{(b)}_t\\right)^2 + V\\left(\\br^{(b)}_t\\right)\\right]. $$\n\n\\(\\br^{(b)}_{t}\\) from SDE discretization. Analogous to reparameterization trick"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#experiments",
    "href": "talks/rl4qm-deepmind/index.html#experiments",
    "title": "Austen Lamacraft",
    "section": "Experiments",
    "text": "Experiments\n\nHydrogen and Helium atoms\nHydrogen molecule\n2D Bosons in harmonic potential with Gaussian interactions\n\n\n…all errors around 1% at the moment without exploiting symmetries"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#hydrogen-1-electron",
    "href": "talks/rl4qm-deepmind/index.html#hydrogen-1-electron",
    "title": "Austen Lamacraft",
    "section": "Hydrogen: 1 electron",
    "text": "Hydrogen: 1 electron\n\\[\nH = -\\frac{\\nabla^2}{2} - \\frac{1}{|\\br|}\n\\]\n\nGround state $\\varphi_0(r) = \\pi^{-1/2}e^{-r}$. \\(E_0=-\\frac{1}{2}\\)\nDrift \\(v(\\br)=-\\hat\\br\\)"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#helium-2-electrons",
    "href": "talks/rl4qm-deepmind/index.html#helium-2-electrons",
    "title": "Austen Lamacraft",
    "section": "Helium: 2 electrons",
    "text": "Helium: 2 electrons\n\\[\nH = -\\frac{\\nabla_1^2+\\nabla_2^2}{2} - \\frac{2}{|\\br_1|} - \\frac{2}{|\\br_2|} + \\frac{1}{|\\br_1-\\br_2|}\n\\]\n\nGround state spins antisymmetric\nSpatial wavefunction symmetric\n\\(\\varphi_0(\\br_1,\\br_2)\\) not known exactly but \\(E_0=-2.903386\\)"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#hydrogen-molecule",
    "href": "talks/rl4qm-deepmind/index.html#hydrogen-molecule",
    "title": "Austen Lamacraft",
    "section": "Hydrogen Molecule",
    "text": "Hydrogen Molecule\n$$ \\begin{align} H &= -\\frac{\\nabla_1^2+\\nabla_2^2}{2}+ \\frac{1}{|\\br_1-\\br_2|}\\\\  &- \\sum_{i=1,2}\\left[\\frac{1}{|\\br_i-\\hat{\\mathbf{z}} R/2|} + \\frac{1}{|\\br_i+\\hat{\\mathbf{z}}R/2|}\\right] \\end{align} $$\n\nSpatial wavefunction again symmetric\nEquilibrium proton separation \\(R=1.401\\), \\(E_0= -1.174476\\)"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#exchange-processes",
    "href": "talks/rl4qm-deepmind/index.html#exchange-processes",
    "title": "Austen Lamacraft",
    "section": "Exchange Processes",
    "text": "Exchange Processes\n\nAt \\(R=8.5\\) tunnelling events are visible"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#d-gaussian-bosons",
    "href": "talks/rl4qm-deepmind/index.html#d-gaussian-bosons",
    "title": "Austen Lamacraft",
    "section": "2D Gaussian Bosons",
    "text": "2D Gaussian Bosons\n$$ \\begin{align} H&=\\frac{1}{2}\\sum_i \\left[\\nabla_i^2 +\\br_i^2\\right]+\\sum_{i&lt;j}U(\\br_i-\\br_j)\\\\ U(\\br) &=\\frac{g}{\\pi s^2}e^{-\\br^2/s^2} \\end{align} $$\n\nMujal et al., PRA 2017 model for ultracold atoms\n\n\n\n\n\n\nDrift Visualization (\\(g=10\\), $s=1/2$)"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#outlook",
    "href": "talks/rl4qm-deepmind/index.html#outlook",
    "title": "Austen Lamacraft",
    "section": "Outlook",
    "text": "Outlook\n\nExcited states; angular momentum ↔︎ non-reversible drift\nFermions?\nLattice models"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#next-up-lattice-models",
    "href": "talks/rl4qm-deepmind/index.html#next-up-lattice-models",
    "title": "Austen Lamacraft",
    "section": "Next Up: Lattice Models",
    "text": "Next Up: Lattice Models"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#xy-model",
    "href": "talks/rl4qm-deepmind/index.html#xy-model",
    "title": "Austen Lamacraft",
    "section": "XY model",
    "text": "XY model\n\nOn chain / square / cubic lattice\n\n$$ \\begin{align} \\partial_t \\Psi_{\\Huge\\circ\\Huge\\bullet\\Huge\\circ} &= \\Psi_{\\Huge\\bullet\\Huge\\circ\\Huge\\circ}+\\Psi_{\\Huge\\circ\\Huge\\circ\\Huge\\bullet}\\\\ &=\\overbrace{ \\Psi_{\\Huge\\bullet\\Huge\\circ\\Huge\\circ}+\\Psi_{\\Huge\\circ\\Huge\\circ\\Huge\\bullet}-2\\Psi_{\\Huge\\circ\\Huge\\bullet\\Huge\\circ}}^{\\text{master / forward eq.}} +2 \\Psi_{\\Huge\\circ\\Huge\\bullet\\Huge\\circ} \\end{align} $$\n\nc.f. imaginary time Schrödinger\n\n\\[\n  \\frac{\\partial\\psi(\\br,t)}{\\partial t} = \\left[\\frac{\\nabla^2}{2}-V(\\br_i)\\right]\\psi(\\br,t)\n\\]\n\n\\(\\exists\\) Feynamn–Kac representation!"
  },
  {
    "objectID": "talks/rl4qm-deepmind/index.html#linearly-solvable-mdps",
    "href": "talks/rl4qm-deepmind/index.html#linearly-solvable-mdps",
    "title": "Austen Lamacraft",
    "section": "Linearly Solvable MDPs",
    "text": "Linearly Solvable MDPs\n\nTodorov (2017) introduced cost\n\n$$   \\ell(j,v) = q(j) +   D_{\\text{KL}}\\left(v(\\cdot|j) \\middle\\|\\middle\\| p(\\cdot|j)\\right) $$\n\n\\(v(j|k)\\) is controlled dynamics, \\(p(j|k)\\) is “passive dynamics”\nBellman equation for the cost to go \\(\\nu(j,t)\\)\n\n$$ \\nu(k,t) = \\min_v\\left[\\ell(k,u) + \\E_{j\\sim u(\\cdot|k)}\\nu(j,t+1)\\right] $$\n\n\nTransform to linear equation for desirability \\(\\Psi(j,t) = \\exp(-\\nu(j,t))\\)\nOptimal dynamics\n\n\\[\n  u^*(j|k)=\\frac{p(j|k)\\Psi(j)}{\\sum_{l}p(l|k)\\Psi(l)},\n\\]\n\nLinear equation\n\n$$ \\Psi(k,t) = e^{-q(k)}\\sum_{j}p(j|k)\\Psi(j,t+1). $$\n\nDiscrete imaginary time Schrödinger equation\n\n\nAny model with FK formula has control rep.!"
  },
  {
    "objectID": "talks/ml-stat-mech-2/index.html",
    "href": "talks/ml-stat-mech-2/index.html",
    "title": "ML and SM 2",
    "section": "",
    "text": "ML and SM 2\n\nSlides: austen.uk/slides/ml-stat-mech-2\nText: austen.uk/post/ml-stat-mech-2\n\n\n\nRecap\n\nLecture 1 introduced idea of Variational Inference (VI)\nTurns inference in latent variable models into optimization\nToday: how to leverage neural networks & automatic differentiation\nModel of choice: Variational Autoencoder\n\n\n\\[\n\\DeclareMathOperator*{\\E}{\\mathbb{E}}\n\\newcommand{\\cE}{\\mathcal{E}}\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\bx}{\\mathbf{x}}\n\\newcommand{\\bz}{\\mathbf{z}}\n\\newcommand{\\br}{\\mathbf{r}}\n\\newcommand{\\bv}{\\mathbf{v}}\n\\newcommand{\\bmu}{\\boldsymbol{\\mu}}\n\\newcommand{\\bSigma}{\\boldsymbol{\\Sigma}}\n\\newcommand{\\bzeta}{\\boldsymbol{\\zeta}}\n\\]\n\n\nVI redux\n\nModel defined by prior \\(p(z)\\) and generative model \\(p\\_\\phi(x|z)\\)\nSimilar model for posterior \\(q\\_\\theta(z|x)\\)\nTwo representatios of \\(p(x,z)\\): forward and backward \\[\np_\\text{F}(x,z)= p_\\theta(x|z)p(z),\\qquad p_\\text{B}(x,z)= q_\\phi(z|x)p_\\text{D}(x).\n\\] where \\(p_\\text{D}(x)\\) is data distribution\n\n\n\nKL between these two models \\[\nD_\\text{KL}(p_\\text{B}||p_\\text{F})= \\E_{x\\sim \\text{Data}}\\left[\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log\\left(\\frac{q_\\phi(z|x)p_\\text{D}(x)}{p_\\theta(x|z)p(z)}\\right)\\right]\\right]\\geq 0.\n\\] or \\[\nH[p_\\text{D}]\\leq \\E_{x\\sim \\text{Data}}\\left[\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log\\left(\\frac{q_\\phi(z|x)}{p_\\theta(x|z)p(z)}\\right)\\right]\\right].\n\\]\nRHS doesn’t involve \\(p_\\text{D}(x)\\) explicitly, only expectation. This is implemented as empirical average over (batches of) data\n\n\n\nRHS often presented as\n\n\\[\n\\E_{x\\sim \\text{Data}}\\left[D_\\text{KL}(q_\\phi(\\cdot|x)||p)-\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log p_\\theta(x|z)\\right]\\right].\n\\]\n\nFirst term small when posterior matches prior\nSecond small when model matches data (reconstruction error)\n\n\n\n\nVariational autoencoder\n\nAbove picture fits into Autoencoder framework\n\n\n\n\n\nAutoencoder trained to return outputs close to inputs\nNot trivial if \\(\\text{dim}\\\\,\\textbf{h}&lt;\\text{dim}\\\\,\\textbf{x}\\)!\n\n\n\nWe have a loss function for VI in autoencoder framework \\[\n\\mathcal{L}(\\theta,\\phi)=\\E_{x\\sim \\text{Data}}\\left[D_\\text{KL}(q_\\phi(\\cdot|x)||p)-\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log p_\\theta(x|z)\\right]\\right]\n\\]\nWe need\n\nTo parameterize \\(p_\\theta(x|z)\\) and \\(q_\\phi(z|x)\\) using NNs.\nTo take gradients of the loss function to perform optimization.\n\nLet’s look at these in turn.\n\n\n\n\nParameterization\n\n\\(\\bz\\in \\R^{H}\\), \\(\\bx\\in \\R^{D}\\)\nFor encoder \\(q_\\phi(\\bz|\\bx)\\), choose \\(\\mathcal{N}(\\bmu_\\phi(\\bx),\\bSigma_\\phi(\\bx))\\)\nIf prior is \\(\\mathcal{N}(0,\\mathbb{1})\\) the KL term loss can be evaluated explicitly.\n\\(\\bmu_\\phi(\\bx)\\) and \\(\\bSigma_\\phi(\\bx)\\) are parameterized using NNs, with architecture adapted to the data e.g. Convolutional neural networks for images\n\n\n\nSimilarly for decoder $p_\\theta(\\cdot|\\bz)=\\mathcal{N}(\\bmu'_\\theta(\\bz),\\bSigma'_\\theta(\\bz))$\nSecond term of loss involves $$ -\\log p_\\theta(\\bx|\\bz) = \\frac{1}{2}(\\bx-\\bmu'_\\theta(\\bz))^T\\bSigma'^{-1}_\\theta(\\bz)(\\bx-\\bmu'_\\theta(\\bz))+\\frac{1}{2}\\log\\det\\bSigma_\\theta'(\\bz)+\\text{const.}, $$ encourages mean output \\(\\bmu'\\_\\theta(\\bz)\\) to be close to \\(\\bx\\)\nRequired expectation over \\(\\bz\\) requires Monte Carlo\nProblem: expectation depends on parameters \\(\\phi\\), and we want derivatives\nWhat do we do?\n\n\n\n\nReparameterization trick\n\nIf you have \\(\\zeta\\sim\\mathcal{N}(0,1)\\) then \\(\\sigma \\zeta +\\mu\\sim \\mathcal{N}(\\mu,\\sigma^2)\\)\nSeparates parameters from sampling, so that a Monte Carlo estimate of an expectation \\[\n\\E_{x\\sim \\mathcal{N}(\\mu,\\sigma^2)}\\left[f(x)\\right]\\approx \\frac{1}{S}\\sum_{s=1}^S f(\\sigma z_s + \\mu)\n\\] is explicitly a function of \\(\\sigma\\) and \\(\\mu\\), so derivatives may be taken\nGeneralizes to multivariate Gaussian: \\(\\bz\\sim \\bSigma_\\phi^{1/2}(\\bx)\\bzeta+\\mu_\\phi(\\bx)\\).\n\n\n\n\nMore practicalities\n\nIn practice a single \\(\\bz\\) sample is usually found to provide useful gradients for optimization\nLarge datasets usually split into batches (sometimes called mini-batches)\nFor batch of size \\(B\\) loss function is estimated using \\(B\\) iid $ _b(0,)$ \\[\n\\mathcal{L}(\\theta,\\phi)\\approx\\frac{1}{B}\\sum_{b=1}^B\\left[D_\\text{KL}(q_\\phi(\\cdot|\\bx_b)||p)-\\log p_\\theta(\\bx_b|\\bSigma_\\phi^{1/2}(\\bx_b)\\bzeta_b+\\mu_\\phi(\\bx_b))\\right]\n\\]\nGradients calculated by automatic differentiation, implemented in all modern DL libraries\nThere’s a great deal of craft to the business of training…\n\n\n\n\nInterpretability\n\nOne promise of latent variable models is an interpretable latent space\nMoving in lower dimensional latent space \\(\\R^H\\) allows us to explore the manifold in which the data is embedded in \\(\\R^D\\)\n\n\n\nSome issues:\n\nLoss function doesn’t require that the latent space is used at all. If decoder model \\(p\\_\\theta(\\bx|\\bz)\\) is rich enough may have \\(p\\_\\theta(\\bx|\\bz)\\approx p\\_\\text{D}(\\bx)\\). By Bayes’ theorem posterior is \\[\n  \\frac{p\\_\\theta(\\bx|\\bz)p(\\bz)}{p\\_\\text{D}(\\bx)}\\approx p(\\bz),\n  \\] same as the prior! This is posterior collapse\nNo guarantee that latent space is used nicely, e.g. with variables for colour, shape, position, etc. (disentangled representation). One problem: prior \\(\\mathcal{N}(0,\\mathbb{1})\\) is rotationally invariant, so lifting symmetry is necessary.\n\n\n\n\n\nCompression with VAEs: bits back\n\nIn Lecture 1 I suggested that good probabilistic models could give better compression\nHow does this work for latent variable models like VAE?\nProblem, as always, is that model doesn’t have explicit \\(p_\\text{M}(x)\\): marginalizing over latent variables is intractable.\n\n\n\n\nRecall that loss function of VAE is based\n\n\\[\nH[p_\\text{D}]\\leq \\E_{x\\sim \\text{Data}}\\left[\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log\\left(\\frac{q_\\phi(z|x)}{p_\\theta(x|z)p(z)}\\right)\\right]\\right].\n\\]\n\nSplit RHS into three terms\n\n\\[\n\\E_{x\\sim \\text{Data}}\\left[\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log\\left(q_\\phi(z|x)\\right)-\\log\\left(p_\\theta(x|z)\\right)-\\log\\left(p(z)\\right)\\right]\\right].\n\\]\n\nRemember \\(-\\log_2 p(x)\\) is length in bits of optimal encoding of \\(x\\). Last two terms could be interpreted as\n\nGiven data \\(x\\) we sample \\(z\\sim q_\\phi(\\cdot|x)\\).\nWe encode \\(x\\) using the distribution \\(p_\\theta(\\cdot|z)\\), then\nEncode \\(z\\) using the prior \\(p(\\cdot)\\).\n\n\n\n\nFor decoding, go in reverse\n\nDecode \\(z\\) using the prior \\(p(z)\\).\nDecode \\(x\\) using \\(p\\_\\theta(\\cdot|z)\\)\n\nWe’ll never reach Shannon bound this way, however, because of the negative first term in\n\n\\[\n\\E_{x\\sim \\text{Data}}\\left[\\E_{z\\sim q_\\phi(\\cdot|x)}\\left[\\log\\left(q_\\phi(z|x)\\right)-\\log\\left(p_\\theta(x|z)\\right)-\\log\\left(p(z)\\right)\\right]\\right].\n\\]\n\nWe need to make the code shorter. How?\n\n\n\nRemember that Shannon bound applies in limit of \\(N\\to\\infty\\) iid data\nImagine a semi-infinite bit stream mid-way through encoding\n\nWe decode part of already encoded bitstream using \\(q\\_\\phi(\\cdot|x)\\)\nResult is \\(z\\sim q\\_\\phi(\\cdot|x)\\): use for encoding \\(x\\) as described above\nThese are bits back: remove \\(H(q\\_\\phi(\\cdot|x))\\) bits on average\nAllows us to reach the Shannon bound\n\nWhen decoding data, the last thing we do for each \\(x\\) is encode \\(z\\) back to the bitstream using \\(q\\_\\phi(\\cdot|x)\\)\n\n\n\n\nRelated Models\nThe VAE framework is quite general, and in recent years has been elaborated in various ways.\n\n\n\nMarkov chain autoencoders (??)\n\nUp to now our encoder and decoder were just Gaussian models\nCan we produce a model with a richer distribution?\nMake forward and backward models Markov processes with \\(T\\) steps \\[\np_\\text{F}(z_0,\\ldots x=z_T) = p_\\theta(x=z_T|z_{T-1})p_\\theta(z_{T-1}|z_{T-2})\\cdots p_\\theta(z_1|z_{0})p(z_0)\n\\] \\[\np_\\text{B}(z_0,\\ldots \\ldots x=z_T) = q_\\phi(z_0|z_{1})\\cdots q_\\phi(z_{T-2}|z_{T-1})q_\\phi(z_{T-1}|z_T)p_\\text{D}(x=z_T)\n\\]\nLoss function is\n\n\\[\nH[p_\\text{D}]\\leq \\E_{z\\sim p_\\text{B}}\\left[\\log \\left(\\frac{q_\\phi(z_0|z_1)}{p(z_0)}\\right)+\\sum_{t=0}^{T-2}\\log\\left(\\frac{q_\\phi(z_{t+1}|z_{t+2})}{p_\\theta(z_{t+1}|z_t)}\\right)\\right].\n\\]\n\n\nCan pass to continuous time limit, in which case \\(z_t\\) described by stochastic differential equation (SDE). \\[\ndz_t = \\mu_\\theta(z_t)dt + dW_t\n\\] \\(W_t\\) is \\(\\R^H\\) dimensional Brownian motion, \\(\\mu\\_\\theta(z\\_t)\\) is a parameterized drift\nOne forward and one backward SDE\nModel is separate from implementation of dynamics. Solve SDE by whatever method you like: AD through solution.\n\n\n\nPossible applications\n\nInfer the trajectories that led to measured outcomes in stochastic dynamics.\n\nForward model describes a simulation of a physical system – e.g. molecular dynamics simulation of a biomolecule\nBackward model can be used to infer trajectories that led to some measured states \\(z_T\\).\n\nFix the backward model and just learn the forward model. Seems strange from point of view of finding posterior\n\n\n\n\n\nDenoising Diffusion Probabilistic Models\n\n\n\n\n\n\n\n\n\n\n\n\nNormalizing flows\n\nAutoencoders conceived for \\(H&lt;D\\)\nBy taking \\(\\R^H=\\R^D\\) can make contact with: Normalizing Flows\nTake \\(\\bSigma_\\phi\\) and \\(\\bSigma'_\\theta\\to 0\\), so that \\(q_\\phi(\\bz|\\bx)\\) and \\(p_\\theta(\\bx|\\bz)\\) become deterministic\n\n\\[\n\\bz = \\mu_\\phi(\\bx),\\qquad \\bx = \\mu'_\\theta(\\bz).\n\\]\n\n\\(D_\\text{KL}\\neq 0\\) only if they are inverses\n\n\n\nWhat is KL? $$ q_\\phi(\\cdot|\\bx) = \\frac{1}{\\sqrt{(2\\pi)^{D} \\det\\bSigma_\\phi(\\bx)}} \\exp\\left[-\\frac{1}{2}(\\bz-\\bmu_\\phi(\\bx))^T\\bSigma^{-1}_\\phi(\\bx)(\\bz-\\bmu_\\phi(\\bx))\\right], $$\nKL involves the ratio $$ \\frac{q_\\phi(\\bz|\\bx)}{p_\\theta(\\bx|\\bz)} $$\nWhen \\(\\bz\\) and \\(\\bx\\) are inverses $$ \\frac{q_\\phi(\\bz|\\bx)}{p_\\theta(\\bx|\\bz)}\\longrightarrow \\sqrt{\\frac{\\det\\bSigma'_\\theta(\\bz)}{\\det\\bSigma_\\phi(\\bx)}}=\\det \\left(\\frac{\\partial\\bx}{\\partial\\bz}\\right). $$\n\n\n\nIf \\(\\bz\\) described by \\(p(\\bz)\\) then \\(\\bx=\\mu'\\_\\theta(\\bz)\\) has density \\[\n\\det\\left(\\frac{\\partial\\bz}{\\partial\\bx}\\right) p(\\mu_\\phi(\\bx)).\n\\] i.e. we map to \\(\\bz\\) and evaluate density there, accounting for Jacobian\nIn deterministic limit, KL becomes \\[\nD_\\text{KL}(p_\\text{B}||p_\\text{F})\\longrightarrow -\\E_{x\\sim \\text{Data}}\\left[\\log\\det \\left(\\frac{\\partial\\bz}{\\partial\\bx}\\right)+\\log p(\\mu_\\phi(\\bx))\\right].\n\\]\nChallenge: construct flexible, invertible models with tractable Jacobians (determinant is \\(O(D^3)\\))\nStack simpler transformations, each invertible with known Jacobian.\n\n\n\n\nLearning the path integral\nBarr, Gispen, Lamacraft (2020)\n\n\n\nFeynman–Kac formula\n\nFor “imaginary time” Schrödinger \\[\n\\left[-\\frac{\\nabla^2}{2m}+V(\\br_i)\\right]\\psi(\\br,t) = -\\partial_t\\psi(\\br,t)\n\\]\nFeynman–Kac formula expresses \\(\\psi(\\br,t)\\) as expectation… $$   \\psi(\\br_2,t_2) =  \\E_{\\br_t}\\left[\\exp\\left(-\\int_{t_1}^{t_2}V(\\br_t)dt\\right)\\psi(\\br_{t_1},t_1)\\right] $$\n\n…over Brownian paths with \\(\\br_{t_{2}}=\\br_{2}\\)\n\nFor \\(t\\to\\infty\\): \\(\\psi(\\br,t)\\to e^{-E_0 t}\\varphi_0(\\br)\\)\n\n\n\nPath integral Monte Carlo\n\n\n\n\n\n Ceperley, RMP (1995) \n\n\n\n\nLoss function\n\nFK formula defines path measure \\(\\mathbb{P}_\\text{FK}\\)\nJamison (1974): process is Markovian \\[\nd\\br_t = d\\mathbf{W}_t + \\bv(\\br_t,t)dt\n\\]\nModel drift \\(\\bv(\\br,t)\\) defines measure \\(\\mathbb{P}_\\bv\\)\n\\(D_\\text{KL}(\\mathbb{P}_\\bv\\lvert\\rvert \\mathbb{P}_\\text{FK})=\\E_{\\mathbb{P}_\\bv}\\left[\\log\\left(\\frac{d\\mathbb{P}_\\bv}{d\\mathbb{P}_\\text{FK}}\\right)\\right]\\) is our loss function\nRL / Optimal Control formulation of QM (Holland, 1977)\n\n\n\n\nTraining\n\nRelative likelihood (Radon–Nikodym derivative; Girsanov theorem)\n\n$$   \\log\\left(\\frac{d\\mathbb{P}_{\\bv}}{d\\mathbb{P}_\\text{FK}}\\right) =\\ell_T - E_0 T+\\log\\left(\\frac{\\varphi_0(\\br_0)}{\\varphi_0(\\br_T)}\\right) $$ \\[\n   \\ell_T\\equiv \\int_0^T \\bv(\\br_t)\n  \\cdot d\\mathbf{W}_t+\\int_0^T dt\\left(\\frac{1}{2}|\\bv(\\br_t)|^2+V(\\br_t)\\right)\n\\]\n\nMonte Carlo estimate of \\(D_\\text{KL}(\\mathbb{P}_\\bv\\lvert\\rvert \\mathbb{P}_\\text{FK})=\\E_{\\mathbb{P}_\\bv}\\left[\\log\\left(\\frac{d\\mathbb{P}_\\bv}{d\\mathbb{P}_\\text{FK}}\\right)\\right]\\)\n\\(\\br^{(b)}_{t}\\) from SDE discretization. Analogous to reparameterization trick\n\\(D_\\text{KL}(\\mathbb{P}_\\bv\\lvert\\rvert \\mathbb{P}_\\text{FK})\\geq 0\\) so \\(\\E_{\\mathbb{P}_\\bv}\\left[\\ell_T\\right]\\geq E_0T\\)\n\n\n\nSuggests strategy:\n\nRepresent $\\bv_\\theta(\\br) = \\textsf{NN}_\\theta(\\br)$\nIntegrate batch of SDE trajectories\nBackprop through the (MC estimated) cost\n\n\n\n\n\n\n\n\nHydrogen Molecule\n$$ H = -\\frac{\\nabla_1^2+\\nabla_2^2}{2}+ \\frac{1}{|\\br_1-\\br_2|}- \\sum_{i=1,2}\\left[\\frac{1}{|\\br_i-\\hat{\\mathbf{z}} R/2|} + \\frac{1}{|\\br_i+\\hat{\\mathbf{z}}R/2|}\\right] $$\n\nEquilibrium proton separation \\(R=1.401\\), \\(E_0= -1.174476\\)\n\n\n\n\n\n\n\n2D Gaussian Bosons\n$$ \\begin{align} H&=\\frac{1}{2}\\sum_i \\left[-\\nabla_i^2 +\\br_i^2\\right]+\\sum_{i&lt;j}U(\\br_i-\\br_j)\\\\ U(\\br) &=\\frac{g}{\\pi s^2}e^{-\\br^2/s^2} \\end{align} $$\n\nMujal et al., PRA 2017 model for ultracold atoms\n\n\n\n\n\n\nDrift Visualization (\\(g=15\\), $s=1/2$)"
  },
  {
    "objectID": "talks/new-rules-tum/index.html",
    "href": "talks/new-rules-tum/index.html",
    "title": "New Rules:",
    "section": "",
    "text": "austen.uk/slides/new-rules-tum\nAusten Lamacraft and Pieter Claeys\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEach site either dead (0) or alive (1)\nFate of cell determined by eight neighbors\n\nAny live cell with two or three live neighbours survives\nAny dead cell with three live neighbours becomes a live cell\nAll other live cells die in the next generation\n\nComplex behavior!\n\n\n\n\n\n\nDynamical systems with discrete space, time, and degrees of freedom\nInteresting for statistical physics:\n\nWhat kinds of dynamics may occur?\nHow does dynamics determine thermodynamic behavior?\n\n\n\n\n\n\n\nA quantum analog of CAs\nBasis of “quantum supremacy” work by Google and others\n\n\n\n\nA schematic view of the Google Sycamore processor.\n\n\n\n\n\n\n\nWhat are the similarities and differences? Can we try the same tricks?\nWhen is quantum dynamics harder?\nWhat about measurements?\n\n\n\n\n\n\n“Space” is one dimension with cells \\(x_n=0,1\\) \\(n\\in\\mathbb{Z}\\)\nUpdate cells every time step depending on cells in neighborhood\n\nNeighborhood is cell and two neighbors for elementary CA\n\n\n\n\nUpdate specified by function\n\n\\[\nf:\\\\{0,1\\\\}^3\\longrightarrow \\\\{0,1\\\\}.\n\\]\n\\[\nx^{t+1}_{n} = f(x^{t}\\_{n-1},x^{t}\\_{n},x^{t}\\_{n+1})\n\\]\n\nHow many possible functions?\n\n\n\n\n\n\nDomain of \\(f\\) is \\(2^3=8\\) possible values for three cells\n\\(2^8=256\\) possible choices for the function \\(f\\)\nList outputs corresponding to inputs: 111, 110, … 000\n\n\n\n\n111\n110\n101\n100\n011\n010\n001\n000\n\n\n\n\n0\n1\n1\n0\n1\n1\n1\n0\n\n\n\n\nInterpret as binary number: this one is Rule 110\n\n\n\nMany behaviors, from ordered (Rule 18) to chaotic (Rule 30)\n\n\n\n\n\n\n\n\nRule 110 is capable of universal computation!\n\n\n\n\n\nThat’s Christmas sorted\n\n\n\n\n\n\n\n\n\ngive each pixel a random Pokemon type, and then battle pixels against their neighbors, updating each pixel with the winning type (using the Pokemon type chart)we quickly see areas of fire &gt; water &gt; grass &gt; fire, electric sweeping over, ground frontiers taking over etc etc pic.twitter.com/BHgQuKRApR\n\n— Matt Henderson (@matthen2) July 2, 2022\n\n\n\n\n\n\n\nNotion of a causal “light cone” (45 degree lines)\nVariety of possible behaviors: chaos, periodicity, …\n\n\n\n\n\n\nRapid growth of small differences between two trajectories\n\n\n\n\n\n\n\n\nSmallest change: flip one site and monitor \\(z^t\\equiv x^t\\oplus y^t\\)\n\n\n\n\n\n\nNo exponential growth (c.f. Lyapunov exponent in continuous systems)\nTrack number of differences (Hamming distance) between trajectories\nPropagating “front” cannot exceed “speed of light”: generally slower\n\n\n\n\n\n\nNo chance of solving the dynamics of any one CA\nLooking for generic properties: natural to consider ensembles\n\nof initial conditions\nof rules\n\n\n\n\n\n\n\nChoose rules iid for each site and instant\n\n\n\n\n\n\n\n\nCell values are now white noise, but \\(z_t=x_t\\oplus y_t\\) revealing\nFluctuations of front are larger and average speed \\(&lt;\\) maximum\n\n\n\n\n\n\nNo elementary CAs are reversible (bijective)! Requires size 4 neighborhood\nReversibility is undecidable above one spatial dimension\n\\(∃\\) reversible constructions\n\n\n\n\n\n\nFredkin construction\n\n$$ x^{t+1}_{n} = f(x^{t}_{n-1},x^{t}_{n},x^{t}_{n+1}) + x^{t-1}_{n},\\, \\mod 2 $$\n\n\n\n\n$$ x^{t+1}_{n} = x^{t}_{n-1} x^{t-1}_{n} + x^{t}_{n+1} + x^{t}_{n-1}x^{t}_{n+1}\\, \\mod 2 $$\n\nInterpret as “tiling rules”\n\n\n \n\nFrom Buca, Klobas, and Prosen (2021)\n\n\n\nRandom tilings consistent with constraint have entropy \\(\\propto L\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartition cells into blocks (Margolus neighborhoods)\nApply invertible mapping to block\nAlternate overlapping partitions\n\n\n\n\n\n\n\n\n\nBlue squares: invertible mapping on states of two sites: 00, 01, 10, 11\n\n\n\n\n\ngiven these four jigsaw pieces, there is only one way to fill in the rest of the puzzle. The solution ends up drawing a Sierpinski triangle. Can you see why? pic.twitter.com/OvxVz2oehy\n\n— Matt Henderson (@matthen2) May 25, 2022\n\n\n\n\n\n\n\n\nEach block a permutation of 00, 01, 10, 11\n\\(4!=24\\) blocks\nOrder:\n\n\n\n\n\n\n\n(1324), and so on\n\nBlock 2 is the map \\((00, 01, 10, 11) ⟶ (00, 10, 01, 11)\\)\nExchange, or SWAP gate in quantum information\n\n\n\n\n\n\n\n\n\nEnsemble of block CAs similar to PCA\n\n\n\n\n\nCan we find an ensemble where front propagates at maximal speed?\nYes! Dual reversible blocks are bijections in both time and space\nThere are 12 such blocks (out of 24)\nEnsemble is Markov in time and space: must have maximal velocity!\n\n\n\n\n\n\nFor \\(N=2\\) dynamics of \\(z_t=x_t\\oplus y_t\\) independent of \\(x_t\\) (or \\(y_t\\))\nRecurrence time always \\(\\propto L\\) (instead of double exponential)\nEdge corresponds to the stationary state of a Markov process (c.f. Claeys and Lamacraft (2020) for quantum case)\n\n\n\n\n\n\nBorsi and Pozsgay (2022) find 227 inequivalent dual reversible models\n\n\n\n\n\n\n\n\n\n\n\n\\[\n(c,d) = f(a,b) = (a + b, a - b)\\, \\mod 3\n\\]\n\nOriginal dual unitary circuit from Hosur et al.\nUnusual behavior of recurrence time\n\nFor \\(L = 2\\times 3^m\\) have \\(T_\\text{recur}=2L\\)\nBorsi and Pozsgay prove using Fourier analysis over finite fields\n\n\n\n\n\n\n\n\n\n\\(L=54=2\\times 3^3\\), \\(T_\\text{recur}=2L=108\\)\n\n\n\n\n\n\n\nDisjoint regions \\(A\\) and \\(\\bar A\\): how much does one tell about the other?\nUse mutual information: measure of dependence of random variables\nSuggested in this context by Pizzi et al. (2022)\n\n\n\nMI defined as \\[\nI(X;Y) \\equiv S(X) + S(Y) - S(X,Y)\n\\]\n\n\\(S(X)\\) is entropy of \\(p_X(x)\\); marginal distribution of \\(X\\)\n\\(S(Y)\\) is entropy of \\(p_Y(y)\\); marginal distribution of \\(Y\\)\n\\(S(X,Y)\\) is entropy of joint distribution \\(p_{(X,Y)}(x,y)\\)\n\nVanishes if \\(p_{(X,Y)}(x,y)=p_X(x)p_Y(y)\\)\n\n\n\n\n\n\n\n\nFrom Pizzi et al. (2022)\n\n\n\n\n\n\n\nSuppose either \\(X=Y=1\\) or \\(X=Y=0\\), with equal probability\n\n$$ \\begin{align} p_{(X,Y)}(0,0)&=p_{(X,Y)}(1,1)=1/2\\\\  p_{(X,Y)}(1,0)&=p_{(X,Y)}(0,1)=0 \\end{align} $$\n\\[\nI(X;Y)=S(X) + S(Y) - S(X,Y)= 1+1-1=1 \\text{ bit}\n\\]\n\n\n\n\n\n\n\n\nInitial distribution factorizes over correlated pairs\nApply SWAPs\n1 bit MI for every pair with one member in \\(A\\) and one in \\(\\bar A\\)\n\n\\[\nI(A;\\bar A) = \\min(4\\lfloor t/2\\rfloor, |A|) \\text{ bits}\n\\]\n\n\\(|A|\\) is (even) number of sites in \\(A\\)\n\n\n\n\n\n\nTotal entropy conserved (c.f Liouville’s theorem)\nEntropy of initial distribution is half max, but entropy \\(S(A)\\) saturates at maximal value (thermalization in time \\(\\sim |A|/2\\))\nThis model is not so special! Any of the dual reversible blocks CAs behaves exactly the same!\n\n\n\n\n\nFor reversibility and dual reversibility\n\n\n\n\n\n\n\n8 sites share 4 bits of entropy\n\n\n\n\nAfter four steps increases to (maximum) 8 bits!\n\n\n\n\n\n\n8 sites share 4 bits of entropy\n\n\n\n\nAfter two steps increases to 6 bits!\n\n\n\nEntropies of \\(A\\) and \\(\\bar A\\) subsystems behave just as in the toy model\n\n\\[\nI(A;\\bar A) = \\min(4\\lfloor t/2\\rfloor, |A|) \\text{ bits}\n\\]\n\n… for all dual reversible models!\n\n\n\n\n\n$$ \\begin{equation} \\begin{aligned} \\Phi_{\\tau}\\left(\\mathbf{S}_{1}, \\mathbf{S}_{2}\\right) &=\\frac{1}{\\sigma^{2}+\\tau^{2}}\\left(\\sigma^{2} \\mathbf{S}_{1}+\\tau^{2} \\mathbf{S}_{2}+\\tau \\mathbf{S}_{1} \\times \\mathbf{S}_{2}, \\sigma^{2} \\mathbf{S}_{2}+\\tau^{2} \\mathbf{S}_{1}+\\tau \\mathbf{S}_{2} \\times \\mathbf{S}_{1}\\right) \\\\ \\sigma^{2} &:=\\frac{1}{2}\\left(1+\\mathbf{S}_{1} \\cdot \\mathbf{S}_{2}\\right) \\end{aligned} \\end{equation} $$\n\n\n\nFrom Krajnik and Prosen (2020)\n\n\n\nMI has exactly the same behavior!\n\n\n\n\n\n\n\nCAs as dynamical systems: chaotic fronts and information dynamics\nDynamical ensembles as a theoretical tool\n\n\nHow can we extend these ideas to quantum systems?\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlock CA\nQuantum Circuit\n\n\n\n\nBasic unit\nInvertible map\nUnitary operator (gate)\n\n\nLocal variable\n\\(z_n \\in \\\\{0, 1\\\\}\\)\n\\(\\ket{\\psi_n}\\in \\mathbb{C}^2\\)\n\n\nGlobal state\n$z \\{0,1\\}^N $\n\\(\\ket{\\Psi(t)}\\in \\mathbb{C}^{2^N}\\)\n\n\nSimulation\nEasy\nHard\n\n\n\n\n\n\n\n\nModel of universal quantum computation\nExample of discrete time, many body quantum dynamics\n\n\nEveryone’s doing it!\n\n\n\n\n\n\n\\(n\\)-qubit unitary has matrix elements \\(U_{x_1\\ldots x_n,x'_1,\\ldots, x'_n}\\) in computational basis \\(\\ket{0}\\), \\(\\ket{1}\\)\nUnitarity means\n\n\\[\n\\sum\\_{x_1'\\ldots x_N'}U_{x_1\\ldots x_n,x'_1,\\ldots, x'_n} U^\\dagger\\_{x'_1\\ldots x'_n,x''_1,\\ldots, x''_n}=\\delta\\_{x_1,x_1''}\\ldots \\delta\\_{x_N,x_N''},\n\\]\n\nBut we’d like to avoid such awful looking expressions\n\n\n\n\n\n\nGeneral state of \\(N\\) qubits is\n\n$$ \\ket{\\Psi} = \\sum_{x_{1:N}\\in \\{0,1\\}^N} \\Psi_{x_1\\ldots x_N}\\ket{x_1}_1\\ket{x_2}_2\\cdots \\ket{x_N}_N $$\n\nWrite \\(\\ket{x_1}\\_1\\ket{x_2}\\_2\\cdots \\ket{x_N}\\_N =\\ket{x_1\\cdots x_N}=\\ket{x_{1:N}}\\) for brevity\nOperator on \\(N\\) qubits has matrix elements\n\n$$ \\mathcal{O}_{x_{1:N},x'_{1:N}} = \\bra{x_{1:N}}\\mathcal{O}\\ket{x'_{1:N}} $$\n\n\n\n\n\n\n\nSee Pan Zhang’s tutorial\n\n\n\n\n\n\n\n\n\n\nHave causality built in\nQuantum analog of (block) CAs\n\n\n\n\n\n\nWork in the basis \\(\\ket{00}\\), \\(\\ket{01}\\), \\(\\ket{10}\\), \\(\\ket{11}\\)\nSimplest example: SWAP gate\n\n\\[\n\\operatorname{SWAP}=\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\\\n0 & 0 & 1 & 0 \\\\\\\n0 & 1 & 0 & 0 \\\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n\\]\n\nSwitches states. Takes product state to product state\n\n\\[\n\\operatorname{SWAP}\\ket{10} = \\ket{01}\n\\]\n\n\n\n\n\\[\n\\sqrt{\\operatorname{SWAP}}=\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\\\n0 & \\frac{1}{2}(1+i) & \\frac{1}{2}(1-i) & 0 \\\\\\\n0 & \\frac{1}{2}(1-i) & \\frac{1}{2}(1+i) & 0 \\\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}.\n\\]\n\nGenerates entanglement (non product state)\n\n\\[\n\\sqrt{\\operatorname{SWAP}}\\ket{10} = \\frac{1}{2}\\left[(1+i)\\ket{10}+(1-i)\\ket{01}\\right]\n\\]\n\n\\(\\sqrt{\\operatorname{SWAP}}\\) and single qubit unitaries are universal gate set\n\n\n\n\n\n\nWe need both \\(U\\)s and \\(U^\\dagger\\)s (e.g. for \\(\\mathcal{O}(t)=U^\\dagger(t)\\mathcal{O}U(t)\\))\n\n\n\n\n\n\n\n\n\n\n\nMuch better!\n\n\n\n\n\n\n \n\n(left) Schematic view of the Google Sycamore processor (right)\n\n\n\n\n\n\n\nSampling from circuits basis of Google’s “quantum supremacy”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNormally matrix-vector multiplication is \\(O(\\operatorname{dim}^2)=2^{2N}\\)\nGates are sparse so \\(O(\\operatorname{dim})=2^{N}\\), but still exponentially hard\nFor low depth \\(T&lt;N\\) move horizontally instead\n\n\n\n\n\n\nEvaluate \\(\\bra{\\Psi}\\mathcal{O}\\ket{\\Psi}=\\bra{\\Psi_0}\\mathcal{U}^\\dagger\\mathcal{O}\\mathcal{U}\\ket{\\Psi_0}\\) for local \\(\\mathcal{O}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter folding, lines correspond to two indices / 4 dimensions\n\n\n\n\n\n\nCircle denotes \\(\\delta_{ab}\\)\n\n\n\n\n\n\n\n\n\nEmergence of “light cone”\n\n\n\n\n\n\n\n\nExpectation values in region \\(A\\) evaluated using reduced density matrix\n\n\\[\n\\rho_A = \\operatorname{tr}\\_{\\bar A}\\left[\\ket{\\Psi}\\bra{\\Psi}\\right]=\\operatorname{tr}_{\\bar A}\\left[\\mathcal{U}\\ket{\\Psi_0}\\bra{\\Psi_0}\\mathcal{U}^\\dagger\\right]\n\\]\n\n\n\n\n\n\n\n\\(\\rho_A\\) very useful for quantifying entanglement\nIf $\\ket{\\Psi} = \\ket{\\psi}_A \\otimes \\ket{\\phi}_{\\bar A}$ then \\(\\rho_A = \\ket{\\psi}_A\\bra{\\psi}_A\\)`\nAny deviation from product state leads to mixed density matrix\nQuantify by entropy of \\(\\rho_A\\) (the entanglement entropy)\n\n\\[\nS_A \\equiv -\\operatorname{tr}\\left[\\rho_A\\log \\rho_A\\right].\n\\]\n\n\n\n\n\n\n\n\nEach pair in Bell state $ \\ket{\\Phi^+}_{2n, 2n+1} = \\frac{1}{\\sqrt{2}}\\left[\\ket{0}_{2n}\\ket{0}_{2n+1}+ \\ket{1}_{2n}\\ket{1}_{2n+1}\\right] $\nReduced density matrix for one member: $\\operatorname{tr}_{2}\\left[\\ket{\\Phi^+}_{12}\\bra{\\Phi^+}_{12}\\right] = \\frac{1}{2}\\mathbb{1}_1$\nEntanglement entropy of 1 bit\n\n\n\n\n\n\nFor a Bell pair consisting of qubits at sites \\(m\\) and \\(n\\):\n\nIf \\(n\\in A\\), \\(m\\in\\bar A\\), \\(\\rho_A\\) has factor \\(\\mathbb{1}_n\\).\nIf \\(m, n\\in A\\) they contribute a factor \\(\\ket{\\Phi^+}\\_{nm}\\bra{\\Phi^+}\\_{nm}\\) (pure)\n\nOnly first case contributes to $  S_A = \\min(4\\lfloor t/2\\rfloor, |A|) \\text{ bits} $\nJust like mutual information in classical version!\n\n\n\n\n\n\nExactly the same behavior for all unitaries satisfying\n\n\n\n\n\nc.f. dual reversible CAs\n\n\n\n\n\n\n\\(4\\times 4\\) unitaries are 16-dimensional\nFamily of dual unitaries is 14-dimensional\nIncludes kicked Ising model at particular values of couplings\nDual unitaries not “integrable” but have enough structure to allow many calculations\n\n\n\n\n\n\n\n8 sites; 4 layers\n\n\n\n\n\\(\\rho_A\\) is unitary transformation of\n\n\\[\n  \\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\n\\]\n\n\n\n\n\n\n\n\\(\\rho_A\\) is unitary transformation of\n\n\\[\n\\mathbb{1}\\otimes\\mathbb{1}\\ket{\\Phi^+}\\bra{\\Phi^+}\\otimes\\ket{\\Phi^+}\\bra{\\Phi^+}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\n\\]\n\n\n\n\nRDM is unitary transformation of\n\n\\[\n\\rho_0=\\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1} \\otimes\\overbrace{\\ket{\\Phi^+}\\bra{\\Phi^+} \\cdots }^{N_A/2-t+1 } \\otimes \\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1}\n\\]\n\nRDM has \\(2^{\\min(2t-2,N_A)}\\) non-zero eigenvalues all equal to \\(\\left(\\frac{1}{2}\\right)^{\\min(2t-2,N_A)}\\)\nConverse – maximal entanglement growth implies dual unitary gates – recently proved by Zhou and Harrow (2022)\n\n\n\n\n\n\n\nAfter \\(N_A/2 + 1\\) steps, reduced density matrix is \\(\\propto \\mathbb{1}\\)\nAll expectations (with \\(A\\)) take on infinite temperature value\n\n\n\n\n\n\nTime dependent Hamiltonian with kicks at \\(t=0,1,2,\\ldots\\).\n\n$$ \\begin{aligned} H_{\\text{KIM}}(t) = H_\\text{I}[\\mathbf{h}] + \\sum_{m}\\delta(t-n)H_\\text{K}\\\\ H_\\text{I}[\\mathbf{h}]=\\sum_{j=1}^L\\left[J Z_j Z_{j+1} + h_j Z_j\\right],\\qquad H_\\text{K} &= b\\sum_{j=1}^L X_j, \\end{aligned} $$\n\n“Stroboscopic” form of \\(U(t)=\\mathcal{T}\\exp\\left[-i\\int^t H_{\\text{KIM}}(t') dt'\\right]\\)\n\n$$ \\begin{aligned}   U(n_+) &= \\left[U(1_+)\\right]^n,\\qquad U(1_-) = K I_\\mathbf{h}\\\\   I_\\mathbf{h} &= e^{-iH_\\text{I}[\\mathbf{h}]}, \\qquad K = e^{-iH_\\text{K}} \\end{aligned} $$\n\n\n\n\n\n\n\n$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]. \\end{aligned} $$\n\n\n\n\nBertini, Kos, Prosen (2019) found that when \\(|J|=|b|=\\pi/4\\)\n\n\\[\n\\lim_{L\\to\\infty} S_A =\\min(2t-2,N_A)\\log 2,\n\\]\n\nAny \\(h_j\\); initial \\(Z_j\\) product state\n\n\n\n\n\n\n\n\n\n\nRecall KIM has circuit representation\n\n\n\n\n$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]. \\end{aligned} $$\n\nAt \\(|J|=|b|=\\pi/4\\) model is dual unitary\n\n\n\n\n\n\n\n\n\n(\\(q=2\\) here) Not satisfied by e.g. \\(\\operatorname{SWAP}\\)\nMaps product states to maximally entangled (Bell) states\nProduct initial states also work for KIM!\n\n\n\n\n\nHeisenberg picture: \\(Z_n(t)=\\mathcal{U}^\\dagger(t)Z_n \\mathcal{U}(t)\\)\nMight use \\(Z_n(t)\\) to evaluate correlation \\(\\langle Z_n(t)Z_m(0) \\rangle\\)\nHow does \\(Z_n(t)\\) look?\n\n\n\n\n\n\nExpand \\(Z_n(t)\\) in products of local operators \\(X_m\\), \\(Y_m\\), \\(Z_m\\), \\(\\mathbb{1}_m\\)\nTypical term $\\sim \\mathbb{1}_1\\otimes \\cdots X_{8}\\otimes Y_{9} \\otimes Z_{10}\\cdots \\otimes\\mathbb{1}_N$\n\n\\[\nZ_n(t)= \\sum_{\\mu_{1:N}=\\\\{0,1,2,3\\\\}^N} \\mathcal{C}\\_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots\\otimes \\sigma_N^{\\mu_N},\\qquad \\sigma^\\mu = (\\mathbb{1},X,Y,Z)\n\\]\nAs time progresses two things (tend to) increase:\n\nThe number of sites \\(\\neq\\mathbb{1}\\) (known as operator spreading)\nThe number of different contributions (or operator entanglement)\n\n\n\nOperator spreading closely analogous to chaotic fronts in CAs\nIntroduce ensemble of random circuits. \\(\\mathcal{C}\\_{\\mu_{1:N}}(t)\\) become random\nFluctuating signs mean \\(\\langle Z_n(t)Z_m(0) \\rangle\\) will tend to average to zero\nc.f. a single PCA trajectory appears as white noise\n\n\n\n\n\n\\[\n\\operatorname{OTOC}_{nm}(t) \\equiv \\langle Z_n(t)Z_m(0)Z_n(t)Z_m(0)\\rangle.\n\\]\n\nIn terms of operator expansion\n\n$$ \\operatorname{OTOC}_{nm}(t)\\propto \\sum_{\\mu_{1:N}}\\mathcal{C}_{\\mu_{1:N}}^2(t)\\left[\\delta_{\\mu_m,0}+\\delta_{\\mu_m,3}-\\delta_{\\mu_m,1}-\\delta_{\\mu_m,2}\\right]. $$\n\n\\(\\operatorname{OTOC}\\_{nm}(t)\\neq 1\\) when operator \\(Z_n(t)\\) spreads from site \\(n\\) to \\(m\\)\nCharacteristic speed of propagation is “butterfly velocity” \\(v_\\text{B}\\)\nOTOC quantum analog of bitstring differences \\(z_t=x_t\\oplus y_t\\) in CAs.\n\n\n\n\n\n\n\n\nThe measured OTOC for \\(i\\operatorname{SWAP}\\) gates (top) and \\(\\sqrt{i\\operatorname{SWAP}}\\) (bottom) after averaging over single qubit gates.\n\n\n\n\n\n\n\n\\(\\overline{\\operatorname{OTOC}}\\) can be expressed as a Markov process\nEfficiently calculate using Monte Carlo simulations\n\n\nAren’t quantum computers supposed to do things that classical computers find hard?\n\n\n\nAveraging is what enables efficient classical algorithms\nFor a given circuit (no averaging), no probabilistic interpretation\n\n\n\n\n\n\nUnitary evolution not the only game in town!\nWe can also measure, which we expect to reduce entanglement\nConsider measurements with certain rate and density in space\n\n\n\n\n\n\n\\(∃\\) phase transition where entanglement vanishes at finite measurement rate (Y Li, X Chen, MPA Fisher (2019), B Skinner, J Ruhman, A Nahum (2019))\nAlternative viewpoint: an initially mixed state is purified by (strong enough) measurements (MJ Gullans, DA Huse (2020))\n\n\n\n\n\nAll states purify, but on exponentially long times below transition\n\n\n\n\n\n\nInteresting variation on PCA: choose output \\(1\\) with probability \\(p\\)\n\\(p\\neq 1/2\\) makes dynamics less one-to-one. What happens?\n\n\n\n\n\n\n\n\n\n\n\n\nFor \\(0.25\\lesssim p\\lesssim 0.75\\) front propagates to infinity\nOutside this region, front dies out\nIn finite system two copies always merge after exponentially long time (“bad luck”)\n\n\n\n\n\n\nIf inputs differ, \\(z^{t+1}_n=1\\) with probability \\(2p(1-p)\\) (Derrida and Stauffer (1986))\n\n\n\n\n\n\\(z^{t+1}\\_{n}=1\\) only if at least one of \\(z^t\\_{n\\pm 1}=1\\)\n\n\n\nSeek connected cluster of sites occupied with probability \\(x=2p(1-p)\\)\nThis is (site) directed percolation\n\\(x\\leq 1/2&lt; x_\\text{crit}\\sim 0.706\\) on square lattice: require NN neighbors\nSimilar phenomenon in coupled map lattices: “synchronization of extended chaotic systems”\n\n\n\n\n\n\nMeasurements purify state; analogous to non-injective rules in CA\nIt was a surprise that a mixed state survives finite measurement rate\nBut… a chaotic front survives non-injective rules (up to a point)\n\n\n\n\n\n\n\n\n\nc.f. Iaconia, Lucas, Chen (2020)\nAnalogous to forced version of transition (Nahum et al. (2021))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCellular Automata\nQuantum Circuits\n\n\n\n\nChaos diagonistic\nDifference \\(z^t=x^t\\oplus y^t\\)\nOTOC \\(\\langle Z_n(t)Z_m(0)Z_n(t)Z_m(0)\\rangle\\)\n\n\nSpread of\nMutual information\nEntanglement entropy\n\n\nTransition via\nNon-injectivity\nMeasurements\n\n\nEnsemble\nRandom maps\nRandom unitaries\n\n\n\n\n\n\n[Links at austen.uk/slides/new-rules-tum] - Review on random circuits Andrew Potter, Romain Vasseur (2021)\n\nTransition to chaos in CA closely linked to synchronization of extended chaotic systems"
  },
  {
    "objectID": "talks/new-rules-tum/index.html#quantum-circuits-cellular-automata-complexity-and-chaos",
    "href": "talks/new-rules-tum/index.html#quantum-circuits-cellular-automata-complexity-and-chaos",
    "title": "New Rules:",
    "section": "",
    "text": "austen.uk/slides/new-rules-tum\nAusten Lamacraft and Pieter Claeys\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEach site either dead (0) or alive (1)\nFate of cell determined by eight neighbors\n\nAny live cell with two or three live neighbours survives\nAny dead cell with three live neighbours becomes a live cell\nAll other live cells die in the next generation\n\nComplex behavior!\n\n\n\n\n\n\nDynamical systems with discrete space, time, and degrees of freedom\nInteresting for statistical physics:\n\nWhat kinds of dynamics may occur?\nHow does dynamics determine thermodynamic behavior?\n\n\n\n\n\n\n\nA quantum analog of CAs\nBasis of “quantum supremacy” work by Google and others\n\n\n\n\nA schematic view of the Google Sycamore processor.\n\n\n\n\n\n\n\nWhat are the similarities and differences? Can we try the same tricks?\nWhen is quantum dynamics harder?\nWhat about measurements?\n\n\n\n\n\n\n“Space” is one dimension with cells \\(x_n=0,1\\) \\(n\\in\\mathbb{Z}\\)\nUpdate cells every time step depending on cells in neighborhood\n\nNeighborhood is cell and two neighbors for elementary CA\n\n\n\n\nUpdate specified by function\n\n\\[\nf:\\\\{0,1\\\\}^3\\longrightarrow \\\\{0,1\\\\}.\n\\]\n\\[\nx^{t+1}_{n} = f(x^{t}\\_{n-1},x^{t}\\_{n},x^{t}\\_{n+1})\n\\]\n\nHow many possible functions?\n\n\n\n\n\n\nDomain of \\(f\\) is \\(2^3=8\\) possible values for three cells\n\\(2^8=256\\) possible choices for the function \\(f\\)\nList outputs corresponding to inputs: 111, 110, … 000\n\n\n\n\n111\n110\n101\n100\n011\n010\n001\n000\n\n\n\n\n0\n1\n1\n0\n1\n1\n1\n0\n\n\n\n\nInterpret as binary number: this one is Rule 110\n\n\n\nMany behaviors, from ordered (Rule 18) to chaotic (Rule 30)\n\n\n\n\n\n\n\n\nRule 110 is capable of universal computation!\n\n\n\n\n\nThat’s Christmas sorted\n\n\n\n\n\n\n\n\n\ngive each pixel a random Pokemon type, and then battle pixels against their neighbors, updating each pixel with the winning type (using the Pokemon type chart)we quickly see areas of fire &gt; water &gt; grass &gt; fire, electric sweeping over, ground frontiers taking over etc etc pic.twitter.com/BHgQuKRApR\n\n— Matt Henderson (@matthen2) July 2, 2022\n\n\n\n\n\n\n\nNotion of a causal “light cone” (45 degree lines)\nVariety of possible behaviors: chaos, periodicity, …\n\n\n\n\n\n\nRapid growth of small differences between two trajectories\n\n\n\n\n\n\n\n\nSmallest change: flip one site and monitor \\(z^t\\equiv x^t\\oplus y^t\\)\n\n\n\n\n\n\nNo exponential growth (c.f. Lyapunov exponent in continuous systems)\nTrack number of differences (Hamming distance) between trajectories\nPropagating “front” cannot exceed “speed of light”: generally slower\n\n\n\n\n\n\nNo chance of solving the dynamics of any one CA\nLooking for generic properties: natural to consider ensembles\n\nof initial conditions\nof rules\n\n\n\n\n\n\n\nChoose rules iid for each site and instant\n\n\n\n\n\n\n\n\nCell values are now white noise, but \\(z_t=x_t\\oplus y_t\\) revealing\nFluctuations of front are larger and average speed \\(&lt;\\) maximum\n\n\n\n\n\n\nNo elementary CAs are reversible (bijective)! Requires size 4 neighborhood\nReversibility is undecidable above one spatial dimension\n\\(∃\\) reversible constructions\n\n\n\n\n\n\nFredkin construction\n\n$$ x^{t+1}_{n} = f(x^{t}_{n-1},x^{t}_{n},x^{t}_{n+1}) + x^{t-1}_{n},\\, \\mod 2 $$\n\n\n\n\n$$ x^{t+1}_{n} = x^{t}_{n-1} x^{t-1}_{n} + x^{t}_{n+1} + x^{t}_{n-1}x^{t}_{n+1}\\, \\mod 2 $$\n\nInterpret as “tiling rules”\n\n\n \n\nFrom Buca, Klobas, and Prosen (2021)\n\n\n\nRandom tilings consistent with constraint have entropy \\(\\propto L\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPartition cells into blocks (Margolus neighborhoods)\nApply invertible mapping to block\nAlternate overlapping partitions\n\n\n\n\n\n\n\n\n\nBlue squares: invertible mapping on states of two sites: 00, 01, 10, 11\n\n\n\n\n\ngiven these four jigsaw pieces, there is only one way to fill in the rest of the puzzle. The solution ends up drawing a Sierpinski triangle. Can you see why? pic.twitter.com/OvxVz2oehy\n\n— Matt Henderson (@matthen2) May 25, 2022"
  },
  {
    "objectID": "talks/new-rules-tum/index.html#reversible-models",
    "href": "talks/new-rules-tum/index.html#reversible-models",
    "title": "New Rules:",
    "section": "",
    "text": "Each block a permutation of 00, 01, 10, 11\n\\(4!=24\\) blocks\nOrder:\n\n\n\n\n\n\n\n(1324), and so on\n\nBlock 2 is the map \\((00, 01, 10, 11) ⟶ (00, 10, 01, 11)\\)\nExchange, or SWAP gate in quantum information\n\n\n\n\n\n\n\n\n\nEnsemble of block CAs similar to PCA\n\n\n\n\n\nCan we find an ensemble where front propagates at maximal speed?\nYes! Dual reversible blocks are bijections in both time and space\nThere are 12 such blocks (out of 24)\nEnsemble is Markov in time and space: must have maximal velocity!\n\n\n\n\n\n\nFor \\(N=2\\) dynamics of \\(z_t=x_t\\oplus y_t\\) independent of \\(x_t\\) (or \\(y_t\\))\nRecurrence time always \\(\\propto L\\) (instead of double exponential)\nEdge corresponds to the stationary state of a Markov process (c.f. Claeys and Lamacraft (2020) for quantum case)\n\n\n\n\n\n\nBorsi and Pozsgay (2022) find 227 inequivalent dual reversible models\n\n\n\n\n\n\n\n\n\n\n\n\\[\n(c,d) = f(a,b) = (a + b, a - b)\\, \\mod 3\n\\]\n\nOriginal dual unitary circuit from Hosur et al.\nUnusual behavior of recurrence time\n\nFor \\(L = 2\\times 3^m\\) have \\(T_\\text{recur}=2L\\)\nBorsi and Pozsgay prove using Fourier analysis over finite fields\n\n\n\n\n\n\n\n\n\n\\(L=54=2\\times 3^3\\), \\(T_\\text{recur}=2L=108\\)\n\n\n\n\n\n\n\nDisjoint regions \\(A\\) and \\(\\bar A\\): how much does one tell about the other?\nUse mutual information: measure of dependence of random variables\nSuggested in this context by Pizzi et al. (2022)\n\n\n\nMI defined as \\[\nI(X;Y) \\equiv S(X) + S(Y) - S(X,Y)\n\\]\n\n\\(S(X)\\) is entropy of \\(p_X(x)\\); marginal distribution of \\(X\\)\n\\(S(Y)\\) is entropy of \\(p_Y(y)\\); marginal distribution of \\(Y\\)\n\\(S(X,Y)\\) is entropy of joint distribution \\(p_{(X,Y)}(x,y)\\)\n\nVanishes if \\(p_{(X,Y)}(x,y)=p_X(x)p_Y(y)\\)\n\n\n\n\n\n\n\n\nFrom Pizzi et al. (2022)\n\n\n\n\n\n\n\nSuppose either \\(X=Y=1\\) or \\(X=Y=0\\), with equal probability\n\n$$ \\begin{align} p_{(X,Y)}(0,0)&=p_{(X,Y)}(1,1)=1/2\\\\  p_{(X,Y)}(1,0)&=p_{(X,Y)}(0,1)=0 \\end{align} $$\n\\[\nI(X;Y)=S(X) + S(Y) - S(X,Y)= 1+1-1=1 \\text{ bit}\n\\]\n\n\n\n\n\n\n\n\nInitial distribution factorizes over correlated pairs\nApply SWAPs\n1 bit MI for every pair with one member in \\(A\\) and one in \\(\\bar A\\)\n\n\\[\nI(A;\\bar A) = \\min(4\\lfloor t/2\\rfloor, |A|) \\text{ bits}\n\\]\n\n\\(|A|\\) is (even) number of sites in \\(A\\)\n\n\n\n\n\n\nTotal entropy conserved (c.f Liouville’s theorem)\nEntropy of initial distribution is half max, but entropy \\(S(A)\\) saturates at maximal value (thermalization in time \\(\\sim |A|/2\\))\nThis model is not so special! Any of the dual reversible blocks CAs behaves exactly the same!\n\n\n\n\n\nFor reversibility and dual reversibility\n\n\n\n\n\n\n\n8 sites share 4 bits of entropy\n\n\n\n\nAfter four steps increases to (maximum) 8 bits!\n\n\n\n\n\n\n8 sites share 4 bits of entropy\n\n\n\n\nAfter two steps increases to 6 bits!\n\n\n\nEntropies of \\(A\\) and \\(\\bar A\\) subsystems behave just as in the toy model\n\n\\[\nI(A;\\bar A) = \\min(4\\lfloor t/2\\rfloor, |A|) \\text{ bits}\n\\]\n\n… for all dual reversible models!\n\n\n\n\n\n$$ \\begin{equation} \\begin{aligned} \\Phi_{\\tau}\\left(\\mathbf{S}_{1}, \\mathbf{S}_{2}\\right) &=\\frac{1}{\\sigma^{2}+\\tau^{2}}\\left(\\sigma^{2} \\mathbf{S}_{1}+\\tau^{2} \\mathbf{S}_{2}+\\tau \\mathbf{S}_{1} \\times \\mathbf{S}_{2}, \\sigma^{2} \\mathbf{S}_{2}+\\tau^{2} \\mathbf{S}_{1}+\\tau \\mathbf{S}_{2} \\times \\mathbf{S}_{1}\\right) \\\\ \\sigma^{2} &:=\\frac{1}{2}\\left(1+\\mathbf{S}_{1} \\cdot \\mathbf{S}_{2}\\right) \\end{aligned} \\end{equation} $$\n\n\n\nFrom Krajnik and Prosen (2020)\n\n\n\nMI has exactly the same behavior!"
  },
  {
    "objectID": "talks/new-rules-tum/index.html#summary-so-far",
    "href": "talks/new-rules-tum/index.html#summary-so-far",
    "title": "New Rules:",
    "section": "",
    "text": "CAs as dynamical systems: chaotic fronts and information dynamics\nDynamical ensembles as a theoretical tool\n\n\nHow can we extend these ideas to quantum systems?\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlock CA\nQuantum Circuit\n\n\n\n\nBasic unit\nInvertible map\nUnitary operator (gate)\n\n\nLocal variable\n\\(z_n \\in \\\\{0, 1\\\\}\\)\n\\(\\ket{\\psi_n}\\in \\mathbb{C}^2\\)\n\n\nGlobal state\n$z \\{0,1\\}^N $\n\\(\\ket{\\Psi(t)}\\in \\mathbb{C}^{2^N}\\)\n\n\nSimulation\nEasy\nHard\n\n\n\n\n\n\n\n\nModel of universal quantum computation\nExample of discrete time, many body quantum dynamics\n\n\nEveryone’s doing it!\n\n\n\n\n\n\n\\(n\\)-qubit unitary has matrix elements \\(U_{x_1\\ldots x_n,x'_1,\\ldots, x'_n}\\) in computational basis \\(\\ket{0}\\), \\(\\ket{1}\\)\nUnitarity means\n\n\\[\n\\sum\\_{x_1'\\ldots x_N'}U_{x_1\\ldots x_n,x'_1,\\ldots, x'_n} U^\\dagger\\_{x'_1\\ldots x'_n,x''_1,\\ldots, x''_n}=\\delta\\_{x_1,x_1''}\\ldots \\delta\\_{x_N,x_N''},\n\\]\n\nBut we’d like to avoid such awful looking expressions\n\n\n\n\n\n\nGeneral state of \\(N\\) qubits is\n\n$$ \\ket{\\Psi} = \\sum_{x_{1:N}\\in \\{0,1\\}^N} \\Psi_{x_1\\ldots x_N}\\ket{x_1}_1\\ket{x_2}_2\\cdots \\ket{x_N}_N $$\n\nWrite \\(\\ket{x_1}\\_1\\ket{x_2}\\_2\\cdots \\ket{x_N}\\_N =\\ket{x_1\\cdots x_N}=\\ket{x_{1:N}}\\) for brevity\nOperator on \\(N\\) qubits has matrix elements\n\n$$ \\mathcal{O}_{x_{1:N},x'_{1:N}} = \\bra{x_{1:N}}\\mathcal{O}\\ket{x'_{1:N}} $$\n\n\n\n\n\n\n\nSee Pan Zhang’s tutorial\n\n\n\n\n\n\n\n\n\n\nHave causality built in\nQuantum analog of (block) CAs\n\n\n\n\n\n\nWork in the basis \\(\\ket{00}\\), \\(\\ket{01}\\), \\(\\ket{10}\\), \\(\\ket{11}\\)\nSimplest example: SWAP gate\n\n\\[\n\\operatorname{SWAP}=\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\\\n0 & 0 & 1 & 0 \\\\\\\n0 & 1 & 0 & 0 \\\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n\\]\n\nSwitches states. Takes product state to product state\n\n\\[\n\\operatorname{SWAP}\\ket{10} = \\ket{01}\n\\]\n\n\n\n\n\\[\n\\sqrt{\\operatorname{SWAP}}=\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\\\n0 & \\frac{1}{2}(1+i) & \\frac{1}{2}(1-i) & 0 \\\\\\\n0 & \\frac{1}{2}(1-i) & \\frac{1}{2}(1+i) & 0 \\\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}.\n\\]\n\nGenerates entanglement (non product state)\n\n\\[\n\\sqrt{\\operatorname{SWAP}}\\ket{10} = \\frac{1}{2}\\left[(1+i)\\ket{10}+(1-i)\\ket{01}\\right]\n\\]\n\n\\(\\sqrt{\\operatorname{SWAP}}\\) and single qubit unitaries are universal gate set\n\n\n\n\n\n\nWe need both \\(U\\)s and \\(U^\\dagger\\)s (e.g. for \\(\\mathcal{O}(t)=U^\\dagger(t)\\mathcal{O}U(t)\\))\n\n\n\n\n\n\n\n\n\n\n\nMuch better!\n\n\n\n\n\n\n \n\n(left) Schematic view of the Google Sycamore processor (right)\n\n\n\n\n\n\n\nSampling from circuits basis of Google’s “quantum supremacy”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNormally matrix-vector multiplication is \\(O(\\operatorname{dim}^2)=2^{2N}\\)\nGates are sparse so \\(O(\\operatorname{dim})=2^{N}\\), but still exponentially hard\nFor low depth \\(T&lt;N\\) move horizontally instead\n\n\n\n\n\n\nEvaluate \\(\\bra{\\Psi}\\mathcal{O}\\ket{\\Psi}=\\bra{\\Psi_0}\\mathcal{U}^\\dagger\\mathcal{O}\\mathcal{U}\\ket{\\Psi_0}\\) for local \\(\\mathcal{O}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter folding, lines correspond to two indices / 4 dimensions\n\n\n\n\n\n\nCircle denotes \\(\\delta_{ab}\\)\n\n\n\n\n\n\n\n\n\nEmergence of “light cone”\n\n\n\n\n\n\n\n\nExpectation values in region \\(A\\) evaluated using reduced density matrix\n\n\\[\n\\rho_A = \\operatorname{tr}\\_{\\bar A}\\left[\\ket{\\Psi}\\bra{\\Psi}\\right]=\\operatorname{tr}_{\\bar A}\\left[\\mathcal{U}\\ket{\\Psi_0}\\bra{\\Psi_0}\\mathcal{U}^\\dagger\\right]\n\\]\n\n\n\n\n\n\n\n\\(\\rho_A\\) very useful for quantifying entanglement\nIf $\\ket{\\Psi} = \\ket{\\psi}_A \\otimes \\ket{\\phi}_{\\bar A}$ then \\(\\rho_A = \\ket{\\psi}_A\\bra{\\psi}_A\\)`\nAny deviation from product state leads to mixed density matrix\nQuantify by entropy of \\(\\rho_A\\) (the entanglement entropy)\n\n\\[\nS_A \\equiv -\\operatorname{tr}\\left[\\rho_A\\log \\rho_A\\right].\n\\]\n\n\n\n\n\n\n\n\nEach pair in Bell state $ \\ket{\\Phi^+}_{2n, 2n+1} = \\frac{1}{\\sqrt{2}}\\left[\\ket{0}_{2n}\\ket{0}_{2n+1}+ \\ket{1}_{2n}\\ket{1}_{2n+1}\\right] $\nReduced density matrix for one member: $\\operatorname{tr}_{2}\\left[\\ket{\\Phi^+}_{12}\\bra{\\Phi^+}_{12}\\right] = \\frac{1}{2}\\mathbb{1}_1$\nEntanglement entropy of 1 bit\n\n\n\n\n\n\nFor a Bell pair consisting of qubits at sites \\(m\\) and \\(n\\):\n\nIf \\(n\\in A\\), \\(m\\in\\bar A\\), \\(\\rho_A\\) has factor \\(\\mathbb{1}_n\\).\nIf \\(m, n\\in A\\) they contribute a factor \\(\\ket{\\Phi^+}\\_{nm}\\bra{\\Phi^+}\\_{nm}\\) (pure)\n\nOnly first case contributes to $  S_A = \\min(4\\lfloor t/2\\rfloor, |A|) \\text{ bits} $\nJust like mutual information in classical version!\n\n\n\n\n\n\nExactly the same behavior for all unitaries satisfying\n\n\n\n\n\nc.f. dual reversible CAs\n\n\n\n\n\n\n\\(4\\times 4\\) unitaries are 16-dimensional\nFamily of dual unitaries is 14-dimensional\nIncludes kicked Ising model at particular values of couplings\nDual unitaries not “integrable” but have enough structure to allow many calculations"
  },
  {
    "objectID": "talks/new-rules-tum/index.html#rho_a-via-dual-unitarity",
    "href": "talks/new-rules-tum/index.html#rho_a-via-dual-unitarity",
    "title": "New Rules:",
    "section": "",
    "text": "8 sites; 4 layers\n\n\n\n\n\\(\\rho_A\\) is unitary transformation of\n\n\\[\n  \\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\n\\]"
  },
  {
    "objectID": "talks/new-rules-tum/index.html#shallower-1",
    "href": "talks/new-rules-tum/index.html#shallower-1",
    "title": "New Rules:",
    "section": "",
    "text": "\\(\\rho_A\\) is unitary transformation of\n\n\\[\n\\mathbb{1}\\otimes\\mathbb{1}\\ket{\\Phi^+}\\bra{\\Phi^+}\\otimes\\ket{\\Phi^+}\\bra{\\Phi^+}\\otimes\\mathbb{1}\\otimes\\mathbb{1}\n\\]\n\n\n\n\nRDM is unitary transformation of\n\n\\[\n\\rho_0=\\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1} \\otimes\\overbrace{\\ket{\\Phi^+}\\bra{\\Phi^+} \\cdots }^{N_A/2-t+1 } \\otimes \\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1}\n\\]\n\nRDM has \\(2^{\\min(2t-2,N_A)}\\) non-zero eigenvalues all equal to \\(\\left(\\frac{1}{2}\\right)^{\\min(2t-2,N_A)}\\)\nConverse – maximal entanglement growth implies dual unitary gates – recently proved by Zhou and Harrow (2022)"
  },
  {
    "objectID": "talks/new-rules-tum/index.html#thermalization",
    "href": "talks/new-rules-tum/index.html#thermalization",
    "title": "New Rules:",
    "section": "",
    "text": "After \\(N_A/2 + 1\\) steps, reduced density matrix is \\(\\propto \\mathbb{1}\\)\nAll expectations (with \\(A\\)) take on infinite temperature value"
  },
  {
    "objectID": "talks/new-rules-tum/index.html#floquet-theory-kicked-ising-model",
    "href": "talks/new-rules-tum/index.html#floquet-theory-kicked-ising-model",
    "title": "New Rules:",
    "section": "",
    "text": "Time dependent Hamiltonian with kicks at \\(t=0,1,2,\\ldots\\).\n\n$$ \\begin{aligned} H_{\\text{KIM}}(t) = H_\\text{I}[\\mathbf{h}] + \\sum_{m}\\delta(t-n)H_\\text{K}\\\\ H_\\text{I}[\\mathbf{h}]=\\sum_{j=1}^L\\left[J Z_j Z_{j+1} + h_j Z_j\\right],\\qquad H_\\text{K} &= b\\sum_{j=1}^L X_j, \\end{aligned} $$\n\n“Stroboscopic” form of \\(U(t)=\\mathcal{T}\\exp\\left[-i\\int^t H_{\\text{KIM}}(t') dt'\\right]\\)\n\n$$ \\begin{aligned}   U(n_+) &= \\left[U(1_+)\\right]^n,\\qquad U(1_-) = K I_\\mathbf{h}\\\\   I_\\mathbf{h} &= e^{-iH_\\text{I}[\\mathbf{h}]}, \\qquad K = e^{-iH_\\text{K}} \\end{aligned} $$"
  },
  {
    "objectID": "talks/new-rules-tum/index.html#kim-as-a-circuit",
    "href": "talks/new-rules-tum/index.html#kim-as-a-circuit",
    "title": "New Rules:",
    "section": "",
    "text": "$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]. \\end{aligned} $$\n\n\n\n\nBertini, Kos, Prosen (2019) found that when \\(|J|=|b|=\\pi/4\\)\n\n\\[\n\\lim_{L\\to\\infty} S_A =\\min(2t-2,N_A)\\log 2,\n\\]\n\nAny \\(h_j\\); initial \\(Z_j\\) product state"
  },
  {
    "objectID": "talks/new-rules-tum/index.html#dual-unitarity",
    "href": "talks/new-rules-tum/index.html#dual-unitarity",
    "title": "New Rules:",
    "section": "",
    "text": "Recall KIM has circuit representation\n\n\n\n\n$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]. \\end{aligned} $$\n\nAt \\(|J|=|b|=\\pi/4\\) model is dual unitary"
  },
  {
    "objectID": "talks/new-rules-tum/index.html#kim-property",
    "href": "talks/new-rules-tum/index.html#kim-property",
    "title": "New Rules:",
    "section": "",
    "text": "(\\(q=2\\) here) Not satisfied by e.g. \\(\\operatorname{SWAP}\\)\nMaps product states to maximally entangled (Bell) states\nProduct initial states also work for KIM!\n\n\n\n\n\nHeisenberg picture: \\(Z_n(t)=\\mathcal{U}^\\dagger(t)Z_n \\mathcal{U}(t)\\)\nMight use \\(Z_n(t)\\) to evaluate correlation \\(\\langle Z_n(t)Z_m(0) \\rangle\\)\nHow does \\(Z_n(t)\\) look?\n\n\n\n\n\n\nExpand \\(Z_n(t)\\) in products of local operators \\(X_m\\), \\(Y_m\\), \\(Z_m\\), \\(\\mathbb{1}_m\\)\nTypical term $\\sim \\mathbb{1}_1\\otimes \\cdots X_{8}\\otimes Y_{9} \\otimes Z_{10}\\cdots \\otimes\\mathbb{1}_N$\n\n\\[\nZ_n(t)= \\sum_{\\mu_{1:N}=\\\\{0,1,2,3\\\\}^N} \\mathcal{C}\\_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots\\otimes \\sigma_N^{\\mu_N},\\qquad \\sigma^\\mu = (\\mathbb{1},X,Y,Z)\n\\]\nAs time progresses two things (tend to) increase:\n\nThe number of sites \\(\\neq\\mathbb{1}\\) (known as operator spreading)\nThe number of different contributions (or operator entanglement)\n\n\n\nOperator spreading closely analogous to chaotic fronts in CAs\nIntroduce ensemble of random circuits. \\(\\mathcal{C}\\_{\\mu_{1:N}}(t)\\) become random\nFluctuating signs mean \\(\\langle Z_n(t)Z_m(0) \\rangle\\) will tend to average to zero\nc.f. a single PCA trajectory appears as white noise\n\n\n\n\n\n\\[\n\\operatorname{OTOC}_{nm}(t) \\equiv \\langle Z_n(t)Z_m(0)Z_n(t)Z_m(0)\\rangle.\n\\]\n\nIn terms of operator expansion\n\n$$ \\operatorname{OTOC}_{nm}(t)\\propto \\sum_{\\mu_{1:N}}\\mathcal{C}_{\\mu_{1:N}}^2(t)\\left[\\delta_{\\mu_m,0}+\\delta_{\\mu_m,3}-\\delta_{\\mu_m,1}-\\delta_{\\mu_m,2}\\right]. $$\n\n\\(\\operatorname{OTOC}\\_{nm}(t)\\neq 1\\) when operator \\(Z_n(t)\\) spreads from site \\(n\\) to \\(m\\)\nCharacteristic speed of propagation is “butterfly velocity” \\(v_\\text{B}\\)\nOTOC quantum analog of bitstring differences \\(z_t=x_t\\oplus y_t\\) in CAs.\n\n\n\n\n\n\n\n\nThe measured OTOC for \\(i\\operatorname{SWAP}\\) gates (top) and \\(\\sqrt{i\\operatorname{SWAP}}\\) (bottom) after averaging over single qubit gates.\n\n\n\n\n\n\n\n\\(\\overline{\\operatorname{OTOC}}\\) can be expressed as a Markov process\nEfficiently calculate using Monte Carlo simulations\n\n\nAren’t quantum computers supposed to do things that classical computers find hard?\n\n\n\nAveraging is what enables efficient classical algorithms\nFor a given circuit (no averaging), no probabilistic interpretation\n\n\n\n\n\n\nUnitary evolution not the only game in town!\nWe can also measure, which we expect to reduce entanglement\nConsider measurements with certain rate and density in space\n\n\n\n\n\n\n\\(∃\\) phase transition where entanglement vanishes at finite measurement rate (Y Li, X Chen, MPA Fisher (2019), B Skinner, J Ruhman, A Nahum (2019))\nAlternative viewpoint: an initially mixed state is purified by (strong enough) measurements (MJ Gullans, DA Huse (2020))\n\n\n\n\n\nAll states purify, but on exponentially long times below transition\n\n\n\n\n\n\nInteresting variation on PCA: choose output \\(1\\) with probability \\(p\\)\n\\(p\\neq 1/2\\) makes dynamics less one-to-one. What happens?\n\n\n\n\n\n\n\n\n\n\n\n\nFor \\(0.25\\lesssim p\\lesssim 0.75\\) front propagates to infinity\nOutside this region, front dies out\nIn finite system two copies always merge after exponentially long time (“bad luck”)\n\n\n\n\n\n\nIf inputs differ, \\(z^{t+1}_n=1\\) with probability \\(2p(1-p)\\) (Derrida and Stauffer (1986))\n\n\n\n\n\n\\(z^{t+1}\\_{n}=1\\) only if at least one of \\(z^t\\_{n\\pm 1}=1\\)\n\n\n\nSeek connected cluster of sites occupied with probability \\(x=2p(1-p)\\)\nThis is (site) directed percolation\n\\(x\\leq 1/2&lt; x_\\text{crit}\\sim 0.706\\) on square lattice: require NN neighbors\nSimilar phenomenon in coupled map lattices: “synchronization of extended chaotic systems”\n\n\n\n\n\n\nMeasurements purify state; analogous to non-injective rules in CA\nIt was a surprise that a mixed state survives finite measurement rate\nBut… a chaotic front survives non-injective rules (up to a point)\n\n\n\n\n\n\n\n\n\nc.f. Iaconia, Lucas, Chen (2020)\nAnalogous to forced version of transition (Nahum et al. (2021))"
  },
  {
    "objectID": "talks/new-rules-tum/index.html#summary-of-analogies",
    "href": "talks/new-rules-tum/index.html#summary-of-analogies",
    "title": "New Rules:",
    "section": "",
    "text": "Cellular Automata\nQuantum Circuits\n\n\n\n\nChaos diagonistic\nDifference \\(z^t=x^t\\oplus y^t\\)\nOTOC \\(\\langle Z_n(t)Z_m(0)Z_n(t)Z_m(0)\\rangle\\)\n\n\nSpread of\nMutual information\nEntanglement entropy\n\n\nTransition via\nNon-injectivity\nMeasurements\n\n\nEnsemble\nRandom maps\nRandom unitaries\n\n\n\n\n\n\n[Links at austen.uk/slides/new-rules-tum] - Review on random circuits Andrew Potter, Romain Vasseur (2021)\n\nTransition to chaos in CA closely linked to synchronization of extended chaotic systems"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html",
    "href": "talks/quantum-circuits-2/index.html",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "austen.uk/slides/quantum-circuits-2\n\n\n\n\n\nCorrelations near the light cone (see Claeys and Lamacraft for details)\nOperator scrambling and the OTOC\n\n\n\n\n\n\\[\nc_{\\alpha \\beta}(x,t) = \\langle \\sigma_{\\alpha}(x,t) \\sigma_{\\beta}(0,0) \\rangle,\\qquad \\sigma_\\alpha(x,t)=U^\\dagger(t)\\sigma_\\alpha(x)U(t)\n\\]\n\nVanishes when \\(|x|&gt;t\\) (outside light cone)\n\n\n\n\n\n\n\n\n\nUsing unitarity (only)\n\n\n\n\n\n\n\n\n\n\n\n\n$$ \\begin{align}\\label{eq:CorrChannels} \\langle \\sigma_{\\alpha}(t,t) \\sigma_{\\beta}(0,0) \\rangle &= \\tr \\left[\\sigma_{\\beta}\\mathcal{M}_{-}^t(\\sigma_{\\alpha})\\right] / q \\\\ &=  \\tr \\left[ \\sigma_{\\alpha}\\mathcal{M}_{+}^{t}(\\sigma_{\\beta})\\right] / q \\end{align} $$ - Calculating correlator involves repeated application of\n\n \n\n\n\n\n\n\n\n\n\nSurprising that correlations can be found at arbitrary distances!\n\n\n\n\n\n\nBertini, Kos, and Prosen introduced above formalism for dual unitaries\nRecall light cone \\(|x|\\leq t\\) was implied by unitarity\nDual unitarity implies correlations also vanish for \\(|x|\\geq t\\)\nOnly nonzero correlations are on the light cone\n\n\n\n\n\n\n\\(SU(2)\\) preserving gate\n\n$$ U_{j,j+1} = \\cos\\theta \\mathbb{1}_{j,j+1} + i\\sin\\theta \\operatorname{P}_{j.j+1} $$\n\\begin{multline} \\mathcal{O} \\longrightarrow U^\\dagger_{j,j+1}\\mathcal{O}U_{j,j+1} = \\cos^2\\theta \\mathcal{O} + \\sin^2\\theta \\operatorname{P}_{j.j+1}\\mathcal{O} \\operatorname{P}_{j.j+1} \\\\ -i\\sin\\theta\\cos\\theta \\left[\\operatorname{P}_{j.j+1}, \\mathcal{O}\\right] \\end{multline}\n\nGenerally useful idea: consider random circuit and average\nTake distribution \\(\\theta=\\pm \\theta_0\\) with \\(p(\\theta_0)-p(-\\theta_0)\\equiv \\delta &gt; 0\\)\n\n\n\n\n\n\\[\\begin{multline}\n\\overline{U^\\dagger_{j,j+1}\\mathcal{O}U_{j,j+1}} = \\cos^2\\theta_0 \\\\, \\mathcal{O} + \\sin^2\\theta_0 \\\\, P_{j.j+1}\\mathcal{O} P_{j.j+1} \\\\\\\\\n+i\\delta \\sin\\theta_0\\cos\\theta_0 \\left[P_{j.j+1}, \\mathcal{O}\\right]\n\\end{multline}\\]\n\nInterpretation:\n\nOperators on sites \\(j\\) and \\(j+1\\) switch with probability \\(\\sin^2\\theta_0\\)\nAsymmetry \\(\\delta\\) governs strength of “quantum” dynamics\n\n\n\n\n\n\n\\[\n\\frac{d\\bar{\\mathcal{O}}}{dt} = \\sum_j \\left[iJ \\left[P_{j,j+1},\\bar{\\mathcal{O}}\\right]+\\left(P_{j,j+1}\\bar{\\mathcal{O}}P_{j,j+1}-\\bar{\\mathcal{O}}\\right)\\right].\n\\]\n\\[\\begin{align}\ni[P,\\sigma^a\\otimes 1]&=-\\epsilon^{abc}\\sigma^b\\otimes\\sigma^c\\nonumber\\\\\\\\\ni[P,1\\otimes \\sigma^a]&=\\epsilon^{abc}\\sigma^b\\otimes\\sigma^c\\nonumber\\\\\\\\\ni[P,\\sigma^a\\otimes \\sigma^b]&=\\epsilon^{abc}\\left(\\sigma^c\\otimes 1- 1\\otimes \\sigma^c\\right).\n\\label{eq:split-merge}\n\\end{align}\\]\n\nSum of first two expressions vanishes by spin conservation\nDescribe operator “splitting” (\\(1\\to 2\\)) and “merging” (\\(2\\to 1\\)).\n\n\n\n\n\n$$ Z_j(t)= \\sum_{\\mu_{1:N}=\\{0,1,2,3\\}^N} \\mathcal{C}_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots \\sigma_N^{\\mu_N},\\qquad \\sigma^\\mu = (\\mathbb{1},X,Y,Z) $$\n\nWith initial condition\n\n\\[\n\\begin{equation}\n\\mathcal{C}\\_{\\mu_{1:N}}(0)=\\begin{cases}\n1 & \\mu_j=z, \\mu_k=0,\\forall k\\neq j \\\\\\\\\n0 & \\text{otherwise},\n\\end{cases}\n\\end{equation}\n\\]\n\nSpin correlations \\(\\langle Z_j(t)Z_k(0)\\rangle=C_{jk}(t) = \\mathcal{C}_{0\\cdots \\mu_k=z \\cdots 0}(t)\\)\n\n\n\n\n\n\n\n\n\nWriting \\(\\mathcal{C}^a_{0\\cdots \\mu_k=a\\cdots 0}\\equiv C^a_k\\) we have equation of motion\n\n\\[\n\\partial_t C^a_k = C^a_{k+1} + C^a_{k-1} - 2 C^a_k\\equiv \\Delta_k C^a_k\n\\]\n\nDiffusion of single \\(\\sigma^a\\) (\\(\\Delta_k\\) is 1D discrete Laplacian)\n\n\n\n\n\n\n\n\n\\[\n\\begin{align}\n\\partial_t \\mathcal{C}\\_{\\mu_{1:N}} = \\sum_j \\left[J\\epsilon_{\\alpha\\beta \\mu_j \\mu_{j+1}} \\mathcal{C}\\_{\\mu_1\\cdots \\alpha\\beta \\cdots \\mu_N} + \\mathcal{C}\\_{\\mu_1\\cdots \\mu_{j+1}\\mu_j \\cdots \\mu_N} - \\mathcal{C}\\_{\\mu_1\\cdots \\mu_{j}\\mu_{j+1} \\cdots \\mu_N}\\right].\n\\end{align}\n\\]\n\n\n\n\nSee Claeys, Lamacraft, and Herzog-Arbeitman for more\n\n\n\n\n\n\nCorrelations (typically) decay exponentially\nDoesn’t mean that operator dynamics is trivial!\nWhat can we say about \\(\\sigma_\\alpha(x,t)=U^\\dagger(t)\\sigma_\\alpha(x) U(t)\\) generally?\n\n\n$$ Z_j(t)= \\sum_{\\mu_{1:N}=\\{0,1,2,3\\}^N} \\mathcal{C}_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots \\sigma_N^{\\mu_N},\\qquad \\sigma^\\mu = (\\mathbb{1},X,Y,Z) $$\n\nAs time progresses two things (tend to) increase\n\nNumber of non-identity sites (operator spreading)\nNumber of different contributions (operator entanglement)\n\nHow to quantify these?\n\nOperator spreading defines “butterfly velocity”\nClifford gates lead to operator spreading but no entanglement\n\n\n\n\n\n\n\\[\n\\operatorname{OTOC}_{jk}(t) =\\langle Z_j(t)Z_k(0)Z_j(t)Z_k(0)\\rangle\n\\]\n$$ Z_j(t)= \\sum_{\\mu_{1:N}=\\{0,1,2,3\\}^N} \\mathcal{C}_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots \\sigma_N^{\\mu_N} $$\n$$ \\operatorname{OTOC}_{jk}(t)\\propto \\sum_{\\mu_{1:N}}\\mathcal{C}_{\\mu_{1:N}}^2(t)\\left[\\delta_{\\mu_k,0}+\\delta_{\\mu_k,3}-\\delta_{\\mu_k,1}-\\delta_{\\mu_k,2}\\right] $$\n\n\\(\\operatorname{OTOC}_{jk}(t)\\neq 1\\) when operator \\(Z_j(t)\\) spreads from site \\(j\\) to site \\(k\\)\nInvolves $\\mathcal{C}_{\\mu_{1:N}}^2(t)$ so survives averaging\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(i\\operatorname{SWAP}\\): sharp OTOC front\n\\(\\sqrt{i\\operatorname{SWAP}}\\): broadened OTOC front\n\n\n\n\n\n\nSee Google’s OTOC experiment (supplementary material)\nContinuous time version in Rowlands and Lamacraft\nMain idea: OTOC extracted from\n\n\\[\n\\hat{\\mathcal{O}}^{(2)}(t)=\\overline{\\hat{O}(t) \\otimes \\hat{O}(t)} \\equiv \\overline{\\hat{O}(t)^{\\otimes 2}}\n\\]\n\n\\[\n\\hat{\\mathcal{O}}^{(2)}(t)=\\overline{\\hat{O}(t) \\otimes \\hat{O}(t)} \\equiv \\overline{\\hat{O}(t)^{\\otimes 2}}\n\\]\n\nInvariant subspace that survives averaging built from \\(\\mathsf{O} \\equiv\\mathbb{1}\\otimes\\mathbb{1}\\) and \\(\\mathsf{1}\\equiv\\frac{1}{3}\\left[X\\otimes X + Y\\otimes Y+ Z\\otimes Z\\right]\\) on each site\nBasis: \\(\\mathsf{S}_{1:N}\\equiv\\mathsf{S}_1\\otimes \\mathsf{S}_2\\otimes\\cdots \\mathsf{S}_N\\), with \\(\\mathsf{S}_j=0,1\\)\n\n$$ \\hat{\\mathcal{O}}^{(2)}(t) = \\sum_{\\mathsf{S}_{1:N}\\in\\{\\mathsf{0},\\mathsf{1}\\}^N} P_{\\mathsf{S}_{1:N}}\\mathsf{S}_{1:N} $$\n\n$$ \\hat{\\mathcal{O}}^{(2)}(t) = \\sum_{\\mathsf{S}_{1:N}\\in\\{\\mathsf{0},\\mathsf{1}\\}^N} P_{\\mathsf{S}_{1:N}}\\mathsf{S}_{1:N} $$\n\n(Average of) gate provides update rule for \\(P_{\\mathsf{S}_{1:N}}\\) $$ P_{\\mathsf{S}_{1:N}}(t+1) = \\sum_{\\mathsf{S}'_j, \\mathsf{S}'_k}  P_{\\mathsf{S}_1\\cdots \\mathsf{S}_j  \\mathsf{S}'_{j+1}\\cdots \\mathsf{S}'_N}(t)\\Omega_{\\mathsf{S}'_j \\mathsf{S}'_k,\\mathsf{S}_j \\mathsf{S}_k} $$ $$ \\begin{gathered} \\Omega=\\left(\\begin{array}{cccc} 1 & 0 & 0 & 0 \\\\ 0 & 1-a-b & a & b \\\\ 0 & a & 1-a-b & b \\\\ 0 & \\frac{b}{3} & \\frac{b}{3} & \\left(1-\\frac{2}{3} b\\right) \\end{array}\\right) \\\\ a=\\frac{1}{3}\\left(2 \\sin ^{2} \\theta+\\sin ^{4} \\theta\\right) \\qquad b=\\frac{1}{3}\\left(\\frac{1}{2} \\sin ^{2} 2 \\theta+2\\left(\\sin ^{2} \\theta+\\cos ^{2} \\theta\\right)\\right) \\end{gathered} $$\n\\(\\theta=\\pi/2\\) for \\(i\\operatorname{SWAP}\\), \\(\\theta=\\pi/4\\) for \\(\\sqrt{i\\operatorname{SWAP}}\\)\n\n\n\n\n\n$$ \\begin{gathered} \\Omega=\\left(\\begin{array}{cccc} 1 & 0 & 0 & 0 \\\\ 0 & 1-a-b & a & b \\\\ 0 & a & 1-a-b & b \\\\ 0 & \\frac{b}{3} & \\frac{b}{3} & \\left(1-\\frac{2}{3} b\\right) \\end{array}\\right) \\\\ \\end{gathered} $$\n\nRows sum to one: Stochastic matrix\nPossible transitions\n\n\\[\\require{extpfeil} \\Newextarrow{\\xleftrightharpoon}{5,10}{0x21CB}\n\\mathsf{10} \\xleftrightharpoon[a]{a} \\mathsf{01} \\qquad \\mathsf{11} \\xleftrightharpoon[b/3]{b} \\mathsf{10},\\mathsf{01}\n\\] - \\(\\mathsf{00}\\) is “inert”\n\n\n\n\n\n\n\n\nStationary state: independent sites with \\(p_1=3/4\\), \\(p_0=1/4\\)\n\n\n\n\n\n\nFront propagation characterised by finite velocity \\(v_\\text{B}\\)\n\n\n\n\n\n\n\n\n\nFront broadens unless \\(v_\\text{B}\\) maximal as for \\(i\\operatorname{SWAP}\\)\n\n\n \n\n\\(i\\operatorname{SWAP}\\) (left) vs. \\(\\sqrt{i\\operatorname{SWAP}}\\) (right)\n\n\n\n\nDiffusive in 1D \\(\\propto \\sqrt{t}\\)\nKPZ dynamics in 2D\n\n\n\n\n\nSee Nahum, Vijay, and Haah for much more\n\n\n\n\n\n\nEfficient simulation of averaged OTOC dynamics via Monte Carlo\nAppearance of Markov process a little surprising\n\n\n\n\n\n\nCircuit-to-circuit fluctuations of OTOC from\n\n\\[\n\\hat{\\mathcal{O}}^{(4)}(t)=\\overline{\\hat{O}(t) \\otimes \\hat{O}(t) \\otimes \\hat{O}(t) \\otimes \\hat{O}(t)} \\equiv \\overline{\\hat{O}(t)^{\\otimes 4}}\n\\]\n\nGo through same procedure of identifying invariant states\nEvolution of average now involves negative matrix elements\nLeads to sign problem in Monte Carlo simulation\nSame problem for \\(\\overline{\\operatorname{OTOC}}\\) in models with number conservation (Rowlands and Lamacraft)"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#this-lecture",
    "href": "talks/quantum-circuits-2/index.html#this-lecture",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Correlations near the light cone (see Claeys and Lamacraft for details)\nOperator scrambling and the OTOC"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#infinite-temperature-correlations",
    "href": "talks/quantum-circuits-2/index.html#infinite-temperature-correlations",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "\\[\nc_{\\alpha \\beta}(x,t) = \\langle \\sigma_{\\alpha}(x,t) \\sigma_{\\beta}(0,0) \\rangle,\\qquad \\sigma_\\alpha(x,t)=U^\\dagger(t)\\sigma_\\alpha(x)U(t)\n\\]\n\nVanishes when \\(|x|&gt;t\\) (outside light cone)"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#on-the-light-cone",
    "href": "talks/quantum-circuits-2/index.html#on-the-light-cone",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Using unitarity (only)"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#quantum-channel",
    "href": "talks/quantum-circuits-2/index.html#quantum-channel",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "$$ \\begin{align}\\label{eq:CorrChannels} \\langle \\sigma_{\\alpha}(t,t) \\sigma_{\\beta}(0,0) \\rangle &= \\tr \\left[\\sigma_{\\beta}\\mathcal{M}_{-}^t(\\sigma_{\\alpha})\\right] / q \\\\ &=  \\tr \\left[ \\sigma_{\\alpha}\\mathcal{M}_{+}^{t}(\\sigma_{\\beta})\\right] / q \\end{align} $$ - Calculating correlator involves repeated application of"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#typical-behaviour-of-correlations",
    "href": "talks/quantum-circuits-2/index.html#typical-behaviour-of-correlations",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Surprising that correlations can be found at arbitrary distances!"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#correlations-for-dual-unitaries",
    "href": "talks/quantum-circuits-2/index.html#correlations-for-dual-unitaries",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Bertini, Kos, and Prosen introduced above formalism for dual unitaries\nRecall light cone \\(|x|\\leq t\\) was implied by unitarity\nDual unitarity implies correlations also vanish for \\(|x|\\geq t\\)\nOnly nonzero correlations are on the light cone"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#effect-of-conservation-laws",
    "href": "talks/quantum-circuits-2/index.html#effect-of-conservation-laws",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "\\(SU(2)\\) preserving gate\n\n$$ U_{j,j+1} = \\cos\\theta \\mathbb{1}_{j,j+1} + i\\sin\\theta \\operatorname{P}_{j.j+1} $$\n\\begin{multline} \\mathcal{O} \\longrightarrow U^\\dagger_{j,j+1}\\mathcal{O}U_{j,j+1} = \\cos^2\\theta \\mathcal{O} + \\sin^2\\theta \\operatorname{P}_{j.j+1}\\mathcal{O} \\operatorname{P}_{j.j+1} \\\\ -i\\sin\\theta\\cos\\theta \\left[\\operatorname{P}_{j.j+1}, \\mathcal{O}\\right] \\end{multline}\n\nGenerally useful idea: consider random circuit and average\nTake distribution \\(\\theta=\\pm \\theta_0\\) with \\(p(\\theta_0)-p(-\\theta_0)\\equiv \\delta &gt; 0\\)"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#average-dynamics",
    "href": "talks/quantum-circuits-2/index.html#average-dynamics",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "\\[\\begin{multline}\n\\overline{U^\\dagger_{j,j+1}\\mathcal{O}U_{j,j+1}} = \\cos^2\\theta_0 \\\\, \\mathcal{O} + \\sin^2\\theta_0 \\\\, P_{j.j+1}\\mathcal{O} P_{j.j+1} \\\\\\\\\n+i\\delta \\sin\\theta_0\\cos\\theta_0 \\left[P_{j.j+1}, \\mathcal{O}\\right]\n\\end{multline}\\]\n\nInterpretation:\n\nOperators on sites \\(j\\) and \\(j+1\\) switch with probability \\(\\sin^2\\theta_0\\)\nAsymmetry \\(\\delta\\) governs strength of “quantum” dynamics"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#continuous-time-limit",
    "href": "talks/quantum-circuits-2/index.html#continuous-time-limit",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "\\[\n\\frac{d\\bar{\\mathcal{O}}}{dt} = \\sum_j \\left[iJ \\left[P_{j,j+1},\\bar{\\mathcal{O}}\\right]+\\left(P_{j,j+1}\\bar{\\mathcal{O}}P_{j,j+1}-\\bar{\\mathcal{O}}\\right)\\right].\n\\]\n\\[\\begin{align}\ni[P,\\sigma^a\\otimes 1]&=-\\epsilon^{abc}\\sigma^b\\otimes\\sigma^c\\nonumber\\\\\\\\\ni[P,1\\otimes \\sigma^a]&=\\epsilon^{abc}\\sigma^b\\otimes\\sigma^c\\nonumber\\\\\\\\\ni[P,\\sigma^a\\otimes \\sigma^b]&=\\epsilon^{abc}\\left(\\sigma^c\\otimes 1- 1\\otimes \\sigma^c\\right).\n\\label{eq:split-merge}\n\\end{align}\\]\n\nSum of first two expressions vanishes by spin conservation\nDescribe operator “splitting” (\\(1\\to 2\\)) and “merging” (\\(2\\to 1\\))."
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#expansion-in-pauli-basis",
    "href": "talks/quantum-circuits-2/index.html#expansion-in-pauli-basis",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "$$ Z_j(t)= \\sum_{\\mu_{1:N}=\\{0,1,2,3\\}^N} \\mathcal{C}_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots \\sigma_N^{\\mu_N},\\qquad \\sigma^\\mu = (\\mathbb{1},X,Y,Z) $$\n\nWith initial condition\n\n\\[\n\\begin{equation}\n\\mathcal{C}\\_{\\mu_{1:N}}(0)=\\begin{cases}\n1 & \\mu_j=z, \\mu_k=0,\\forall k\\neq j \\\\\\\\\n0 & \\text{otherwise},\n\\end{cases}\n\\end{equation}\n\\]\n\nSpin correlations \\(\\langle Z_j(t)Z_k(0)\\rangle=C_{jk}(t) = \\mathcal{C}_{0\\cdots \\mu_k=z \\cdots 0}(t)\\)"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#j0-1-operator-sector",
    "href": "talks/quantum-circuits-2/index.html#j0-1-operator-sector",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Writing \\(\\mathcal{C}^a_{0\\cdots \\mu_k=a\\cdots 0}\\equiv C^a_k\\) we have equation of motion\n\n\\[\n\\partial_t C^a_k = C^a_{k+1} + C^a_{k-1} - 2 C^a_k\\equiv \\Delta_k C^a_k\n\\]\n\nDiffusion of single \\(\\sigma^a\\) (\\(\\Delta_k\\) is 1D discrete Laplacian)"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#equation-of-motion",
    "href": "talks/quantum-circuits-2/index.html#equation-of-motion",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "\\[\n\\begin{align}\n\\partial_t \\mathcal{C}\\_{\\mu_{1:N}} = \\sum_j \\left[J\\epsilon_{\\alpha\\beta \\mu_j \\mu_{j+1}} \\mathcal{C}\\_{\\mu_1\\cdots \\alpha\\beta \\cdots \\mu_N} + \\mathcal{C}\\_{\\mu_1\\cdots \\mu_{j+1}\\mu_j \\cdots \\mu_N} - \\mathcal{C}\\_{\\mu_1\\cdots \\mu_{j}\\mu_{j+1} \\cdots \\mu_N}\\right].\n\\end{align}\n\\]\n\n\n\n\nSee Claeys, Lamacraft, and Herzog-Arbeitman for more"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#operator-spreading",
    "href": "talks/quantum-circuits-2/index.html#operator-spreading",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Correlations (typically) decay exponentially\nDoesn’t mean that operator dynamics is trivial!\nWhat can we say about \\(\\sigma_\\alpha(x,t)=U^\\dagger(t)\\sigma_\\alpha(x) U(t)\\) generally?\n\n\n$$ Z_j(t)= \\sum_{\\mu_{1:N}=\\{0,1,2,3\\}^N} \\mathcal{C}_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots \\sigma_N^{\\mu_N},\\qquad \\sigma^\\mu = (\\mathbb{1},X,Y,Z) $$\n\nAs time progresses two things (tend to) increase\n\nNumber of non-identity sites (operator spreading)\nNumber of different contributions (operator entanglement)\n\nHow to quantify these?\n\nOperator spreading defines “butterfly velocity”\nClifford gates lead to operator spreading but no entanglement"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#out-of-time-order-correlator",
    "href": "talks/quantum-circuits-2/index.html#out-of-time-order-correlator",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "\\[\n\\operatorname{OTOC}_{jk}(t) =\\langle Z_j(t)Z_k(0)Z_j(t)Z_k(0)\\rangle\n\\]\n$$ Z_j(t)= \\sum_{\\mu_{1:N}=\\{0,1,2,3\\}^N} \\mathcal{C}_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots \\sigma_N^{\\mu_N} $$\n$$ \\operatorname{OTOC}_{jk}(t)\\propto \\sum_{\\mu_{1:N}}\\mathcal{C}_{\\mu_{1:N}}^2(t)\\left[\\delta_{\\mu_k,0}+\\delta_{\\mu_k,3}-\\delta_{\\mu_k,1}-\\delta_{\\mu_k,2}\\right] $$\n\n\\(\\operatorname{OTOC}_{jk}(t)\\neq 1\\) when operator \\(Z_j(t)\\) spreads from site \\(j\\) to site \\(k\\)\nInvolves $\\mathcal{C}_{\\mu_{1:N}}^2(t)$ so survives averaging"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#googles-otoc-experiment",
    "href": "talks/quantum-circuits-2/index.html#googles-otoc-experiment",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "\\(i\\operatorname{SWAP}\\): sharp OTOC front\n\\(\\sqrt{i\\operatorname{SWAP}}\\): broadened OTOC front"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#overlineoperatornameotoc-stochastic-model",
    "href": "talks/quantum-circuits-2/index.html#overlineoperatornameotoc-stochastic-model",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "See Google’s OTOC experiment (supplementary material)\nContinuous time version in Rowlands and Lamacraft\nMain idea: OTOC extracted from\n\n\\[\n\\hat{\\mathcal{O}}^{(2)}(t)=\\overline{\\hat{O}(t) \\otimes \\hat{O}(t)} \\equiv \\overline{\\hat{O}(t)^{\\otimes 2}}\n\\]\n\n\\[\n\\hat{\\mathcal{O}}^{(2)}(t)=\\overline{\\hat{O}(t) \\otimes \\hat{O}(t)} \\equiv \\overline{\\hat{O}(t)^{\\otimes 2}}\n\\]\n\nInvariant subspace that survives averaging built from \\(\\mathsf{O} \\equiv\\mathbb{1}\\otimes\\mathbb{1}\\) and \\(\\mathsf{1}\\equiv\\frac{1}{3}\\left[X\\otimes X + Y\\otimes Y+ Z\\otimes Z\\right]\\) on each site\nBasis: \\(\\mathsf{S}_{1:N}\\equiv\\mathsf{S}_1\\otimes \\mathsf{S}_2\\otimes\\cdots \\mathsf{S}_N\\), with \\(\\mathsf{S}_j=0,1\\)\n\n$$ \\hat{\\mathcal{O}}^{(2)}(t) = \\sum_{\\mathsf{S}_{1:N}\\in\\{\\mathsf{0},\\mathsf{1}\\}^N} P_{\\mathsf{S}_{1:N}}\\mathsf{S}_{1:N} $$\n\n$$ \\hat{\\mathcal{O}}^{(2)}(t) = \\sum_{\\mathsf{S}_{1:N}\\in\\{\\mathsf{0},\\mathsf{1}\\}^N} P_{\\mathsf{S}_{1:N}}\\mathsf{S}_{1:N} $$\n\n(Average of) gate provides update rule for \\(P_{\\mathsf{S}_{1:N}}\\) $$ P_{\\mathsf{S}_{1:N}}(t+1) = \\sum_{\\mathsf{S}'_j, \\mathsf{S}'_k}  P_{\\mathsf{S}_1\\cdots \\mathsf{S}_j  \\mathsf{S}'_{j+1}\\cdots \\mathsf{S}'_N}(t)\\Omega_{\\mathsf{S}'_j \\mathsf{S}'_k,\\mathsf{S}_j \\mathsf{S}_k} $$ $$ \\begin{gathered} \\Omega=\\left(\\begin{array}{cccc} 1 & 0 & 0 & 0 \\\\ 0 & 1-a-b & a & b \\\\ 0 & a & 1-a-b & b \\\\ 0 & \\frac{b}{3} & \\frac{b}{3} & \\left(1-\\frac{2}{3} b\\right) \\end{array}\\right) \\\\ a=\\frac{1}{3}\\left(2 \\sin ^{2} \\theta+\\sin ^{4} \\theta\\right) \\qquad b=\\frac{1}{3}\\left(\\frac{1}{2} \\sin ^{2} 2 \\theta+2\\left(\\sin ^{2} \\theta+\\cos ^{2} \\theta\\right)\\right) \\end{gathered} $$\n\\(\\theta=\\pi/2\\) for \\(i\\operatorname{SWAP}\\), \\(\\theta=\\pi/4\\) for \\(\\sqrt{i\\operatorname{SWAP}}\\)"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#markov-process",
    "href": "talks/quantum-circuits-2/index.html#markov-process",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "$$ \\begin{gathered} \\Omega=\\left(\\begin{array}{cccc} 1 & 0 & 0 & 0 \\\\ 0 & 1-a-b & a & b \\\\ 0 & a & 1-a-b & b \\\\ 0 & \\frac{b}{3} & \\frac{b}{3} & \\left(1-\\frac{2}{3} b\\right) \\end{array}\\right) \\\\ \\end{gathered} $$\n\nRows sum to one: Stochastic matrix\nPossible transitions\n\n\\[\\require{extpfeil} \\Newextarrow{\\xleftrightharpoon}{5,10}{0x21CB}\n\\mathsf{10} \\xleftrightharpoon[a]{a} \\mathsf{01} \\qquad \\mathsf{11} \\xleftrightharpoon[b/3]{b} \\mathsf{10},\\mathsf{01}\n\\] - \\(\\mathsf{00}\\) is “inert”"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#fredricksonandersen-model",
    "href": "talks/quantum-circuits-2/index.html#fredricksonandersen-model",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Stationary state: independent sites with \\(p_1=3/4\\), \\(p_0=1/4\\)"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#butterfly-velocity",
    "href": "talks/quantum-circuits-2/index.html#butterfly-velocity",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Front propagation characterised by finite velocity \\(v_\\text{B}\\)"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#front-broadening",
    "href": "talks/quantum-circuits-2/index.html#front-broadening",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Front broadens unless \\(v_\\text{B}\\) maximal as for \\(i\\operatorname{SWAP}\\)\n\n\n \n\n\\(i\\operatorname{SWAP}\\) (left) vs. \\(\\sqrt{i\\operatorname{SWAP}}\\) (right)\n\n\n\n\nDiffusive in 1D \\(\\propto \\sqrt{t}\\)\nKPZ dynamics in 2D\n\n\n\n\n\nSee Nahum, Vijay, and Haah for much more"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#classical-simulation",
    "href": "talks/quantum-circuits-2/index.html#classical-simulation",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Efficient simulation of averaged OTOC dynamics via Monte Carlo\nAppearance of Markov process a little surprising"
  },
  {
    "objectID": "talks/quantum-circuits-2/index.html#otoc-fluctuations",
    "href": "talks/quantum-circuits-2/index.html#otoc-fluctuations",
    "title": "Quantum Circuits II",
    "section": "",
    "text": "Circuit-to-circuit fluctuations of OTOC from\n\n\\[\n\\hat{\\mathcal{O}}^{(4)}(t)=\\overline{\\hat{O}(t) \\otimes \\hat{O}(t) \\otimes \\hat{O}(t) \\otimes \\hat{O}(t)} \\equiv \\overline{\\hat{O}(t)^{\\otimes 4}}\n\\]\n\nGo through same procedure of identifying invariant states\nEvolution of average now involves negative matrix elements\nLeads to sign problem in Monte Carlo simulation\nSame problem for \\(\\overline{\\operatorname{OTOC}}\\) in models with number conservation (Rowlands and Lamacraft)"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html",
    "href": "talks/quantum-circuits-1-icts/index.html",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "austen.uk/slides/quantum-circuits-1-icts for slides\n\n\n\n\n\nThis lecture\n\nWhat is a quantum circuit?\nWhat are the quantities of interest?\n\nNext lecture\n\nSome special kinds of circuits\n\n\n\n\n\n\n\nA way to describe operations on quantum state, usually consisting of several qubits (spin 1/2 subsystems with Hilbert space \\(\\mathbb{C}^2\\))\nTwo quantum states \\(\\ket{0}\\) and \\(\\ket{1}\\) define the computational basis.\n\n\n\n\n\n\\(f\\) acts on top five qubits, then \\(g\\) acts on lower seven\n\n\n\n\n\n\n\n\nSource: Wikipedia\n\n\n\n\\(H\\) (a Hadamard gate) is a single qubit unitary\nAlso two qubit unitary gates (CNOT here)\nMeasurements\n\n\n\n\n\n\nFor this program: example of discrete time, many body dynamics\nModel of universal quantum computation\n\nHow to generate an arbitrary quantum state\nOne of several options e.g. measurement-based\n\nThey exist! Companies (Google, IBM, etc.) have built platforms for gate-based QC\n\n\n\n\n\n\n(Mostly) concerned with unitary circuits made from unitary gates\nGate is \\(n\\)-qubit unitary \\(U_{s_1\\ldots s_n,s'_1,\\ldots, s'_n}\\)\n\n$$ \\sum_{s_1'\\ldots s_N'}U_{s_1\\ldots s_n,s'_1,\\ldots, s'_n} U^\\dagger_{s'_1\\ldots s'_n,s''_1,\\ldots, s''_n}=\\delta_{s_1,s_1''}\\ldots \\delta_{s_N,s_N''} $$\n\n\n\n\n\nState of \\(N\\) qubits expressed in product basis\n\n$$ \\ket{\\Psi} = \\sum_{s_{1:N}\\in \\{0,1\\}^N} \\Psi_{s_1\\ldots s_N}\\ket{s_1}_1\\ket{s_2}_2\\cdots \\ket{s_N}_N $$\n\nWrite $\\ket{s_1}_1\\ket{s_2}_2\\cdots \\ket{s_N}_N =\\ket{s_1\\cdots s_N}=\\ket{s_{1:N}}$ for brevity\nOperator on \\(N\\) qubits has matrix elements\n\n$$ \\mathcal{O}_{s_{1:N},s'_{1:N}} = \\bra{s_{1:N}}\\mathcal{O}\\ket{s'_{1:N}} $$\n\n\n\n\n\nA tensor is denoted by a blob with one leg for each index\nConnecting legs denotes contraction: summing over a shared index\n\n\n\n\nSee Glen Evenbly’s tensor contraction tutorial\n\n\n\n\n\n\n\nMultiplication by a Pauli matrix: \\(X\\), \\(Y\\), or \\(Z\\).\nGeneral case \\(U = a_0\\mathbb{1} + \\mathbf{a}\\cdot(X,Y,Z)\\) with \\(|a_0|^2+|\\mathbf{a}|^2=1\\)\nOther special cases used in quantum information e.g. Hadamard gate\n\n\\[\nH = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}\n1 & 1 \\\\\\\\\n1 & -1\n\\end{pmatrix}\n\\]\n\n\n\n\n\nWork in basis \\(\\ket{00}\\), \\(\\ket{01}\\), \\(\\ket{10}\\), \\(\\ket{11}\\)\nSimplest example is SWAP gate\n\n\\[\n\\operatorname{SWAP}=\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\\\n0 & 0 & 1 & 0 \\\\\\\n0 & 1 & 0 & 0 \\\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n\\].\n\\[\n\\operatorname{SWAP}\\ket{10} = \\ket{01}\n\\]\n\nSWAP takes product states to product states\n\n\n\nSlightly more complicated: square root of SWAP\n\n\\[\n\\sqrt{\\operatorname{SWAP}}=\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\\\n0 & \\frac{1}{2}(1+i) & \\frac{1}{2}(1-i) & 0 \\\\\\\n0 & \\frac{1}{2}(1-i) & \\frac{1}{2}(1+i) & 0 \\\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n\\]\n\nThis generates entanglement: takes product state to non-product state\n\n\\[\n\\sqrt{\\operatorname{SWAP}}\\ket{10} = \\frac{1}{2}\\left[(1+i)\\ket{10}+(1-i)\\ket{01}\\right]\n\\]\n\n\\(\\sqrt{\\operatorname{SWAP}}\\) conserves number of 1s and 0s\n\\(\\sqrt{\\operatorname{SWAP}}\\) together with arbitrary single qubit unitary operators form universal gate set that allows for universal quantum computation\n\n\n\n\n\n\nAny two-qubit unitary \\(U\\in \\mathcal{U(4)}\\) can be written\n\n\\[\nU = e^{i \\phi} (u_+ \\otimes u_-) V[J_x, J_y, J_z] (v_- \\otimes v_+)\n\\]\n\n\\(u_{\\pm}, v_{\\pm} \\in SU(2)\\)\n\n\\[\n\\begin{align*}\nV[J_x, J_y, J_z] &= \\exp \\left[-i\\left(J_x \\sigma^x \\otimes \\sigma^x + J_y \\sigma^y \\otimes \\sigma^y+ J_z \\sigma^z \\otimes \\sigma^z\\right)\\right]\\\\\\\\\n&= \\begin{bmatrix}\ne^{-i J_z} \\cos(J_-) & 0 & 0 & -i e^{-i J_z \\sin(J_-)} \\\\\\\\\n0 & e^{iJ_z} \\cos(J_+) & -ie^{i J_z} \\sin(J_+) & 0 \\\\\\\\\n0 & -ie^{i J_z} \\sin(J_+) & e^{iJ_z} \\cos(J_+) & 0 \\\\\\\\\n-i e^{-i J_z \\sin(J_-)} & 0 & 0 & e^{-i J_z} \\cos(J_-) \\\\\\\\\n\\end{bmatrix}\n\\end{align*}\n\\]\n\n16 parameters!\n\n\n\n\n\n\n\n\nTime evolution operator \\(U=\\exp(-iHt)\\)\nIf \\(H=\\sum_j h_j\\) a sum of single qubit terms\n\n\\[\n\\mathcal{U} = \\exp(-iHt) = \\prod_j \\exp(-ih_j) = \\prod_j U_j\n\\] \\[\nU_j=\\mathbb{1}\\otimes \\ldots \\otimes\\mathbb{1} \\otimes \\overbrace{u_j}^{j\\text{th factor}} \\ldots \\otimes\\mathbb{1}\n\\]\n\n\n\n\n\nSimplest example of two qubit interaction is exchange Hamiltonian\n\n\\[\n\\begin{align*}\nh_{12} &= J\\left[X\\otimes X+Y\\otimes Y+Z\\otimes Z\\right] =J\\left[X_1X_2+Y_1Y_2 + Z_1Z_2\\right]\\\\\\\n&=2\\operatorname{SWAP} - 1\n\\end{align*}\n\\] \\[\nU(J) = \\exp(-ih_{12}) = e^{iJ}\\left[\\cos (2J) \\mathbb{1} - i\\sin (2J) \\operatorname{SWAP}\\right]\n\\]\n\nSpecial cases\n\n\\[\nU(\\pi/4)=\\operatorname{SWAP}\n\\] \\[\nU(\\pi/8)=\\sqrt{\\operatorname{SWAP}}\n\\]\n\nFully rotationally invariant\n\n\n\n\\(H=\\sum_{i,j} h_{i,j}\\) a sum of two qubit terms with \\([h_{i,j},h_{j,k}]\\neq 0\\)\n\n\n\n\nSource: Glen Evenbly\n\n\n\n\\(\\mathcal{U}\\neq \\prod_{i,j} \\exp(-ih_{i,j})\\). More complicated!\nSuzuki–Trotter expansion: decompose \\(H=H_A + H_B\\)\n\n\\[\n\\mathcal{U} = \\exp(-iH) = \\left[\\exp\\left(-\\frac{iH}{n}\\right)\\right]^n \\sim \\left[e^{-iH_A/n} e^{-iH_B/n}\\right]^n\n\\]\n\n\\[\nH = \\sum_j h_{j,j+1}\n\\] \\[\nH_A = \\sum_j h_{2j, 2j+1}\\qquad H_B = \\sum_j h_{2j-1, 2j}\n\\] \\[\ne^{-iH_A/n}=\\prod_j U_{2j,2j+1}\\qquad e^{-iH_B/n} = \\prod_j U_{2j-1,2j}\n\\]\n\n\n\n\n\n\n\n\n\nTime dependent Hamiltonian with kicks at \\(t=0,1,2,\\ldots\\).\n\n\\[\n\\begin{align*}\nH_{\\text{KIM}}(t) = H_\\text{I}[\\mathbf{h}] + \\sum_{n}\\delta(t-n)H_\\text{K}\\\\\\\nH_\\text{I}[\\mathbf{h}]=\\sum_{j=1}^L\\left[J Z_j Z_{j+1} + h_j Z_j\\right],\\qquad H_\\text{K} &= b\\sum_{j=1}^L X_j,\n\\end{align*}\n\\]\n\n“Stroboscopic” form of \\(\\mathcal{U}(t)=\\mathcal{T}\\exp\\left[-i\\int^t H_{\\text{KIM}}(t') dt'\\right]\\)\n\n\\[\n\\begin{aligned}\n  \\mathcal{U}(n_+) &= \\left[\\mathcal{U}(1_+)\\right]^n,\\qquad U(1_-) = K I_\\mathbf{h}\\\\\\\n  I_\\mathbf{h} &= e^{-iH_\\text{I}[\\mathbf{h}]}, \\qquad K = e^{-iH_\\text{K}}\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\\[\n\\begin{aligned}\n  \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\\\\n  \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]\n\\end{aligned}\n\\]\n\n\n\n\n\nLocality a feature of real quantum computing architectures\n\n\n \n\n(top) a schematic view of the Google Sycamore processor and (bottom) the real thing\n\n\n\n\n\n\n\nState is vector in \\(2^N\\) dimensional space\nUpdating involves acting with a unitary matrix\nNaive matrix-vector multiplication \\(O(\\operatorname{dim}^2)=2^{2N}\\)\nSince gates gives sparse matrices update is \\(O(\\operatorname{dim})=2^{N}\\)\nStill exponentially hard in the number of qubits\n\n\n\n\n\n\nDifficulty on classical computer basis of “quantum supremacy” based on circuit sampling\nMeasure empirical distribution of bit strings with fixed initial state\nTotal number of (time) steps \\(T\\) taken is depth of the circuit. For low depth \\(T&lt;N\\) it pays to move horizontally instead\nProblem of finding optimal contraction strategy in general is NP-hard\nGoogle’s initial claim of supremacy disputed by supercomputer optimizations, followed by improved tensor network methods: Huang et al. (2020), Gray and Kourtis (2021), Pan and Zhang (2021), Napp et al. (2022)\n\n\n\n\n\n\n\n\n\n\nEvaluate \\(\\bra{\\Psi}\\mathcal{O}\\ket{\\Psi}=\\bra{\\Psi_0}\\mathcal{U}^\\dagger\\mathcal{O}\\mathcal{U}\\ket{\\Psi_0}\\) for local operator \\(\\mathcal{O}\\)\n\nSimplest example: \\(X\\), \\(Y\\), or \\(Z\\) for one qubit\n\\(\\mathcal{U}\\) is overall unitary operator describing whole circuit\n\n\n\n\n\n\n\nHave to consider both unitaries and conjugates\nIntroduce color-coded notation\n\n\n\n\n\n\nCondition of unitarity \\(U^\\dagger U = U U^\\dagger = \\mathsf{1}\\)\n\n\\[\n\\sum\\_{\\alpha,\\beta}U^{\\vphantom{\\dagger}}_{a,b,\\alpha,\\beta} U^\\dagger\\_{\\alpha,\\beta,c,d}=\\delta\\_{ac}\\delta\\_{bd}\n\\]\n\nUnitarity of two qubit gate expressed as\n\n\n\n\n\nMuch better!\n\n\n\n\n\n\n\\(\\bra{\\Psi}\\mathcal{O}\\ket{\\Psi}=\\bra{\\Psi_0}\\mathcal{U}^\\dagger\\mathcal{O}\\mathcal{U}\\ket{\\Psi_0}\\) has diagrammatic representation\n\n\n\n\n(leave initial state \\(\\ket{\\Psi}\\) unspecified for the moment)\n\n\n\n\n\n\nSince every \\(U\\) accompanied by \\(U^\\dagger\\), include both in single unit by “folding” one on top of the other\n\n\n\n\n\nLines correspond to two indices, and therefore \\(2^2=4\\) dimensions\nUnitarity condition takes form:\n\n\n\n\n\n\nIn folded picture expectation value \\(\\bra{\\Psi}\\mathcal{O}\\ket{\\Psi}\\) looks like this\n\n\n\n\n\nClick to apply unitary condition!\n\n\n\n“Light cone” emerges, reflecting region of circuit that affects expectation value\n\n\n\n\n\n\nExpectation value of operator in region \\(A\\) can be computed from reduced density matrix \\(\\rho_A\\) for region \\(A\\) \\[\n\\rho_A = \\operatorname{tr}\\_{B}\\left[\\ket{\\Psi}\\bra{\\Psi}\\right]=\\operatorname{tr}_{B}\\left[\\mathcal{U}\\ket{\\Psi_0}\\bra{\\Psi_0}\\mathcal{U}^\\dagger\\right]\n\\] (\\(B\\) is complement of \\(A\\))\n\n\n\n\n\nInitial RDM of bottom part of wedge is all that matters!\n\n\n\n\n\n\nRDM quantifies entanglement present in a quantum state describing a system composed of two subsystems A and B\nGeneral state is vector \\(\\in\\mathcal{H}=\\mathcal{H}\\_A\\otimes\\mathcal{H}\\_B\\)\nWrite in terms of basis vectors \\(\\ket{a}\\_A\\) and \\(\\ket{b}\\_B\\) for A and B subsystems \\[\n\\ket{\\Psi}\\_{AB} = \\sum\\_{a=1}^{n\\_A}\\sum\\_{b=1}^{n\\_B} \\Psi\\_{ab}\\ket{a}\\_A\\ket{b}\\_B\n\\] \\(n\\_{A/B}=\\operatorname{dim} \\mathcal{H}\\_{A/B}\\)\nNow regard \\(\\psi_{ab}\\) as matrix and perform a singular value decomposition\n\n\n\nIn new bases our state is\n\n\\[\n\\ket{\\Psi}\\_{AB} = \\sum\\_{n=1}^{\\min(n_A, n_B)} \\sigma\\_n \\ket{u\\_n}\\_A\\otimes\\ket{v\\_n}\\_B\n\\]\n\nNote single sum, c.f. double sum earlier. This is Schmidt decomposition\n\\(\\sigma_n\\) are Schmidt coefficients (singular values of SVD)\nIf only one nonzero singular value state we have product state, indicating no correlations between subsystems\n\n\n\nSimplest example displaying nontrivial entanglement is Bell state\n\n\\[\n\\left|\\Psi^{+}\\right\\rangle=\\frac{1}{\\sqrt{2}}\\left(|0\\rangle_A \\otimes|1\\rangle_B+|1\\rangle_A \\otimes|0\\rangle_B\\right)\n\\]\n\nSchmidt coefficients both \\(\\frac{1}{\\sqrt{2}}\\), indicating maximal entanglement\nSchmidt decomposition closely related to RDM \\[\n\\rho_A = \\operatorname{tr}\\_B\\left[\\ket{\\Psi}\\bra{\\Psi}\\right]\n= \\sum\\_n \\sigma_n^2 \\ket{u\\_n}\\bra{u\\_n}\n\\]\nEigenvalues of RDM are \\(p_n=\\sigma_n^2\\)\n\n\n\nOne measure of entanglement is von Neumann entropy of \\(\\rho_A\\) (aka entanglement entropy)\n\n\\[\nS^{(\\text{vN})}_A \\equiv -\\operatorname{tr}\\left[\\rho_A\\log \\rho_A\\right]\n\\]\n\n\\(S_A\\) vanishes for product state, and is otherwise positive\n\n\n\nRényi entropies provide more complete information \\[\nS^{(\\alpha)}\\_A = \\frac{1}{1-\\alpha}\\log \\text{tr}\\left[\\rho^n\\right]=\\frac{1}{1-\\alpha}\\sum\\_n p\\_n^\\alpha\n\\] \\(S^{(\\text{vN})}\\_A=\\lim\\_{\\alpha\\to 1} S^{(\\alpha)}\\_A\\). \\(S^{(0)}\\_A\\) is number of nonzero Schmidt coefficients (aka Schmidt rank) \\[\nS^{(2)}\\_A = -\\log \\sum_n p_n^2 = -\\log \\gamma\\tr \\rho_A^2\n\\] where \\(\\gamma\\equiv \\tr \\rho_A^2\\) is purity\n\n\n\n\n\n\nCircuit of SWAP gates\n\n\n\nInitial state is product of Bell states \\[\n\\ket{\\Phi^+}\\_{2n, 2n+1} = \\frac{1}{\\sqrt{2}}\\left[\\ket{0}\\_{2n}\\ket{0}\\_{2n+1}+ \\ket{1}\\_{2n}\\ket{1}\\_{2n+1}\\right]\n\\] \\[\n\\operatorname{tr}\\_{2}\\left[\\ket{\\Phi^+}\\_{12}\\bra{\\Phi^+}\\_{12}\\right] = \\frac{1}{2}\\mathbb{1}_1\n\\] with entanglement entropy of one bit\n\n\n\n\\(\\rho_A\\) therefore has factor \\(\\mathbb{1}_n\\) for each site \\(n\\in A\\) with “partner” in \\(B\\)\nIf both qubits of a Bell pair are at sites \\(n,m\\in A\\) they give a factor \\(\\ket{\\Phi^+}\\_{nm}\\bra{\\Phi^+}\\_{nm}\\): a pure state\nEntanglement entropy has contributions from first case only\n\n\\[\nS_A = \\min(4\\lfloor t/2\\rfloor, |A|) \\text{ bits}\n\\]\n\n\\[\nS_A = \\min(4\\lfloor t/2\\rfloor, |A|) \\text{ bits}\n\\]\n\nAfter time \\(\\sim |A|/2\\) subsystem has thermalized.\n\n\n\n\nSource: Bertini et al. (2019)\n\n\n\n\nRamp behaviour in many systems\nIn noninteracting systems or integrable systems, often explained in terms of the causal propagation of (quasi-)particles:\n\n\n\n\nSource: Calabrese and Cardy (2005)\n\n\n\n\nToy model with SWAP gates is rather similar, with qubits playing the role of “noninteracting particles”\nThis picture remains true in circuits where there is no quasiparticle interpretation (next lecture)\n\n\n\n\n\n\nNatural correlation function to consider is\n\n\\[\nc_{\\alpha \\beta}(x,t) = \\frac{1}{2^N}\\tr\\left[\\sigma_{\\alpha}(x,t) \\sigma_{\\beta}(0,0) \\right],\\qquad \\sigma_\\alpha(x,t)=\\mathcal{U}^\\dagger(t)\\sigma_\\alpha(x)\\mathcal{U}(t)\n\\]\n\nAverage overall all initial states uniformly\nThis is “infinite temperature”, although temperature is not defined\n\n\n\n\n\n\\[\nc_{\\alpha \\beta}(x,t) = \\frac{1}{2^N}\\tr\\left[\\sigma_{\\alpha}(x,t) \\sigma_{\\beta}(0,0) \\right],\\qquad \\sigma_\\alpha(x,t)=\\mathcal{U}^\\dagger(t)\\sigma_\\alpha(x)\\mathcal{U}(t)\n\\]\n\n\n\n\n\nWhen \\(|x|&gt;t\\) unitarity condition leads to removal of all \\(U\\)s and \\(U^\\dagger\\)s \\[\nc_{\\alpha \\beta}(x,t) = \\frac{1}{4}\\tr\\left[\\sigma_{\\alpha}\\right]\\tr\\left[\\sigma_{\\beta}\\right]=0,\n\\] and correlations vanish (if operators are traceless)\nCorrelations only nonzero inside “light cone”\n\n\n\nWhen \\(|x|=t\\) remaining tensor network is particularly simple:\n\n\n\n\n\n\nRewrite in several ways, including in folded representation:\n\n\n\n\n\n\\(q\\) is local Hilbert space dimension (\\(q=2\\) up to now)\nNormalization factor by comparing with \\(\\sigma_\\alpha=\\sigma_\\beta=\\mathsf{1}\\) (here \\(t=4\\))\n\n\n\nEvaluate by iteratively applying operator map \\(\\mathcal{M}\\_+\\) or \\(\\mathcal{M}\\_-\\)\n\n\n \n\n\\[\n\\begin{align*}\n\\langle \\sigma\\_{\\alpha}(t,t) \\sigma\\_{\\beta}(0,0) \\rangle &= \\tr \\left[\\sigma\\_{\\beta}\\mathcal{M}\\_{-}^t(\\sigma\\_{\\alpha})\\right] / q \\\\\\\n&=  \\tr \\left[ \\sigma\\_{\\alpha}\\mathcal{M}\\_{+}^{t}(\\sigma\\_{\\beta})\\right] / q\n\\end{align*}\n\\]\n\n\\(\\mathcal{M}\\_\\pm\\) are examples of quantum channels: completely positive trace preserving maps between spaces of operators\n\\(\\mathcal{M}\\_\\pm\\) have the additional property of being unital: \\(\\mathcal{M}\\_\\pm(\\mathsf{1})=\\mathsf{1}\\)\n\n\n\n\n\n\n\n\nSource: Claeys and Lamacraft (2020)\n\n\n\n\nCan evaluate correlation inside light cone\n\n\n\n\n\n“One step inside” involves quantum channel acting on two-site operators: a space of dimension \\(q^4\\).\nTaking \\(s\\) steps inside channel acting on \\(q^{2s}\\)-dimensional space\nGeneral situation is really exponentially hard, as we’d expect\n\n\n\n\n\n\nHow does a local operator “look” as it evolves in Heisenberg picture?\n\\(Z_n(t)=\\mathcal{U}^\\dagger(t)Z_n \\mathcal{U}(t)\\) appears in \\(\\langle Z_n(t)Z_m(0) \\rangle\\), but this is only one “component” of \\(Z_n(t)\\)\nAny observable such as \\(Z_n(t)\\) can be expressed as expansion \\[\nZ_n(t)= \\sum_{\\mu_{1:N}=\\\\{1,x,y,z\\\\}^N} \\mathcal{C}\\_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots \\sigma_N^{\\mu_N}\n\\] \\[\n\\mathcal{C}\\_{\\mu_{1:N}}(0)=\\begin{cases}\n1 & \\mu_j=z, \\mu_k=1,\\forall k\\neq j \\\\\\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\n\n\n\\[\nZ_n(t)= \\sum_{\\mu_{1:N}=\\\\{1,x,y,z\\\\}^N} \\mathcal{C}\\_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots \\sigma_N^{\\mu_N}\n\\]\n\nSince \\(\\tr\\left[\\sigma_\\alpha\\sigma_\\beta\\right]=2\\delta_{\\alpha\\beta}\\), can extract spin correlations from \\(\\langle Z_j(t)Z_k(0)\\rangle=C_{jk}(t) \\equiv \\mathcal{C}_{1\\cdots \\mu_k=z \\cdots 1}(t)\\)\n\n\n\n\n\nThis represents only one component of operator expansion\n\n\n\nOperator norm \\(\\tr\\left[Z\\_n^2(t)\\right]=2\\) is conserved under time evolution\nThis implies the normalization\n\n\\[\n\\sum_{\\mu_{1:N}=\\\\{1,x,y,z\\\\}^N} \\mathcal{C}^2\\_{\\mu_{1:N}}(t) = \\frac{1}{2^{N-1}}.\n\\]\n\n\n\n\n\nConsider gate generated by exchange Hamiltonian: \\[\nU\\_{j,j+1} = \\cos\\theta \\mathbb{1}\\_{j,j+1} + i\\sin\\theta \\operatorname{\\mathsf{S}}\\_{j.j+1}\n\\] \\(\\operatorname{\\mathsf{S}}_{j,j+1}\\) denotes \\(\\operatorname{\\mathsf{SWAP}}\\) gate on sites \\(j\\) and \\(j+1\\)\nAction of this gate on an operator is\n\n\\[\n\\mathcal{O} \\longrightarrow U^\\dagger\\_{j,j+1}\\mathcal{O}U\\_{j,j+1} = \\cos^2\\theta \\mathcal{O} + \\sin^2\\theta \\operatorname{\\mathsf{S}}\\_{j.j+1}\\mathcal{O} \\operatorname{\\mathsf{S}}\\_{j.j+1} \\\\\\\n-i\\sin\\theta\\cos\\theta \\left[\\operatorname{\\mathsf{S}}\\_{j.j+1}, \\mathcal{O}\\right]\n\\]\n\n\n\n\n\nConsider ensemble averaged quantities\nTake \\(\\theta=\\pm \\theta_0\\) with \\(p(\\theta_0)-p(-\\theta_0)\\equiv \\delta &gt; 0\\).\nAveraging the evolved operator gives\n\n\\[\n\\overline{U^\\dagger_{j,j+1}\\mathcal{O}U_{j,j+1}} = \\cos^2\\theta_0 \\\\, \\mathcal{O} + \\sin^2\\theta_0 \\\\, \\mathsf{S}\\_{j.j+1}\\mathcal{O} \\mathsf{S}\\_{j.j+1} \\\\\\\\\n+i\\delta \\sin\\theta_0\\cos\\theta_0 \\left[\\mathsf{S}\\_{j.j+1}, \\mathcal{O}\\right]\n\\]\n\nInterpretation\n\nOperators on sites \\(j\\) and \\(j+1\\) switch with probability \\(\\sin^2\\theta_0\\).\nThe asymmetry \\(\\delta\\) governs strength of “quantum” dynamics\n\n\n\n\nContinuous time limit (Claeys, Lamacraft & Herzog-Arbeitman (2022) \\[\n\\frac{d\\bar{\\mathcal{O}}}{dt} = \\sum_j \\left[iJ \\left[\\mathsf{S}\\_{j,j+1},\\bar{\\mathcal{O}}\\right]+\\left(\\mathsf{S}\\_{j,j+1}\\bar{\\mathcal{O}}\\mathsf{S}\\_{j,j+1}-\\bar{\\mathcal{O}}\\right)\\right]\n\\] where \\(J\\propto \\delta\\). Computing commutator:\n\n\\[\n\\begin{align*}\ni[\\mathsf{S},\\sigma^a\\otimes 1]&=-\\epsilon^{abc}\\sigma^b\\otimes\\sigma^c\\nonumber\\\\\\\\\ni[\\mathsf{S},1\\otimes \\sigma^a]&=\\epsilon^{abc}\\sigma^b\\otimes\\sigma^c\\nonumber\\\\\\\\\ni[\\mathsf{S},\\sigma^a\\otimes \\sigma^b]&=\\epsilon^{abc}\\left(\\sigma^c\\otimes 1- 1\\otimes \\sigma^c\\right).\n\\end{align*}\n\\]\n\nDescribes operator “splitting” (\\(1\\to 2\\)) and “merging” (\\(2\\to 1\\))\n\n\n\n\n\n\\[\n\\frac{d\\bar{\\mathcal{O}}}{dt} = \\sum_j \\left[iJ \\left[\\mathsf{S}\\_{j,j+1},\\bar{\\mathcal{O}}\\right]+\\left(\\mathsf{S}_{j,j+1}\\bar{\\mathcal{O}}\\mathsf{S}\\_{j,j+1}-\\bar{\\mathcal{O}}\\right)\\right]\n\\]\n\nNo splitting and merging and terms\nIn single operator sector define \\(\\mathcal{C}^a_{0\\cdots \\mu_k=a\\cdots 0}\\equiv C^a_k\\) \\[\n\\partial_t C^a_k = C^a_{k+1} + C^a_{k-1} - 2 C^a_k\\equiv \\Delta_k C^a_k,\n\\] diffusion of single \\(\\sigma^a\\) (\\(\\Delta_k\\) is 1D discrete Laplacian)\n\n\n\n\n\n\\[\n\\partial_t \\mathcal{C}\\_{\\mu_{1:N}} = \\sum_j \\left[J\\epsilon_{\\alpha\\beta \\mu_j \\mu_{j+1}} \\mathcal{C}\\_{\\mu_1\\cdots \\alpha\\beta \\cdots \\mu_N} + \\mathcal{C}\\_{\\mu_1\\cdots \\mu_{j+1}\\mu_j \\cdots \\mu_N} - \\mathcal{C}\\_{\\mu_1\\cdots \\mu_{j}\\mu_{j+1} \\cdots \\mu_N}\\right]\n\\]\n\nFirst term leads to single site operator spreading over many sites\n\n\n\n\n\nQualitative behaviour is known as operator spreading and is a generic feature of operator dynamics\n\n\n\nSpreading suppressed at \\(J=0\\) because we considered average\nIn any sample from our random circuit, single-site operator spreads to many sites\nRandom signs of coeffcients \\(\\mathcal{C}\\_{\\mu_{1:N}}\\) means most average to zero: only the single site contributions remain\nWhen \\(J\\neq 0\\) some contribution survives and this allows for a controlled expansion\nWe’d like a measure that is insensitive to these random signs"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#circuits-as-many-body-dynamics",
    "href": "talks/quantum-circuits-1-icts/index.html#circuits-as-many-body-dynamics",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "austen.uk/slides/quantum-circuits-1-icts for slides"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#outline",
    "href": "talks/quantum-circuits-1-icts/index.html#outline",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "This lecture\n\nWhat is a quantum circuit?\nWhat are the quantities of interest?\n\nNext lecture\n\nSome special kinds of circuits"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#what-is-a-quantum-circuit",
    "href": "talks/quantum-circuits-1-icts/index.html#what-is-a-quantum-circuit",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "A way to describe operations on quantum state, usually consisting of several qubits (spin 1/2 subsystems with Hilbert space \\(\\mathbb{C}^2\\))\nTwo quantum states \\(\\ket{0}\\) and \\(\\ket{1}\\) define the computational basis.\n\n\n\n\n\n\\(f\\) acts on top five qubits, then \\(g\\) acts on lower seven"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#possible-operations",
    "href": "talks/quantum-circuits-1-icts/index.html#possible-operations",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Source: Wikipedia\n\n\n\n\\(H\\) (a Hadamard gate) is a single qubit unitary\nAlso two qubit unitary gates (CNOT here)\nMeasurements"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#why-consider-circuits",
    "href": "talks/quantum-circuits-1-icts/index.html#why-consider-circuits",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "For this program: example of discrete time, many body dynamics\nModel of universal quantum computation\n\nHow to generate an arbitrary quantum state\nOne of several options e.g. measurement-based\n\nThey exist! Companies (Google, IBM, etc.) have built platforms for gate-based QC"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#unitary-circuits",
    "href": "talks/quantum-circuits-1-icts/index.html#unitary-circuits",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "(Mostly) concerned with unitary circuits made from unitary gates\nGate is \\(n\\)-qubit unitary \\(U_{s_1\\ldots s_n,s'_1,\\ldots, s'_n}\\)\n\n$$ \\sum_{s_1'\\ldots s_N'}U_{s_1\\ldots s_n,s'_1,\\ldots, s'_n} U^\\dagger_{s'_1\\ldots s'_n,s''_1,\\ldots, s''_n}=\\delta_{s_1,s_1''}\\ldots \\delta_{s_N,s_N''} $$"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#everything-is-a-tensor",
    "href": "talks/quantum-circuits-1-icts/index.html#everything-is-a-tensor",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "State of \\(N\\) qubits expressed in product basis\n\n$$ \\ket{\\Psi} = \\sum_{s_{1:N}\\in \\{0,1\\}^N} \\Psi_{s_1\\ldots s_N}\\ket{s_1}_1\\ket{s_2}_2\\cdots \\ket{s_N}_N $$\n\nWrite $\\ket{s_1}_1\\ket{s_2}_2\\cdots \\ket{s_N}_N =\\ket{s_1\\cdots s_N}=\\ket{s_{1:N}}$ for brevity\nOperator on \\(N\\) qubits has matrix elements\n\n$$ \\mathcal{O}_{s_{1:N},s'_{1:N}} = \\bra{s_{1:N}}\\mathcal{O}\\ket{s'_{1:N}} $$"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#graphical-notation",
    "href": "talks/quantum-circuits-1-icts/index.html#graphical-notation",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "A tensor is denoted by a blob with one leg for each index\nConnecting legs denotes contraction: summing over a shared index\n\n\n\n\nSee Glen Evenbly’s tensor contraction tutorial"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#unitary-gates-one-qubit",
    "href": "talks/quantum-circuits-1-icts/index.html#unitary-gates-one-qubit",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Multiplication by a Pauli matrix: \\(X\\), \\(Y\\), or \\(Z\\).\nGeneral case \\(U = a_0\\mathbb{1} + \\mathbf{a}\\cdot(X,Y,Z)\\) with \\(|a_0|^2+|\\mathbf{a}|^2=1\\)\nOther special cases used in quantum information e.g. Hadamard gate\n\n\\[\nH = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}\n1 & 1 \\\\\\\\\n1 & -1\n\\end{pmatrix}\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#two-qubits",
    "href": "talks/quantum-circuits-1-icts/index.html#two-qubits",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Work in basis \\(\\ket{00}\\), \\(\\ket{01}\\), \\(\\ket{10}\\), \\(\\ket{11}\\)\nSimplest example is SWAP gate\n\n\\[\n\\operatorname{SWAP}=\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\\\n0 & 0 & 1 & 0 \\\\\\\n0 & 1 & 0 & 0 \\\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n\\].\n\\[\n\\operatorname{SWAP}\\ket{10} = \\ket{01}\n\\]\n\nSWAP takes product states to product states\n\n\n\nSlightly more complicated: square root of SWAP\n\n\\[\n\\sqrt{\\operatorname{SWAP}}=\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\\\n0 & \\frac{1}{2}(1+i) & \\frac{1}{2}(1-i) & 0 \\\\\\\n0 & \\frac{1}{2}(1-i) & \\frac{1}{2}(1+i) & 0 \\\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n\\]\n\nThis generates entanglement: takes product state to non-product state\n\n\\[\n\\sqrt{\\operatorname{SWAP}}\\ket{10} = \\frac{1}{2}\\left[(1+i)\\ket{10}+(1-i)\\ket{01}\\right]\n\\]\n\n\\(\\sqrt{\\operatorname{SWAP}}\\) conserves number of 1s and 0s\n\\(\\sqrt{\\operatorname{SWAP}}\\) together with arbitrary single qubit unitary operators form universal gate set that allows for universal quantum computation"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#general-two-qubit-unitary",
    "href": "talks/quantum-circuits-1-icts/index.html#general-two-qubit-unitary",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Any two-qubit unitary \\(U\\in \\mathcal{U(4)}\\) can be written\n\n\\[\nU = e^{i \\phi} (u_+ \\otimes u_-) V[J_x, J_y, J_z] (v_- \\otimes v_+)\n\\]\n\n\\(u_{\\pm}, v_{\\pm} \\in SU(2)\\)\n\n\\[\n\\begin{align*}\nV[J_x, J_y, J_z] &= \\exp \\left[-i\\left(J_x \\sigma^x \\otimes \\sigma^x + J_y \\sigma^y \\otimes \\sigma^y+ J_z \\sigma^z \\otimes \\sigma^z\\right)\\right]\\\\\\\\\n&= \\begin{bmatrix}\ne^{-i J_z} \\cos(J_-) & 0 & 0 & -i e^{-i J_z \\sin(J_-)} \\\\\\\\\n0 & e^{iJ_z} \\cos(J_+) & -ie^{i J_z} \\sin(J_+) & 0 \\\\\\\\\n0 & -ie^{i J_z} \\sin(J_+) & e^{iJ_z} \\cos(J_+) & 0 \\\\\\\\\n-i e^{-i J_z \\sin(J_-)} & 0 & 0 & e^{-i J_z} \\cos(J_-) \\\\\\\\\n\\end{bmatrix}\n\\end{align*}\n\\]\n\n16 parameters!"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#time-evolution",
    "href": "talks/quantum-circuits-1-icts/index.html#time-evolution",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Time evolution operator \\(U=\\exp(-iHt)\\)\nIf \\(H=\\sum_j h_j\\) a sum of single qubit terms\n\n\\[\n\\mathcal{U} = \\exp(-iHt) = \\prod_j \\exp(-ih_j) = \\prod_j U_j\n\\] \\[\nU_j=\\mathbb{1}\\otimes \\ldots \\otimes\\mathbb{1} \\otimes \\overbrace{u_j}^{j\\text{th factor}} \\ldots \\otimes\\mathbb{1}\n\\]\n\n\n\n\n\nSimplest example of two qubit interaction is exchange Hamiltonian\n\n\\[\n\\begin{align*}\nh_{12} &= J\\left[X\\otimes X+Y\\otimes Y+Z\\otimes Z\\right] =J\\left[X_1X_2+Y_1Y_2 + Z_1Z_2\\right]\\\\\\\n&=2\\operatorname{SWAP} - 1\n\\end{align*}\n\\] \\[\nU(J) = \\exp(-ih_{12}) = e^{iJ}\\left[\\cos (2J) \\mathbb{1} - i\\sin (2J) \\operatorname{SWAP}\\right]\n\\]\n\nSpecial cases\n\n\\[\nU(\\pi/4)=\\operatorname{SWAP}\n\\] \\[\nU(\\pi/8)=\\sqrt{\\operatorname{SWAP}}\n\\]\n\nFully rotationally invariant\n\n\n\n\\(H=\\sum_{i,j} h_{i,j}\\) a sum of two qubit terms with \\([h_{i,j},h_{j,k}]\\neq 0\\)\n\n\n\n\nSource: Glen Evenbly\n\n\n\n\\(\\mathcal{U}\\neq \\prod_{i,j} \\exp(-ih_{i,j})\\). More complicated!\nSuzuki–Trotter expansion: decompose \\(H=H_A + H_B\\)\n\n\\[\n\\mathcal{U} = \\exp(-iH) = \\left[\\exp\\left(-\\frac{iH}{n}\\right)\\right]^n \\sim \\left[e^{-iH_A/n} e^{-iH_B/n}\\right]^n\n\\]\n\n\\[\nH = \\sum_j h_{j,j+1}\n\\] \\[\nH_A = \\sum_j h_{2j, 2j+1}\\qquad H_B = \\sum_j h_{2j-1, 2j}\n\\] \\[\ne^{-iH_A/n}=\\prod_j U_{2j,2j+1}\\qquad e^{-iH_B/n} = \\prod_j U_{2j-1,2j}\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#floquet-theory-kicked-ising-model",
    "href": "talks/quantum-circuits-1-icts/index.html#floquet-theory-kicked-ising-model",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Time dependent Hamiltonian with kicks at \\(t=0,1,2,\\ldots\\).\n\n\\[\n\\begin{align*}\nH_{\\text{KIM}}(t) = H_\\text{I}[\\mathbf{h}] + \\sum_{n}\\delta(t-n)H_\\text{K}\\\\\\\nH_\\text{I}[\\mathbf{h}]=\\sum_{j=1}^L\\left[J Z_j Z_{j+1} + h_j Z_j\\right],\\qquad H_\\text{K} &= b\\sum_{j=1}^L X_j,\n\\end{align*}\n\\]\n\n“Stroboscopic” form of \\(\\mathcal{U}(t)=\\mathcal{T}\\exp\\left[-i\\int^t H_{\\text{KIM}}(t') dt'\\right]\\)\n\n\\[\n\\begin{aligned}\n  \\mathcal{U}(n_+) &= \\left[\\mathcal{U}(1_+)\\right]^n,\\qquad U(1_-) = K I_\\mathbf{h}\\\\\\\n  I_\\mathbf{h} &= e^{-iH_\\text{I}[\\mathbf{h}]}, \\qquad K = e^{-iH_\\text{K}}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#kim-as-a-circuit",
    "href": "talks/quantum-circuits-1-icts/index.html#kim-as-a-circuit",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "\\[\n\\begin{aligned}\n  \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\\\\n  \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#locality",
    "href": "talks/quantum-circuits-1-icts/index.html#locality",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Locality a feature of real quantum computing architectures\n\n\n \n\n(top) a schematic view of the Google Sycamore processor and (bottom) the real thing"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#computational-complexity",
    "href": "talks/quantum-circuits-1-icts/index.html#computational-complexity",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "State is vector in \\(2^N\\) dimensional space\nUpdating involves acting with a unitary matrix\nNaive matrix-vector multiplication \\(O(\\operatorname{dim}^2)=2^{2N}\\)\nSince gates gives sparse matrices update is \\(O(\\operatorname{dim})=2^{N}\\)\nStill exponentially hard in the number of qubits"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#quantum-supremacy",
    "href": "talks/quantum-circuits-1-icts/index.html#quantum-supremacy",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Difficulty on classical computer basis of “quantum supremacy” based on circuit sampling\nMeasure empirical distribution of bit strings with fixed initial state\nTotal number of (time) steps \\(T\\) taken is depth of the circuit. For low depth \\(T&lt;N\\) it pays to move horizontally instead\nProblem of finding optimal contraction strategy in general is NP-hard\nGoogle’s initial claim of supremacy disputed by supercomputer optimizations, followed by improved tensor network methods: Huang et al. (2020), Gray and Kourtis (2021), Pan and Zhang (2021), Napp et al. (2022)"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#expectation-values",
    "href": "talks/quantum-circuits-1-icts/index.html#expectation-values",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Evaluate \\(\\bra{\\Psi}\\mathcal{O}\\ket{\\Psi}=\\bra{\\Psi_0}\\mathcal{U}^\\dagger\\mathcal{O}\\mathcal{U}\\ket{\\Psi_0}\\) for local operator \\(\\mathcal{O}\\)\n\nSimplest example: \\(X\\), \\(Y\\), or \\(Z\\) for one qubit\n\\(\\mathcal{U}\\) is overall unitary operator describing whole circuit"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#unitarity-in-graphical-notation",
    "href": "talks/quantum-circuits-1-icts/index.html#unitarity-in-graphical-notation",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Have to consider both unitaries and conjugates\nIntroduce color-coded notation\n\n\n\n\n\n\nCondition of unitarity \\(U^\\dagger U = U U^\\dagger = \\mathsf{1}\\)\n\n\\[\n\\sum\\_{\\alpha,\\beta}U^{\\vphantom{\\dagger}}_{a,b,\\alpha,\\beta} U^\\dagger\\_{\\alpha,\\beta,c,d}=\\delta\\_{ac}\\delta\\_{bd}\n\\]\n\nUnitarity of two qubit gate expressed as\n\n\n\n\n\nMuch better!"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#using-unitarity",
    "href": "talks/quantum-circuits-1-icts/index.html#using-unitarity",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "\\(\\bra{\\Psi}\\mathcal{O}\\ket{\\Psi}=\\bra{\\Psi_0}\\mathcal{U}^\\dagger\\mathcal{O}\\mathcal{U}\\ket{\\Psi_0}\\) has diagrammatic representation\n\n\n\n\n(leave initial state \\(\\ket{\\Psi}\\) unspecified for the moment)"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#folded-representations",
    "href": "talks/quantum-circuits-1-icts/index.html#folded-representations",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Since every \\(U\\) accompanied by \\(U^\\dagger\\), include both in single unit by “folding” one on top of the other\n\n\n\n\n\nLines correspond to two indices, and therefore \\(2^2=4\\) dimensions\nUnitarity condition takes form:\n\n\n\n\n\n\nIn folded picture expectation value \\(\\bra{\\Psi}\\mathcal{O}\\ket{\\Psi}\\) looks like this\n\n\n\n\n\nClick to apply unitary condition!\n\n\n\n“Light cone” emerges, reflecting region of circuit that affects expectation value"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#reduced-density-matrix",
    "href": "talks/quantum-circuits-1-icts/index.html#reduced-density-matrix",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Expectation value of operator in region \\(A\\) can be computed from reduced density matrix \\(\\rho_A\\) for region \\(A\\) \\[\n\\rho_A = \\operatorname{tr}\\_{B}\\left[\\ket{\\Psi}\\bra{\\Psi}\\right]=\\operatorname{tr}_{B}\\left[\\mathcal{U}\\ket{\\Psi_0}\\bra{\\Psi_0}\\mathcal{U}^\\dagger\\right]\n\\] (\\(B\\) is complement of \\(A\\))\n\n\n\n\n\nInitial RDM of bottom part of wedge is all that matters!"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#quantifying-entanglement",
    "href": "talks/quantum-circuits-1-icts/index.html#quantifying-entanglement",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "RDM quantifies entanglement present in a quantum state describing a system composed of two subsystems A and B\nGeneral state is vector \\(\\in\\mathcal{H}=\\mathcal{H}\\_A\\otimes\\mathcal{H}\\_B\\)\nWrite in terms of basis vectors \\(\\ket{a}\\_A\\) and \\(\\ket{b}\\_B\\) for A and B subsystems \\[\n\\ket{\\Psi}\\_{AB} = \\sum\\_{a=1}^{n\\_A}\\sum\\_{b=1}^{n\\_B} \\Psi\\_{ab}\\ket{a}\\_A\\ket{b}\\_B\n\\] \\(n\\_{A/B}=\\operatorname{dim} \\mathcal{H}\\_{A/B}\\)\nNow regard \\(\\psi_{ab}\\) as matrix and perform a singular value decomposition\n\n\n\nIn new bases our state is\n\n\\[\n\\ket{\\Psi}\\_{AB} = \\sum\\_{n=1}^{\\min(n_A, n_B)} \\sigma\\_n \\ket{u\\_n}\\_A\\otimes\\ket{v\\_n}\\_B\n\\]\n\nNote single sum, c.f. double sum earlier. This is Schmidt decomposition\n\\(\\sigma_n\\) are Schmidt coefficients (singular values of SVD)\nIf only one nonzero singular value state we have product state, indicating no correlations between subsystems\n\n\n\nSimplest example displaying nontrivial entanglement is Bell state\n\n\\[\n\\left|\\Psi^{+}\\right\\rangle=\\frac{1}{\\sqrt{2}}\\left(|0\\rangle_A \\otimes|1\\rangle_B+|1\\rangle_A \\otimes|0\\rangle_B\\right)\n\\]\n\nSchmidt coefficients both \\(\\frac{1}{\\sqrt{2}}\\), indicating maximal entanglement\nSchmidt decomposition closely related to RDM \\[\n\\rho_A = \\operatorname{tr}\\_B\\left[\\ket{\\Psi}\\bra{\\Psi}\\right]\n= \\sum\\_n \\sigma_n^2 \\ket{u\\_n}\\bra{u\\_n}\n\\]\nEigenvalues of RDM are \\(p_n=\\sigma_n^2\\)\n\n\n\nOne measure of entanglement is von Neumann entropy of \\(\\rho_A\\) (aka entanglement entropy)\n\n\\[\nS^{(\\text{vN})}_A \\equiv -\\operatorname{tr}\\left[\\rho_A\\log \\rho_A\\right]\n\\]\n\n\\(S_A\\) vanishes for product state, and is otherwise positive\n\n\n\nRényi entropies provide more complete information \\[\nS^{(\\alpha)}\\_A = \\frac{1}{1-\\alpha}\\log \\text{tr}\\left[\\rho^n\\right]=\\frac{1}{1-\\alpha}\\sum\\_n p\\_n^\\alpha\n\\] \\(S^{(\\text{vN})}\\_A=\\lim\\_{\\alpha\\to 1} S^{(\\alpha)}\\_A\\). \\(S^{(0)}\\_A\\) is number of nonzero Schmidt coefficients (aka Schmidt rank) \\[\nS^{(2)}\\_A = -\\log \\sum_n p_n^2 = -\\log \\gamma\\tr \\rho_A^2\n\\] where \\(\\gamma\\equiv \\tr \\rho_A^2\\) is purity"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#toy-model",
    "href": "talks/quantum-circuits-1-icts/index.html#toy-model",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Circuit of SWAP gates\n\n\n\nInitial state is product of Bell states \\[\n\\ket{\\Phi^+}\\_{2n, 2n+1} = \\frac{1}{\\sqrt{2}}\\left[\\ket{0}\\_{2n}\\ket{0}\\_{2n+1}+ \\ket{1}\\_{2n}\\ket{1}\\_{2n+1}\\right]\n\\] \\[\n\\operatorname{tr}\\_{2}\\left[\\ket{\\Phi^+}\\_{12}\\bra{\\Phi^+}\\_{12}\\right] = \\frac{1}{2}\\mathbb{1}_1\n\\] with entanglement entropy of one bit\n\n\n\n\\(\\rho_A\\) therefore has factor \\(\\mathbb{1}_n\\) for each site \\(n\\in A\\) with “partner” in \\(B\\)\nIf both qubits of a Bell pair are at sites \\(n,m\\in A\\) they give a factor \\(\\ket{\\Phi^+}\\_{nm}\\bra{\\Phi^+}\\_{nm}\\): a pure state\nEntanglement entropy has contributions from first case only\n\n\\[\nS_A = \\min(4\\lfloor t/2\\rfloor, |A|) \\text{ bits}\n\\]\n\n\\[\nS_A = \\min(4\\lfloor t/2\\rfloor, |A|) \\text{ bits}\n\\]\n\nAfter time \\(\\sim |A|/2\\) subsystem has thermalized.\n\n\n\n\nSource: Bertini et al. (2019)\n\n\n\n\nRamp behaviour in many systems\nIn noninteracting systems or integrable systems, often explained in terms of the causal propagation of (quasi-)particles:\n\n\n\n\nSource: Calabrese and Cardy (2005)\n\n\n\n\nToy model with SWAP gates is rather similar, with qubits playing the role of “noninteracting particles”\nThis picture remains true in circuits where there is no quasiparticle interpretation (next lecture)"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#correlation-functions",
    "href": "talks/quantum-circuits-1-icts/index.html#correlation-functions",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Natural correlation function to consider is\n\n\\[\nc_{\\alpha \\beta}(x,t) = \\frac{1}{2^N}\\tr\\left[\\sigma_{\\alpha}(x,t) \\sigma_{\\beta}(0,0) \\right],\\qquad \\sigma_\\alpha(x,t)=\\mathcal{U}^\\dagger(t)\\sigma_\\alpha(x)\\mathcal{U}(t)\n\\]\n\nAverage overall all initial states uniformly\nThis is “infinite temperature”, although temperature is not defined"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#graphical-representation",
    "href": "talks/quantum-circuits-1-icts/index.html#graphical-representation",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "\\[\nc_{\\alpha \\beta}(x,t) = \\frac{1}{2^N}\\tr\\left[\\sigma_{\\alpha}(x,t) \\sigma_{\\beta}(0,0) \\right],\\qquad \\sigma_\\alpha(x,t)=\\mathcal{U}^\\dagger(t)\\sigma_\\alpha(x)\\mathcal{U}(t)\n\\]\n\n\n\n\n\nWhen \\(|x|&gt;t\\) unitarity condition leads to removal of all \\(U\\)s and \\(U^\\dagger\\)s \\[\nc_{\\alpha \\beta}(x,t) = \\frac{1}{4}\\tr\\left[\\sigma_{\\alpha}\\right]\\tr\\left[\\sigma_{\\beta}\\right]=0,\n\\] and correlations vanish (if operators are traceless)\nCorrelations only nonzero inside “light cone”\n\n\n\nWhen \\(|x|=t\\) remaining tensor network is particularly simple:\n\n\n\n\n\n\nRewrite in several ways, including in folded representation:\n\n\n\n\n\n\\(q\\) is local Hilbert space dimension (\\(q=2\\) up to now)\nNormalization factor by comparing with \\(\\sigma_\\alpha=\\sigma_\\beta=\\mathsf{1}\\) (here \\(t=4\\))\n\n\n\nEvaluate by iteratively applying operator map \\(\\mathcal{M}\\_+\\) or \\(\\mathcal{M}\\_-\\)\n\n\n \n\n\\[\n\\begin{align*}\n\\langle \\sigma\\_{\\alpha}(t,t) \\sigma\\_{\\beta}(0,0) \\rangle &= \\tr \\left[\\sigma\\_{\\beta}\\mathcal{M}\\_{-}^t(\\sigma\\_{\\alpha})\\right] / q \\\\\\\n&=  \\tr \\left[ \\sigma\\_{\\alpha}\\mathcal{M}\\_{+}^{t}(\\sigma\\_{\\beta})\\right] / q\n\\end{align*}\n\\]\n\n\\(\\mathcal{M}\\_\\pm\\) are examples of quantum channels: completely positive trace preserving maps between spaces of operators\n\\(\\mathcal{M}\\_\\pm\\) have the additional property of being unital: \\(\\mathcal{M}\\_\\pm(\\mathsf{1})=\\mathsf{1}\\)"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#typical-behaviour-of-correlations",
    "href": "talks/quantum-circuits-1-icts/index.html#typical-behaviour-of-correlations",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Source: Claeys and Lamacraft (2020)\n\n\n\n\nCan evaluate correlation inside light cone\n\n\n\n\n\n“One step inside” involves quantum channel acting on two-site operators: a space of dimension \\(q^4\\).\nTaking \\(s\\) steps inside channel acting on \\(q^{2s}\\)-dimensional space\nGeneral situation is really exponentially hard, as we’d expect"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#operator-spreading",
    "href": "talks/quantum-circuits-1-icts/index.html#operator-spreading",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "How does a local operator “look” as it evolves in Heisenberg picture?\n\\(Z_n(t)=\\mathcal{U}^\\dagger(t)Z_n \\mathcal{U}(t)\\) appears in \\(\\langle Z_n(t)Z_m(0) \\rangle\\), but this is only one “component” of \\(Z_n(t)\\)\nAny observable such as \\(Z_n(t)\\) can be expressed as expansion \\[\nZ_n(t)= \\sum_{\\mu_{1:N}=\\\\{1,x,y,z\\\\}^N} \\mathcal{C}\\_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots \\sigma_N^{\\mu_N}\n\\] \\[\n\\mathcal{C}\\_{\\mu_{1:N}}(0)=\\begin{cases}\n1 & \\mu_j=z, \\mu_k=1,\\forall k\\neq j \\\\\\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\n\n\n\\[\nZ_n(t)= \\sum_{\\mu_{1:N}=\\\\{1,x,y,z\\\\}^N} \\mathcal{C}\\_{\\mu_{1:N}}(t) \\sigma_1^{\\mu_1}\\otimes\\cdots \\sigma_N^{\\mu_N}\n\\]\n\nSince \\(\\tr\\left[\\sigma_\\alpha\\sigma_\\beta\\right]=2\\delta_{\\alpha\\beta}\\), can extract spin correlations from \\(\\langle Z_j(t)Z_k(0)\\rangle=C_{jk}(t) \\equiv \\mathcal{C}_{1\\cdots \\mu_k=z \\cdots 1}(t)\\)\n\n\n\n\n\nThis represents only one component of operator expansion\n\n\n\nOperator norm \\(\\tr\\left[Z\\_n^2(t)\\right]=2\\) is conserved under time evolution\nThis implies the normalization\n\n\\[\n\\sum_{\\mu_{1:N}=\\\\{1,x,y,z\\\\}^N} \\mathcal{C}^2\\_{\\mu_{1:N}}(t) = \\frac{1}{2^{N-1}}.\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#example-su2-preserving-gate",
    "href": "talks/quantum-circuits-1-icts/index.html#example-su2-preserving-gate",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Consider gate generated by exchange Hamiltonian: \\[\nU\\_{j,j+1} = \\cos\\theta \\mathbb{1}\\_{j,j+1} + i\\sin\\theta \\operatorname{\\mathsf{S}}\\_{j.j+1}\n\\] \\(\\operatorname{\\mathsf{S}}_{j,j+1}\\) denotes \\(\\operatorname{\\mathsf{SWAP}}\\) gate on sites \\(j\\) and \\(j+1\\)\nAction of this gate on an operator is\n\n\\[\n\\mathcal{O} \\longrightarrow U^\\dagger\\_{j,j+1}\\mathcal{O}U\\_{j,j+1} = \\cos^2\\theta \\mathcal{O} + \\sin^2\\theta \\operatorname{\\mathsf{S}}\\_{j.j+1}\\mathcal{O} \\operatorname{\\mathsf{S}}\\_{j.j+1} \\\\\\\n-i\\sin\\theta\\cos\\theta \\left[\\operatorname{\\mathsf{S}}\\_{j.j+1}, \\mathcal{O}\\right]\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#ensemble-of-circuits",
    "href": "talks/quantum-circuits-1-icts/index.html#ensemble-of-circuits",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "Consider ensemble averaged quantities\nTake \\(\\theta=\\pm \\theta_0\\) with \\(p(\\theta_0)-p(-\\theta_0)\\equiv \\delta &gt; 0\\).\nAveraging the evolved operator gives\n\n\\[\n\\overline{U^\\dagger_{j,j+1}\\mathcal{O}U_{j,j+1}} = \\cos^2\\theta_0 \\\\, \\mathcal{O} + \\sin^2\\theta_0 \\\\, \\mathsf{S}\\_{j.j+1}\\mathcal{O} \\mathsf{S}\\_{j.j+1} \\\\\\\\\n+i\\delta \\sin\\theta_0\\cos\\theta_0 \\left[\\mathsf{S}\\_{j.j+1}, \\mathcal{O}\\right]\n\\]\n\nInterpretation\n\nOperators on sites \\(j\\) and \\(j+1\\) switch with probability \\(\\sin^2\\theta_0\\).\nThe asymmetry \\(\\delta\\) governs strength of “quantum” dynamics\n\n\n\n\nContinuous time limit (Claeys, Lamacraft & Herzog-Arbeitman (2022) \\[\n\\frac{d\\bar{\\mathcal{O}}}{dt} = \\sum_j \\left[iJ \\left[\\mathsf{S}\\_{j,j+1},\\bar{\\mathcal{O}}\\right]+\\left(\\mathsf{S}\\_{j,j+1}\\bar{\\mathcal{O}}\\mathsf{S}\\_{j,j+1}-\\bar{\\mathcal{O}}\\right)\\right]\n\\] where \\(J\\propto \\delta\\). Computing commutator:\n\n\\[\n\\begin{align*}\ni[\\mathsf{S},\\sigma^a\\otimes 1]&=-\\epsilon^{abc}\\sigma^b\\otimes\\sigma^c\\nonumber\\\\\\\\\ni[\\mathsf{S},1\\otimes \\sigma^a]&=\\epsilon^{abc}\\sigma^b\\otimes\\sigma^c\\nonumber\\\\\\\\\ni[\\mathsf{S},\\sigma^a\\otimes \\sigma^b]&=\\epsilon^{abc}\\left(\\sigma^c\\otimes 1- 1\\otimes \\sigma^c\\right).\n\\end{align*}\n\\]\n\nDescribes operator “splitting” (\\(1\\to 2\\)) and “merging” (\\(2\\to 1\\))"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#j0-limit",
    "href": "talks/quantum-circuits-1-icts/index.html#j0-limit",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "\\[\n\\frac{d\\bar{\\mathcal{O}}}{dt} = \\sum_j \\left[iJ \\left[\\mathsf{S}\\_{j,j+1},\\bar{\\mathcal{O}}\\right]+\\left(\\mathsf{S}_{j,j+1}\\bar{\\mathcal{O}}\\mathsf{S}\\_{j,j+1}-\\bar{\\mathcal{O}}\\right)\\right]\n\\]\n\nNo splitting and merging and terms\nIn single operator sector define \\(\\mathcal{C}^a_{0\\cdots \\mu_k=a\\cdots 0}\\equiv C^a_k\\) \\[\n\\partial_t C^a_k = C^a_{k+1} + C^a_{k-1} - 2 C^a_k\\equiv \\Delta_k C^a_k,\n\\] diffusion of single \\(\\sigma^a\\) (\\(\\Delta_k\\) is 1D discrete Laplacian)"
  },
  {
    "objectID": "talks/quantum-circuits-1-icts/index.html#jneq-0",
    "href": "talks/quantum-circuits-1-icts/index.html#jneq-0",
    "title": "Quantum Circuits I",
    "section": "",
    "text": "\\[\n\\partial_t \\mathcal{C}\\_{\\mu_{1:N}} = \\sum_j \\left[J\\epsilon_{\\alpha\\beta \\mu_j \\mu_{j+1}} \\mathcal{C}\\_{\\mu_1\\cdots \\alpha\\beta \\cdots \\mu_N} + \\mathcal{C}\\_{\\mu_1\\cdots \\mu_{j+1}\\mu_j \\cdots \\mu_N} - \\mathcal{C}\\_{\\mu_1\\cdots \\mu_{j}\\mu_{j+1} \\cdots \\mu_N}\\right]\n\\]\n\nFirst term leads to single site operator spreading over many sites\n\n\n\n\n\nQualitative behaviour is known as operator spreading and is a generic feature of operator dynamics\n\n\n\nSpreading suppressed at \\(J=0\\) because we considered average\nIn any sample from our random circuit, single-site operator spreads to many sites\nRandom signs of coeffcients \\(\\mathcal{C}\\_{\\mu_{1:N}}\\) means most average to zero: only the single site contributions remain\nWhen \\(J\\neq 0\\) some contribution survives and this allows for a controlled expansion\nWe’d like a measure that is insensitive to these random signs"
  },
  {
    "objectID": "talks/space-time-dual-cat-and-clock-models/index.html#outline",
    "href": "talks/space-time-dual-cat-and-clock-models/index.html#outline",
    "title": "Space-time dual cat models",
    "section": "Outline",
    "text": "Outline\n\nReview of space-time\nHadamards\nZX calculus\nRecent WW Ho paper on hexagonal lattice. Generalized dual unitarity. Three arrows of time and three light cones\nTriunitarity Jonay, Khemani, Ippoliti\nCauchy surfaces and Lorentz symmetry (review of earlier works)\nCliffords and cats\nAutomata"
  },
  {
    "objectID": "talks/space-time-dual-cat-and-clock-models/index.html#space-time-dual-cat-and-clock-maps",
    "href": "talks/space-time-dual-cat-and-clock-models/index.html#space-time-dual-cat-and-clock-maps",
    "title": "Space-time dual cat models",
    "section": "Space-time dual cat and clock maps",
    "text": "Space-time dual cat and clock maps\nAusten Lamacraft (Cambridge) and Pieter Claeys (Dresden)\nausten.uk/#talks for slides"
  },
  {
    "objectID": "talks/space-time-dual-cat-and-clock-models/index.html#outline-1",
    "href": "talks/space-time-dual-cat-and-clock-models/index.html#outline-1",
    "title": "Space-time dual cat models",
    "section": "Outline",
    "text": "Outline\n\nGeneralizing SDKI with Hadamard gates\nCat maps and Clifford gates; classical limit\nSpace-time duality for CA\nModels with continuous state space"
  },
  {
    "objectID": "talks/space-time-dual-cat-and-clock-models/index.html#zx-calculus",
    "href": "talks/space-time-dual-cat-and-clock-models/index.html#zx-calculus",
    "title": "Space-time dual cat models",
    "section": "ZX Calculus",
    "text": "ZX Calculus\n\nProvides alternative view on dual unitarity\nLinks to reviews, also books.\nvan der Wetering (2020)"
  },
  {
    "objectID": "talks/space-time-dual-cat-and-clock-models/index.html#cat-map",
    "href": "talks/space-time-dual-cat-and-clock-models/index.html#cat-map",
    "title": "Space-time dual cat models",
    "section": "Cat map",
    "text": "Cat map\n\nimport { catMap } from \"./js/cat.js\";\n// createSketch(catMap, 'cat-map');"
  },
  {
    "objectID": "talks/space-time-dual-cat-and-clock-models/index.html#three-dimensions",
    "href": "talks/space-time-dual-cat-and-clock-models/index.html#three-dimensions",
    "title": "Space-time dual cat models",
    "section": "Three dimensions",
    "text": "Three dimensions\n\nimport { threeDCat } from \"./js/3d-cat.js\";\ncreateSketch(threeDCat, 'three-dimensions');"
  },
  {
    "objectID": "talks/space-time-dual-cat-and-clock-models/index.html#dual-unitarity-for-classical-models",
    "href": "talks/space-time-dual-cat-and-clock-models/index.html#dual-unitarity-for-classical-models",
    "title": "Space-time dual cat models",
    "section": "Dual unitarity for classical models?",
    "text": "Dual unitarity for classical models?"
  },
  {
    "objectID": "talks/space-time-dual-cat-and-clock-models/index.html#elementary-ca",
    "href": "talks/space-time-dual-cat-and-clock-models/index.html#elementary-ca",
    "title": "Space-time dual cat models",
    "section": "Elementary CA",
    "text": "Elementary CA\n\nMany behaviours, from ordered (Rule 18) to chaotic (Rule 30)\n\n\nviewof rule = Inputs.range([0, 255], {step: 1, label: \"Rule\"})\nviewof initialCondition = Inputs.select([\"single 1\", \"random\"], {label: \"Initial\"})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport { elementary } from \"./js/elementary-ca.js\";\ncreateSketch(elementary(rule, initialCondition), 'elementary-ca');\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRule 110 is capable of universal computation!"
  },
  {
    "objectID": "talks/space-time-dual-cat-and-clock-models/index.html#reversible-models",
    "href": "talks/space-time-dual-cat-and-clock-models/index.html#reversible-models",
    "title": "Space-time dual cat models",
    "section": "24 reversible models",
    "text": "24 reversible models\n\nEach block a permutation of 00, 01, 10, 11\n4!=24 blocks\nOrder:\n\n\n\n\n\n\n\n(0213), and so on\n\nBlock 2 is the map (00, 01, 10, 11) ⟶ (00, 10, 01, 11) (SWAP)"
  },
  {
    "objectID": "talks/space-time-dual-cat-and-clock-models/index.html#symplectic-dynamics",
    "href": "talks/space-time-dual-cat-and-clock-models/index.html#symplectic-dynamics",
    "title": "Space-time dual cat models",
    "section": "Symplectic dynamics",
    "text": "Symplectic dynamics\n\nState space \\Sigma is symplectic manifold with symplectic form \\omega\nf:\\Sigma\\times\\Sigma\\longrightarrow\\Sigma\\times\\Sigma obeys f^{*}(\\omega_1+\\omega_2)=\\omega_1+\\omega_2\n\\omega has (locally) canonical form\n\n\n\\omega = \\sum_{i=1}^{n} dx_i\\wedge dy_i\n\n\nDf is symplectic matrix\n\n\n\\begin{align*}\nDf^T \\Omega Df &= \\Omega\\qquad \\Omega \\equiv\\operatorname{diag}(\\omega,\\omega)\\\\\n\\omega &= \\begin{pmatrix}\n    0 & \\mathbb{1}_n \\\\\n    -\\mathbb{1}_n & 0\n    \\end{pmatrix}\n\\end{align*}"
  },
  {
    "objectID": "talks/ml-stat-mech-1/index.html",
    "href": "talks/ml-stat-mech-1/index.html",
    "title": "Machine Learning and Statistical Mechanics",
    "section": "",
    "text": "\\[\n\\DeclareMathOperator*{\\E}{\\mathbb{E}}\n\\newcommand{\\cE}{\\mathcal{E}}\n\\]"
  },
  {
    "objectID": "talks/ml-stat-mech-1/index.html#some-mathematical-background",
    "href": "talks/ml-stat-mech-1/index.html#some-mathematical-background",
    "title": "Machine Learning and Statistical Mechanics",
    "section": "Some mathematical background",
    "text": "Some mathematical background\n\n\nProbabilities\n\nProbabilities \\(p(x)\\geq 0\\) satisfy\n\n\\[\n\\sum_x p(x)=1\n\\]\n\nFor continuous variables \\[\n\\int p(x) dx=1,\n\\] but we’ll use the discrete notation throughout.\n\n\n\nJoint probabilities denoted \\(p(x_1,\\ldots x_N)\\)\nSum over subset to give marginal distribution of remaining\n\n\\[\np(x)= \\sum_{y} p(x,y).\n\\]\n\nConditional probability \\(p(x|y)\\): distribution of \\(x\\) given fixed \\(y\\). The relation between joint and conditional probabilities is\n\n\\[\np(x,y)=p(x|y)p(y)\n\\tag{1}\n\\label{eq:joint}\n\\]\n\n\n\nChain rule of probability\n\\[\np(x_1,\\ldots x_N)=p(x_1)p(x_2|x_1)p(x_3|x_2,x_1)\\cdots p(x_N|x_1,\\ldots x_{N-1}),\n\\tag{2}\n\\label{eq:chain}\n\\]\n\nc.f. Autoregressive models\nSampling is easy!\n\n\n\n\nPriors and posteriors\n\nAnother way to express the joint probability is\n\n\\[\np(x,y)=p(y|x)p(x)\n\\]\n\nWe deduce Bayes’ theorem\n\n\\[\np(y|x)=\\frac{p(x|y)p(y)}{p(x)}\n\\]\n\n\n\nBayesian statistics\n\nBayes’ theorem is workhorse of Bayesian statistics\nRegard parameters \\(z\\) in your probability model as random variables taken from some initial distribution \\(p(z)\\), called the prior distribution (or just the prior)\n\n\n\n\nExample\n\nModel distribution is Gaussian normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\)\nParameters are \\(z=(\\mu,\\sigma^2)\\)\nFor prior could choose a normal distribution: \\(\\mu\\sim \\mathcal{N}(\\mu_\\mu,\\sigma^2_\\mu))\\)\nFor \\(\\sigma^2\\) a distribution of a positive quantity: the inverse gamma distribution is a popular choice.\n\n\n\nOnce parameters fixed, have a model distribution for your data that can be thought of as the conditional distribution \\(p(x|z)\\)\nWhat does an observation of \\(x\\) tell me? Just use Bayes:\n\n\\[\np(z|x) = \\frac{p(x|z)p(z)}{p(x)}.\n\\]\n\nThis is the posterior distribution (or just posterior)\nNote that the denominator doesn’t depend on \\(z\\), it just provides a normalization. If you have lots of data points then\n\n\\[\np(z|x_1,\\ldots x_N) \\propto  p(x_1,\\ldots x_N|z)p(z).\n\\]\n\n\nBayes’ theorem lets us update our beliefs about parameters based on our initial beliefs and any evidence we receive. This is inference.\n\n\n{{&lt; tweet 1325474361407660034 &gt;}}\n\n\n\n\nLatent variables; generative models\n\nWe allow the \\(z\\)s to have different distributions for different data points \\(p(z_n|x_n)\\)\nEquivalently, our model is defined by a joint distribution \\(p(x,z)\\).\n\n\n\n\nExample: mixture model\n\n\\(M\\) different components, each with their own distribution \\(p(x|m)\\) and occurring with probability \\(p(m)\\), so that\n\n\\[\np(x) = \\sum_m p(m)p(x|m).\n\\]\n\nObservation \\(x\\) will give me information about \\(p(m|x)\\), telling which of the \\(M\\) components that observation belongs to.\nThis may bring insight, if latent variables are interpretable\nOr: a more powerful model\n\n\n\nLatent variables allow for structure learning\nExample: for a dataset of images of people walking we’d like to find latent variables parameterize a manifold of different poses.\nLatent variable models are also the basis of generative modelling: sampling from a distribution \\(p(x)\\) learnt from data.\nIf the model has been formulated in terms of a prior \\(p(z)\\) over latent variables and a generative model \\(p(x|z)\\), sampling is straightforward in principle.\n\n\n\n\nEntropy\n\nIn SM we’re familiar with entropy associated with probability distribution.\nArrived in ML from information theory\n\n\\[\nH[p]=- \\sum_x p(x)\\log_2 p(x).\n\\]\n\nTaking the logarithm base 2 means we measure in bits\n\n\n\n\n\n\nOne interpretation of entropy\n\n\\(N\\) iid variables with distribution \\(p(x)\\)\nProbability of observing a sequence \\(x_1,\\ldots x_N\\) is\n\n\\[\n\\begin{equation}\np(x_1,\\ldots x_N)=\\prod_{n=1}^N p(x_n).\n\\end{equation}\n\\tag{3}\n\\label{eq:seq}\n\\]\n\nProbability is obviously exponentially small as \\(N\\to\\infty\\), but how small?\n\n\n\\[\n\\lim_{N\\to\\infty} \\frac{1}{N}\\log p(x_1,\\ldots x_N) = -H[p].\n\\]\n\nAsymptotic partition property\nShouldn’t the probability depend on what you actually get?\nSuppose you have a biased coin that give heads with probability \\(p_H&gt;0.5\\) and tails with probability \\(p_T=1-p_H\\)\nChance of getting half heads and half tails exponentially small\n\n\n\nWhat you’re going to get instead is\n\n\\[\n\\frac{N_H}{N}\\to p_H\\qquad \\frac{N_T}{N}\\to p_T\\qquad .\n\\]\n\nWhat is the probability of such a sequence? \\(p_H^{N_H}p_T^{N_T}\\)\n\n\\[\n\\log_2\\left(p_H^{N_H}p_T^{N_T}\\right)= N_H\\log_2 p_H + N_T\\log_2 p_T = -N H[p_H, p_T].\n\\]\n\n\n\nEntropy and information\n\nA way to quantify information in a signal\nIf the coin is really biased, you will be surprised when you get tails\nEntropy lower than for fair coin, which has maximum entropy \\(H=1\\)\n\n\n\nHHHHHHHHHHHHHHHHHHHHHTHHHHHHHHHHHHHTHHHHT\n\n\nTo describe such a sequence, you might say “21 H, 13 H, 4 H”\nShorter than the original sequence; possible because of the high degree of predictability\nBut: extra symbols including the digits 0-9 and comma.\nShould instead compare with a binary code of only two symbols\nHow can we exploit the lower entropy of the sequence?\n\n\n\nUse fact that we expect \\(N_H=Np_H\\) heads and \\(N_T=N p_T\\) tails, so we can just give the ordering of these heads and tails, which is one of \\[\n\\frac{N!}{N_H! N_T!}\n\\] possibilities. If we label each of these with a binary number, we end up with a description of length \\[\n\\log_2\\left(\\frac{N!}{N_H! N_T!}\\right)\\sim N H[p]\\leq N\n\\] (where we used Stirling’s approximation \\(\\log n! \\sim n\\log n -n\\)).\n\n\n\nSimplest illustration of Shannon’s source coding theorem:\n\n\nN i.i.d. random variables each with entropy H(X) can be compressed into more than N H(X) bits with negligible risk of information loss, as N → ∞; but conversely, if they are compressed into fewer than N H(X) bits it is virtually certain that information will be lost.\n\n\nShannon’s theorem is the core idea that underlies (lossless) data compression\nThe more predictable a signal (i.e. the lower the entropy) the more it can be compressed, with the entropy setting a fundamental limit on the number of bits required.\n\n\n\n\nDivergences\n\nWe need some way of talking about the degree to which two distributions differ\nMost common measure in use in ML is the Kullback–Leibler divergence (KL)\n\n\\[\nD_\\text{KL}(p||q)=\\sum_x p(x)\\log\\left(\\frac{p(x)}{q(x)}\\right)=\\E_{x\\sim p}\\log\\left(\\frac{p(x)}{q(x)}\\right).\n\\]\n\n\nKL has property\n\n\\[\nD_\\text{KL}(p||q)\\geq 0\n\\]\n\nConsequence of Jensen’s inequality. For a convex function \\(\\varphi(x)\\)\n\n\\[\n\\E\\left[\\varphi(x))\\right]\\geq \\varphi\\left(\\E\\left[x\\right]\\right)\n\\]\n\nApply this to the KL then, using the convexity of \\(\\varphi(x)=-\\log(x)\\) \\[\nD_\\text{KL}(p||q)=-\\E_{x\\sim p}\\log\\left(\\frac{q(x)}{p(x)}\\right)\\geq -\\log\\left(\\E_{x\\sim p}\\left[\\frac{q(x)}{p(x)}\\right]\\right)=-\\log(1)=0,\n\\] with equality if and only if \\(p=q\\).\n\n\n\n\nVariational inference (VI)\n\nRecall Bayes’\n\n\\[\np(z|x) = \\frac{p(x|z)p(z)}{p(x)}=\\frac{p(x,z)}{p(x)}.\n\\]\n\nComplicated latent variable model \\(\\longrightarrow\\) intractable denominator\n\n\n\n\n\nMean field theory\n\nFor SM model like Ising the probability has the form\n\n\\[\np(\\sigma) = \\frac{\\exp\\left[-\\beta\\cE(\\sigma)\\right]}{Z}.\n\\]\n\\[\nq_\\theta(\\sigma)=\\prod_n q_{\\theta_n}(\\sigma_n).\n\\]\n\nNatural to try to minimize\n\n\\[\nD_\\text{KL}(q||p)(q||p)=\\E_{\\sigma\\sim q_\\theta}\\left[\\log\\left(\\frac{q_\\theta(\\sigma)}{p(\\sigma)}\\right)\\right].\n\\]\n\n\nSubstituting in the Boltzmann distribution \\[\nD_\\text{KL}(q||p)(q||p)= \\log Z - H[q_\\theta] + \\beta \\E_{\\sigma\\sim q_\\theta}\\left[\\cE(\\sigma)\\right]\\geq 0,\n\\] or in usual SM language \\[\n\\E_{\\sigma\\sim q_\\theta}\\left[\\cE(\\sigma)\\right]-TH[q_\\theta] \\geq F,\n\\] where \\(F=-T\\log Z\\) is the Helmholtz free energy.\nThis is the Bogoliubov or Gibbs inequality\n\n\n\nFor Ising spins our factorized distributions are defined by fields on each site \\[\nq_{\\theta_n}(\\sigma_n) = \\frac{\\exp\\left[-\\beta\\theta_n\\sigma_n\\right]}{2\\cosh (\\beta\\theta_n)},\n\\] with average spin \\[\n\\E_{\\sigma_n\\sim q_n}\\left[\\sigma_n\\right] = -\\tanh\\left(\\beta\\theta_n\\right).\n\\]\n\n\n\n\nVI in latent variable models\n\nJust need to replace the Boltzmann distribution with \\[\np(z|x) =\\frac{p(x,z)}{p_\\text{M}(x)}.\n\\] (we add the subscript “M” for model)\nRole of spins \\(\\sigma\\) is now played by the latent variables\nFollowing same steps leads us to\n\n\\[\n\\log p_\\text{M}(x) \\geq \\E_{z\\sim q_\\theta(\\cdot|x)}\\left[\\log p(x,z)\\right]+ H[q_\\theta(\\cdot|z)].\n\\]\n\n\nRHS is Evidence lower bound or ELBO (marginalized probability \\(p(x)\\) on the left is sometimes called the model evidence).\nPossible to rewrite as \\[\n\\log p_\\text{M}(x) \\geq \\log p_\\text{M}(x) - D_\\text{KL}(q_\\theta(\\cdot|x)||p(\\cdot|x)),\n\\] so the bound is saturated when the variational posterior for the latent variables coincides with the true posterior \\[\np(z|x)=p(x,z)/p_\\text{M}(x)\n\\]"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#game-of-life",
    "href": "talks/new-rules-ictp/index.html#game-of-life",
    "title": "New Rules",
    "section": "Game of life",
    "text": "Game of life\n\nimport { life } from \"./js/life.js\";\ncreateSketch(life, 'game-of-life');"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#game-of-life-in-space-time",
    "href": "talks/new-rules-ictp/index.html#game-of-life-in-space-time",
    "title": "New Rules",
    "section": "Game of life in space-time",
    "text": "Game of life in space-time\n\n\nas a longtime fan of Conway’s “Game of Life” algorithm i never once considered visualizing the time axis physically – this is breathtaking and elegant to mecredit:https://t.co/qdPZiEAEPq pic.twitter.com/yKDanPKvos\n\n— chris_cubosh (@cubosh) March 22, 2024"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#rules-of-life",
    "href": "talks/new-rules-ictp/index.html#rules-of-life",
    "title": "New Rules",
    "section": "Rules of Life",
    "text": "Rules of Life\n\nEach site either dead (0) or alive (1)\nFate of cell determined by eight neighbors\n\nAny live cell with two or three live neighbours survives\nAny dead cell with three live neighbours becomes a live cell\nAll other live cells die in the next generation\n\nComplex behavior!\nSee “Recursive Life”: oimo.io/works/life/"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#cellular-automata",
    "href": "talks/new-rules-ictp/index.html#cellular-automata",
    "title": "New Rules",
    "section": "Cellular Automata",
    "text": "Cellular Automata\n\nDynamical systems with discrete space, time, and degrees of freedom\nInteresting for statistical physics:\n\nWhat kinds of dynamics may occur?\nHow does dynamics determine thermodynamic behavior?"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#quantum-circuits",
    "href": "talks/new-rules-ictp/index.html#quantum-circuits",
    "title": "New Rules",
    "section": "Quantum Circuits",
    "text": "Quantum Circuits\n\nA quantum analog of CAs\nBasis of “quantum supremacy” work by Google and others\n\n\n\n\nA schematic view of the Google Sycamore processor"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#elementary-cellular-automata",
    "href": "talks/new-rules-ictp/index.html#elementary-cellular-automata",
    "title": "New Rules",
    "section": "Elementary cellular automata",
    "text": "Elementary cellular automata\n\n“Space” is one dimension with cells x_n=0,1 n\\in\\mathbb{Z}\nUpdate cells every time step depending on cells in neighborhood\n\nNeighborhood is cell and two neighbors for elementary CA"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#wolframs-rules",
    "href": "talks/new-rules-ictp/index.html#wolframs-rules",
    "title": "New Rules",
    "section": "Wolfram’s rules",
    "text": "Wolfram’s rules\n\nDomain of f is 2^3=8 possible values for three cells\n2^8=256 possible choices for the function f\nList outputs corresponding to inputs: 111, 110, … 000\n\n\n\n\n111\n110\n101\n100\n011\n010\n001\n000\n\n\n\n\n0\n1\n1\n0\n1\n1\n1\n0\n\n\n\n\nInterpret as binary number: this one is Rule 110"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#many-behaviours",
    "href": "talks/new-rules-ictp/index.html#many-behaviours",
    "title": "New Rules",
    "section": "Many behaviours",
    "text": "Many behaviours\n\nFrom ordered (Rule 18) to chaotic (Rule 30)\n\n\nviewof rule = Inputs.range(\n  [0, 255], \n  {value: 30, step: 1, label: \"Rule number:\"}\n)\nviewof initial = Inputs.select(\n  [\"single 1\", \"random\"], \n  { value: \"single 1\", \n    label: \"Initial conditions:\"\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport { elementaryParam } from \"./js/elementary-ca.js\";\ncreateSketch(elementaryParam(rule, initial), 'many-behaviours');\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRule 110 is capable of universal computation!"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#cas-as-model-physics",
    "href": "talks/new-rules-ictp/index.html#cas-as-model-physics",
    "title": "New Rules",
    "section": "CAs as model physics",
    "text": "CAs as model physics\n\nNotion of a causal “light cone” (45 degree lines)\nVariety of possible behaviors: chaos, periodicity, …\nDo these have quantum analogues?"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#outline",
    "href": "talks/new-rules-ictp/index.html#outline",
    "title": "New Rules",
    "section": "Outline",
    "text": "Outline\n\nQuantum gates and circuits\nCircuit phenomenology\nCase study: space-time duality"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#what-is-a-quantum-circuit",
    "href": "talks/new-rules-ictp/index.html#what-is-a-quantum-circuit",
    "title": "New Rules",
    "section": "What is a quantum circuit?",
    "text": "What is a quantum circuit?\n\nA way to describe operations on a quantum state, usually consisting of several qubits (spin 1/2 subsystems with Hilbert space \\mathbb{C}^2)\nTwo quantum states \\ket{0} and \\ket{1} define the computational basis.\n\n\n\n\n\nf acts on top five qubits, then g acts on lower seven"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#possible-operations",
    "href": "talks/new-rules-ictp/index.html#possible-operations",
    "title": "New Rules",
    "section": "Possible operations",
    "text": "Possible operations\n\n\n\nSource: Wikipedia\n\n\n\nH (a Hadamard gate) is a single qubit unitary\nAlso two qubit unitary gates (CNOT here)\nMeasurements"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#why-consider-circuits",
    "href": "talks/new-rules-ictp/index.html#why-consider-circuits",
    "title": "New Rules",
    "section": "Why consider circuits?",
    "text": "Why consider circuits?\n\nExample of discrete time, many body dynamics\nMay be used to simulate continuous time evolution\nModel of universal quantum computation\n\nHow to generate an arbitrary quantum state\nOne of several options e.g. measurement-based\n\nThey exist! Companies (Google, IBM, etc.) have built platforms for gate-based QC"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#unitary-circuits",
    "href": "talks/new-rules-ictp/index.html#unitary-circuits",
    "title": "New Rules",
    "section": "Unitary circuits",
    "text": "Unitary circuits\n\n(Mostly) concerned with unitary circuits made from unitary gates\nGate is n-qubit unitary U_{s_1\\ldots s_n,s'_1,\\ldots, s'_n}\n\n\n\\sum_{s_1'\\ldots s_N'}U_{s_1\\ldots s_n,s'_1,\\ldots, s'_n} U^\\dagger_{s'_1\\ldots s'_n,s''_1,\\ldots, s''_n}=\\delta_{s_1,s_1''}\\ldots \\delta_{s_N,s_N''}"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#everything-is-a-tensor",
    "href": "talks/new-rules-ictp/index.html#everything-is-a-tensor",
    "title": "New Rules",
    "section": "Everything is a tensor",
    "text": "Everything is a tensor\n\nState of N qubits expressed in product basis\n\n\n\\ket{\\Psi} = \\sum_{s_{1:N}\\in \\{0,1\\}^N} \\Psi_{s_1\\ldots s_N}\\ket{s_1}_1\\ket{s_2}_2\\cdots \\ket{s_N}_N\n\n\nWrite \\ket{s_1}_1\\ket{s_2}_2\\cdots \\ket{s_N}_N =\\ket{s_1\\cdots s_N}=\\ket{s_{1:N}} for brevity\nOperator on N qubits has matrix elements\n\n\n\\mathcal{O}_{s_{1:N},s'_{1:N}} = \\bra{s_{1:N}}\\mathcal{O}\\ket{s'_{1:N}}"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#graphical-notation",
    "href": "talks/new-rules-ictp/index.html#graphical-notation",
    "title": "New Rules",
    "section": "Graphical notation",
    "text": "Graphical notation\n\nA tensor is denoted by a blob with one leg for each index\nConnecting legs denotes contraction: summing over a shared index\n\n\n\n\nSee Glen Evenbly’s tensor contraction tutorial"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#unitary-gates-one-qubit",
    "href": "talks/new-rules-ictp/index.html#unitary-gates-one-qubit",
    "title": "New Rules",
    "section": "Unitary gates: one qubit",
    "text": "Unitary gates: one qubit\n\nMultiplication by a Pauli matrix: X, Y, or Z.\nGeneral case U = a_0\\mathbb{1} + \\mathbf{a}\\cdot(X,Y,Z) with |a_0|^2+|\\mathbf{a}|^2=1\nOther special cases used in quantum information e.g. Hadamard gate\n\n\nH = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}\n1 & 1 \\\\\\\\\n1 & -1\n\\end{pmatrix}"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#two-qubits",
    "href": "talks/new-rules-ictp/index.html#two-qubits",
    "title": "New Rules",
    "section": "Two qubits",
    "text": "Two qubits\n\nWork in basis \\ket{00}, \\ket{01}, \\ket{10}, \\ket{11}\nSimplest example is SWAP gate\n\n\n\\operatorname{SWAP}=\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\\\n0 & 0 & 1 & 0 \\\\\\\n0 & 1 & 0 & 0 \\\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n.\n\n\\operatorname{SWAP}\\ket{10} = \\ket{01}\n\n\nSWAP takes product states to product states"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#general-two-qubit-unitary",
    "href": "talks/new-rules-ictp/index.html#general-two-qubit-unitary",
    "title": "New Rules",
    "section": "General two qubit unitary",
    "text": "General two qubit unitary\n\nHave to consider both unitaries and conjugates\nIntroduce color-coded notation"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#unitarity-in-graphical-notation",
    "href": "talks/new-rules-ictp/index.html#unitarity-in-graphical-notation",
    "title": "New Rules",
    "section": "Unitarity in graphical notation",
    "text": "Unitarity in graphical notation\n\nCondition of unitarity U^\\dagger U = U U^\\dagger = \\mathsf{1}\n\n\n\\sum_{\\alpha,\\beta}U^{\\vphantom{\\dagger}}_{ab,\\alpha\\beta} U^\\dagger_{\\alpha\\beta,cd}=\\delta_{ac}\\delta_{bd}\n\n\nUnitarity of two qubit gate expressed as\n\n\n\n\n\nMuch better!"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#time-evolution-single-qubit-gates",
    "href": "talks/new-rules-ictp/index.html#time-evolution-single-qubit-gates",
    "title": "New Rules",
    "section": "Time evolution: single qubit gates",
    "text": "Time evolution: single qubit gates\n\nTime evolution operator U=\\exp(-iHt)\nIf H=\\sum_j h_j a sum of single qubit terms\n\n\n\\mathcal{U} = \\exp(-iHt) = \\prod_j \\exp(-ih_j) = \\prod_j U_j\n \nU_j=\\mathbb{1}\\otimes \\ldots \\otimes\\mathbb{1} \\otimes \\overbrace{u_j}^{j\\text{th factor}} \\ldots \\otimes\\mathbb{1}"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#two-qubit-gates",
    "href": "talks/new-rules-ictp/index.html#two-qubit-gates",
    "title": "New Rules",
    "section": "Two qubit gates",
    "text": "Two qubit gates\n\nSimplest example of two qubit interaction is exchange Hamiltonian\n\n\n\\begin{align*}\nh_{12} &= J\\left[X\\otimes X+Y\\otimes Y+Z\\otimes Z\\right] =J\\left[X_1X_2+Y_1Y_2 + Z_1Z_2\\right]\\\\\\\n&=2\\operatorname{SWAP} - 1\n\\end{align*}\n \nU(J) = \\exp(-ih_{12}) = e^{iJ}\\left[\\cos (2J) \\mathbb{1} - i\\sin (2J) \\operatorname{SWAP}\\right]\n\n\nSpecial cases\n\n\nU(\\pi/4)=\\operatorname{SWAP}\n \nU(\\pi/8)=\\sqrt{\\operatorname{SWAP}}\n\n\nFully rotationally invariant"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#floquet-theory-kicked-ising-model",
    "href": "talks/new-rules-ictp/index.html#floquet-theory-kicked-ising-model",
    "title": "New Rules",
    "section": "Floquet theory: kicked Ising model",
    "text": "Floquet theory: kicked Ising model\n\nTime dependent Hamiltonian with kicks at t=0,1,2,\\ldots.\n\n\n\\begin{align*}\nH_{\\text{KIM}}(t) = H_\\text{I}[\\mathbf{h}] + \\sum_{n}\\delta(t-n)H_\\text{K}\\\\\\\nH_\\text{I}[\\mathbf{h}]=\\sum_{j=1}^L\\left[J Z_j Z_{j+1} + h_j Z_j\\right],\\qquad H_\\text{K} &= b\\sum_{j=1}^L X_j\n\\end{align*}\n\n\n“Stroboscopic” form of \\mathcal{U}(t)=\\mathcal{T}\\exp\\left[-i\\int^t H_{\\text{KIM}}(t') dt'\\right]\n\n\n\\begin{aligned}\n  \\mathcal{U}(n_+) &= \\left[\\mathcal{U}(1_+)\\right]^n,\\qquad U(1_-) = K I_\\mathbf{h}\\\\\\\n  I_\\mathbf{h} &= e^{-iH_\\text{I}[\\mathbf{h}]}, \\qquad K = e^{-iH_\\text{K}}\n\\end{aligned}"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#kim-as-a-circuit",
    "href": "talks/new-rules-ictp/index.html#kim-as-a-circuit",
    "title": "New Rules",
    "section": "KIM as a circuit",
    "text": "KIM as a circuit\n\n\n\n\n\\begin{aligned}\n  \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\\\\n  \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]\n\\end{aligned}"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#locality",
    "href": "talks/new-rules-ictp/index.html#locality",
    "title": "New Rules",
    "section": "Locality",
    "text": "Locality\n\nLocality a feature of real quantum computing architectures\n\n\n \n\n(top) a schematic view of the Google Sycamore processor and (bottom) the real thing"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#computational-complexity",
    "href": "talks/new-rules-ictp/index.html#computational-complexity",
    "title": "New Rules",
    "section": "Computational complexity",
    "text": "Computational complexity\n\nState is vector in 2^N dimensional space\nUpdating involves acting with a unitary matrix\nNaive matrix-vector multiplication O(\\operatorname{dim}^2)=2^{2N}\nSince gates gives sparse matrices update is O(\\operatorname{dim})=2^{N}\nStill exponentially hard in the number of qubits"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#quantum-supremacy",
    "href": "talks/new-rules-ictp/index.html#quantum-supremacy",
    "title": "New Rules",
    "section": "Quantum supremacy",
    "text": "Quantum supremacy\n\nDifficulty on classical computer basis of “quantum supremacy” based on circuit sampling\nMeasure empirical distribution of bit strings with fixed initial state\nTotal number of (time) steps T taken is depth of the circuit. For low depth T&lt;N it pays to move horizontally instead\nProblem of finding optimal contraction strategy in general is NP-hard\nGoogle’s initial claim of supremacy disputed by supercomputer optimizations, followed by improved tensor network methods: Huang et al. (2020), Gray and Kourtis (2021), Pan and Zhang (2021), Napp et al. (2022)"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#causality",
    "href": "talks/new-rules-ictp/index.html#causality",
    "title": "New Rules",
    "section": "Causality",
    "text": "Causality\n\nBrickwork circuit has natural lightcone! (c=1)"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#operator-pushing",
    "href": "talks/new-rules-ictp/index.html#operator-pushing",
    "title": "New Rules",
    "section": "Operator pushing",
    "text": "Operator pushing\n\n\\mathcal{O}'=\\mathcal{U}^\\dagger\\mathcal{O}\\mathcal{U}\n\n\n\\mathcal{U}\\mathcal{O}'=\\mathcal{O}\\mathcal{U}\n\n\n\n\n\nEvidently \\mathcal{O}=\\mathbb{1} \\longleftrightarrow \\mathcal{O}'=\\mathbb{1}"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#no-correlations-outside-light-cone",
    "href": "talks/new-rules-ictp/index.html#no-correlations-outside-light-cone",
    "title": "New Rules",
    "section": "No correlations outside light cone",
    "text": "No correlations outside light cone\n\nC(\\mathcal{O}_1(t),\\mathcal{O}_2(0)) \\equiv \\operatorname{tr}\\left[\\mathcal{U}_t^\\dagger\\mathcal{O}_1\\mathcal{U}_t\\mathcal{O}_2\\right] = \\operatorname{tr}\\left[\\mathcal{O}'_1\\mathcal{O}_2\\right] = \\operatorname{tr}\\left[\\mathcal{O}'_1\\right]\\operatorname{tr}\\left[\\mathcal{O}_2\\right]"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#operator-spreading",
    "href": "talks/new-rules-ictp/index.html#operator-spreading",
    "title": "New Rules",
    "section": "Operator spreading",
    "text": "Operator spreading\n\nObservable Z_n(t) expanded in local products of Paulis\n\n\nZ_n,\\qquad X_n Y_{n+1},\\qquad Z_{n-1}Y_n X_{n+1},\\cdots"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#kim-at-jbhpi4",
    "href": "talks/new-rules-ictp/index.html#kim-at-jbhpi4",
    "title": "New Rules",
    "section": "KIM at J=b=h=\\pi/4",
    "text": "KIM at J=b=h=\\pi/4\n\nIn this case only one term in operator expansion\n\n\n\n\n\nFractal pattern of Z operators"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#dimensional-kim",
    "href": "talks/new-rules-ictp/index.html#dimensional-kim",
    "title": "New Rules",
    "section": "2+1 dimensional KIM",
    "text": "2+1 dimensional KIM\n\nimport { threeDCat } from \"./js/3d-cat.js\";\ncreateSketch(threeDCat, 'dimensional-kim');"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#out-of-time-order-correlator",
    "href": "talks/new-rules-ictp/index.html#out-of-time-order-correlator",
    "title": "New Rules",
    "section": "Out of time order correlator",
    "text": "Out of time order correlator\n\n\\operatorname{OTOC}_{jk}(t) \\equiv \\langle Z_j(t)Z_k(0)Z_j(t)Z_k(0)\\rangle\n\n\nOTOC sometimes written as squared commutator\n\n\n\\langle \\left[Z_k(0),Z_j(t)\\right]^2 \\rangle\n\n\nRelation between two expressions is (using Z^2=1)\n\n\n\\operatorname{OTOC}_{jk}(t) = \\frac{1}{2}\\langle \\left[Z_k(0),Z_j(t)\\right]^2 \\rangle + 1"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#classical-analogue",
    "href": "talks/new-rules-ictp/index.html#classical-analogue",
    "title": "New Rules",
    "section": "Classical analogue",
    "text": "Classical analogue\n\nRapid growth of small differences between two trajectories\n\n\nviewof ruleDifference = Inputs.range(\n  [0, 255], \n  {value: 110, step: 1, label: \"Rule number:\"}\n)\n\n\n\n\n\n\n\nimport { differenceParam } from \"./js/ca-difference.js\";\ncreateSketch(differenceParam(ruleDifference), 'classical-analogue');\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSmallest change: flip one site and monitor z^t\\equiv x^t\\oplus y^t"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#phenomenology-of-spreading",
    "href": "talks/new-rules-ictp/index.html#phenomenology-of-spreading",
    "title": "New Rules",
    "section": "Phenomenology of spreading",
    "text": "Phenomenology of spreading\n\nvon Keyserlingk et al (2018) and Nahum, Vijay, Haar (2018)\n\n\n\n\nSource: Nahum, Vijay, Haar (2018)."
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#googles-otoc-experiment",
    "href": "talks/new-rules-ictp/index.html#googles-otoc-experiment",
    "title": "New Rules",
    "section": "Google’s OTOC experiment",
    "text": "Google’s OTOC experiment\n\nOTOC measured in 2021 by Google\n\n\n\n\nThe measured OTOC for i\\operatorname{\\operatorname{\\mathsf{SWAP}}} gates (top) and \\sqrt{i\\operatorname{\\mathsf{SWAP}}} (bottom) after averaging over single qubit gates"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#quantifying-entanglement",
    "href": "talks/new-rules-ictp/index.html#quantifying-entanglement",
    "title": "New Rules",
    "section": "Quantifying entanglement",
    "text": "Quantifying entanglement\n\nSystem composed of two subsystems A and B\nGeneral state is vector \\in\\mathcal{H}=\\mathcal{H}_A\\otimes\\mathcal{H}_B\nWrite in terms of basis vectors \\ket{a}_A and \\ket{b}_B for A and B subsystems \n\\ket{\\Psi}_{AB} = \\sum_{a=1}^{n_A}\\sum_{b=1}^{n_B} \\Psi_{ab}\\ket{a}_A\\ket{b}_B\n n_{A/B}=\\operatorname{dim} \\mathcal{H}_{A/B}\nNow regard \\Psi_{ab} as matrix and perform a singular value decomposition"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#two-important-facts",
    "href": "talks/new-rules-ictp/index.html#two-important-facts",
    "title": "New Rules",
    "section": "Two important facts",
    "text": "Two important facts\n\n\\rho_A = \\operatorname{tr}_B\\left[\\ket{\\Psi}\\bra{\\Psi}\\right] unchanged by unitary transformation on B\n\\operatorname{spec}(\\rho_A) unchanged by unitary transformation on A"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#toy-model",
    "href": "talks/new-rules-ictp/index.html#toy-model",
    "title": "New Rules",
    "section": "Toy model",
    "text": "Toy model\n\nCircuit of SWAP gates\n\n\n\nInitial state is product of Bell states \n\\ket{\\Phi^+}_{2n, 2n+1} = \\frac{1}{\\sqrt{2}}\\left[\\ket{0}_{2n}\\ket{0}_{2n+1}+ \\ket{1}_{2n}\\ket{1}_{2n+1}\\right]\n \n\\operatorname{tr}_{2}\\left[\\ket{\\Phi^+}_{12}\\bra{\\Phi^+}_{12}\\right] = \\frac{1}{2}\\mathbb{1}_1\n with entanglement entropy of one bit"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#recall-kicked-ising-model",
    "href": "talks/new-rules-ictp/index.html#recall-kicked-ising-model",
    "title": "New Rules",
    "section": "Recall: kicked Ising model",
    "text": "Recall: kicked Ising model\n\nTime dependent Hamiltonian with kicks at t=0,1,2,\\ldots.\n\n\n\\begin{align*}\nH_{\\text{KIM}}(t) = H_\\text{I}[\\mathbf{h}] + \\sum_{n}\\delta(t-n)H_\\text{K}\\\\\\\nH_\\text{I}[\\mathbf{h}]=\\sum_{j=1}^L\\left[J Z_j Z_{j+1} + h_j Z_j\\right],\\qquad H_\\text{K} &= b\\sum_{j=1}^L X_j\n\\end{align*}"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#entanglement-growth-for-kim",
    "href": "talks/new-rules-ictp/index.html#entanglement-growth-for-kim",
    "title": "New Rules",
    "section": "Entanglement Growth for KIM",
    "text": "Entanglement Growth for KIM\n\nBertini, Kos, Prosen (2019) found that when |J|=|b|=\\pi/4\n\n\n\\lim_{L\\to\\infty} S_A =\\min(2t-2,N_A)\\log 2,\n\n\nAny h_j; initial Z_j product state"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#rdm-and-thermalization",
    "href": "talks/new-rules-ictp/index.html#rdm-and-thermalization",
    "title": "New Rules",
    "section": "RDM and thermalization",
    "text": "RDM and thermalization\n\nFor SDKIM have 2^{\\min(2t-2,N_A)} non-zero eigenvalues of RDM all equal\n\n\np_n = \\left(\\frac{1}{2}\\right)^{\\min(2t-2,N_A)}\n\n\nAfter N_A/2 + 1 steps, reduced density matrix is \\propto \\mathbb{1}\nAll expectations (with A) take on infinite temperature value"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#dual-unitarity",
    "href": "talks/new-rules-ictp/index.html#dual-unitarity",
    "title": "New Rules",
    "section": "Dual unitarity",
    "text": "Dual unitarity\n\nRecall KIM has circuit representation\n\n\n\n\n\n\\begin{aligned}\n  \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\\n  \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]\n\\end{aligned}"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#the-dual-unitary-family",
    "href": "talks/new-rules-ictp/index.html#the-dual-unitary-family",
    "title": "New Rules",
    "section": "The dual unitary family",
    "text": "The dual unitary family\n\n4\\times 4 unitaries are 16-dimensional\nFamily of dual unitaries is 14-dimensional\nIncludes kicked Ising model at particular values of couplings\nDual unitaries not “integrable” but have enough structure to allow many calculations"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#entanglement-from-space-time-duality",
    "href": "talks/new-rules-ictp/index.html#entanglement-from-space-time-duality",
    "title": "New Rules",
    "section": "Entanglement from space-time duality",
    "text": "Entanglement from space-time duality\n\nStart from neighbouring Bell states (seems special)\n\n\n\n\n\nCircuit above the dotted line =\\mathcal{U}_A\\otimes\\mathcal{U}_B: doesn’t change entanglement!"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#remark-operator-entanglement",
    "href": "talks/new-rules-ictp/index.html#remark-operator-entanglement",
    "title": "New Rules",
    "section": "Remark: operator entanglement",
    "text": "Remark: operator entanglement\n\nOTOC provides one measure of operator spreading\nAnother question: how many nonzero coefficients \\mathcal{C}_{\\mu_{1:N}}?\nIntroduce Schmidt decomposition for operators \n\\mathcal{O}_{AB} = \\sum_{n=1}^{\\min(n^2_A, n^2_B)} \\Sigma_n A_n\\otimes B_n\n\n\\Sigma_n\\geq 0 are operator Schmidt coefficients\nA_n and B_n are orthonormal operators on \\mathcal{H}_A and \\mathcal{H}_B i.e. \\operatorname{tr}\\left[A^\\dagger_m A_n\\right]=\\operatorname{tr}\\left[B^\\dagger_m B_n\\right]=\\delta_{mn}"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#influence-functional",
    "href": "talks/new-rules-ictp/index.html#influence-functional",
    "title": "New Rules",
    "section": "Influence functional",
    "text": "Influence functional\n\n\n\nSource: Sonner, Lerose, Abanin (2021)\n\n\n\nEarlier named process tensor by Pollock et al. (2018)"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#isometry",
    "href": "talks/new-rules-ictp/index.html#isometry",
    "title": "New Rules",
    "section": "Isometry",
    "text": "Isometry\n\nLinear map \\mathcal{I}:\\mathcal{H}_A\\longrightarrow \\mathcal{H}_B that preserves distance i.e.  \n\\braket{a|a} = \\braket{a|\\mathcal{I}^\\dagger \\mathcal{I}|a}\\text{  or  } \\mathcal{I}^\\dagger \\mathcal{I} = \\mathbb{1}_A\n\nIf system described by wavefunction \n\\ket{\\Psi}_{AB}=\\sum_{a,b} \\mathcal{I}_{ab}\\ket{a}\\otimes \\ket{b}\n\nRDM of A is\n\n\n\\rho_A = \\operatorname{tr}_B\\left[\\ket{\\Psi}_{AB}\\bra{\\Psi}_{AB}\\right]\\propto \\mathbb{1}_A"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#influence-functional-is-rdm-in-time",
    "href": "talks/new-rules-ictp/index.html#influence-functional-is-rdm-in-time",
    "title": "New Rules",
    "section": "Influence functional is RDM in time!",
    "text": "Influence functional is RDM in time!\n\n\n\n\nFor DU circuit map from vertical to horizontal is isometry\nHappens precisely for bath of size t"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#temporal-entanglement",
    "href": "talks/new-rules-ictp/index.html#temporal-entanglement",
    "title": "New Rules",
    "section": "Temporal entanglement",
    "text": "Temporal entanglement\n\nA DU circuit is a purely Markovian bath (no approximation)\nDegree of non-markovianity captured by temporal entanglement (Sonner, Lerose, Abanin (2021))\nLow temporal entanglment allows efficient MPS methods to be applied to process tensor (see Fux et al. (2021))"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#reminder-no-correlations-outside-light-cone",
    "href": "talks/new-rules-ictp/index.html#reminder-no-correlations-outside-light-cone",
    "title": "New Rules",
    "section": "Reminder: no correlations outside light cone",
    "text": "Reminder: no correlations outside light cone\n\nC(\\mathcal{O}_1(t),\\mathcal{O}_2(0)) \\equiv \\operatorname{tr}\\left[\\mathcal{U}_t^\\dagger\\mathcal{O}_1\\mathcal{U}_t\\mathcal{O}_2\\right] = \\operatorname{tr}\\left[\\mathcal{O}'_1\\mathcal{O}_2\\right] = \\operatorname{tr}\\left[\\mathcal{O}'_1\\right]\\operatorname{tr}\\left[\\mathcal{O}_2\\right]\n\n\n\n\n\nBertini, Kos, Prosen (2019): DU means correlations vanish inside light cone!\nDU family spans ergodic to integrable behaviour of correlations"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#quantinuum-experiment",
    "href": "talks/new-rules-ictp/index.html#quantinuum-experiment",
    "title": "New Rules",
    "section": "Quantinuum experiment",
    "text": "Quantinuum experiment\n\nCorrelations measured in SDKIM by Chertkov et al. (2022)"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#cnot-circuit-floquet-east-model",
    "href": "talks/new-rules-ictp/index.html#cnot-circuit-floquet-east-model",
    "title": "New Rules",
    "section": "CNOT circuit (Floquet East model)",
    "text": "CNOT circuit (Floquet East model)\n\n \n\nSource: Gopalakrishnan and Zakirov (2018)"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#zx-calculus",
    "href": "talks/new-rules-ictp/index.html#zx-calculus",
    "title": "New Rules",
    "section": "ZX Calculus",
    "text": "ZX Calculus\n\nCalculus of “special” tensors\n\n\n \n\n\nSee also van der Wetering (2020)"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#basic-ingredients-z-and-x-tensors-spiders",
    "href": "talks/new-rules-ictp/index.html#basic-ingredients-z-and-x-tensors-spiders",
    "title": "New Rules",
    "section": "Basic ingredients: Z and X tensors (“spiders”)",
    "text": "Basic ingredients: Z and X tensors (“spiders”)\n\n \n\nSource: van der Wetering (2020)\n\n\n\n|0\\rangle=\\left(\\begin{array}{l}\n1 \\\\\n0\n\\end{array}\\right) \\quad|1\\rangle=\\left(\\begin{array}{l}\n0 \\\\\n1\n\\end{array}\\right) \\quad|+\\rangle=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{l}\n1 \\\\\n1\n\\end{array}\\right) \\quad|-\\rangle=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{c}\n1 \\\\\n-1\n\\end{array}\\right)\n\n\nObey many identities upon contraction"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#simplest-examples",
    "href": "talks/new-rules-ictp/index.html#simplest-examples",
    "title": "New Rules",
    "section": "Simplest examples",
    "text": "Simplest examples\n\nIdentity\n\n\n\nCNOT"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#example-liu-and-ho-2023",
    "href": "talks/new-rules-ictp/index.html#example-liu-and-ho-2023",
    "title": "New Rules",
    "section": "Example: Liu and Ho (2023)",
    "text": "Example: Liu and Ho (2023)"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#rewrite-in-zx-language",
    "href": "talks/new-rules-ictp/index.html#rewrite-in-zx-language",
    "title": "New Rules",
    "section": "Rewrite in ZX language",
    "text": "Rewrite in ZX language\n\n\n\n\nCNOTs (East model, see also Bertini et al. (2023)) + phases on each spider"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#recent-applications-of-dual-unitarity",
    "href": "talks/new-rules-ictp/index.html#recent-applications-of-dual-unitarity",
    "title": "New Rules",
    "section": "Recent applications of dual unitarity…",
    "text": "Recent applications of dual unitarity…\n\nEmerging dual unitarity in models described by CFTs\n(Carignano, Tagliacozzo (2024))\nTemporal entanglement in dual-unitary Clifford circuits with measurements\n(Yao, Claeys (2024))\nStabilizer Rényi entropy in the dual-unitary XXZ model\n(Montañà López, Kos (2024))\nDual unitary shadow tomography\n(Akhtar et al. (2024))"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#last-thing-lorentz-symmetry",
    "href": "talks/new-rules-ictp/index.html#last-thing-lorentz-symmetry",
    "title": "New Rules",
    "section": "Last thing: Lorentz symmetry",
    "text": "Last thing: Lorentz symmetry\n\n\n\\color{red}{\\Lambda}\\color{green}{\\mathcal{T}} \\color{black}{=}\\color{green}{\\mathcal{T}'}\\color{red}{\\Lambda}\n\n\n\\color{red}\\Lambda\\color{green}\\mathcal{T}\\color{red}\\Lambda^\\dagger \\color{black}=\\color{green} \\mathcal{T}'\n\n\nMasanes suggests (arXiv:2301.02825) DU circuits connected to CFTs"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#summary",
    "href": "talks/new-rules-ictp/index.html#summary",
    "title": "New Rules",
    "section": "Summary",
    "text": "Summary\n\nFurther reading…\nMeasurements etc."
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#physical-quantites",
    "href": "talks/new-rules-ictp/index.html#physical-quantites",
    "title": "New Rules",
    "section": "Physical quantites",
    "text": "Physical quantites\n\nCausality and light cones. How to show that unitarity is related to causality\nNotions of operator spreading and operator entanglment\nOperator pushing\nInclude fact that for dual unitaries operator can’t push to operator with component having identity on opposite side (why not? because identity pushes to identity)\nOTOC and Google experiment\nOperator entanglement\nTemporal entanglement and notion of bath (refer to Gerald stuff). Again follows from isometry property\nSpectral statistics and quantum chaos\nRandom circuits\nSimple example of Heisenberg circuit maybe?\nSuperdiffusion"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#quantum-models",
    "href": "talks/new-rules-ictp/index.html#quantum-models",
    "title": "New Rules",
    "section": "Quantum models",
    "text": "Quantum models\n\nFloquet time evolution\nTrotterization\nQuantum circuits\nSDKI as a paradigmatic system"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#classical-models",
    "href": "talks/new-rules-ictp/index.html#classical-models",
    "title": "New Rules",
    "section": "Classical models",
    "text": "Classical models\n\nSpatiotemporal cat\nConnection to SDKI\nClifford automata. Sometimes QM is not harder than classical physics\nAutomata with gliders vs. fractal growth"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#graphical-methods",
    "href": "talks/new-rules-ictp/index.html#graphical-methods",
    "title": "New Rules",
    "section": "Graphical methods",
    "text": "Graphical methods\n\nZX calculus\nTriunitary condition\nLiu Ho model and East"
  },
  {
    "objectID": "talks/new-rules-ictp/index.html#frontiers",
    "href": "talks/new-rules-ictp/index.html#frontiers",
    "title": "New Rules",
    "section": "Frontiers",
    "text": "Frontiers\n\nMeasurements\nPieter recent measurement work\nHayden Preskill\nLorentz symmetry\nSimple examples of rules for CAs\nConnections to nontrivial geometries eg. HaPPY code\nRecent Kos work on stabilizer entropy for kicked XY\nRecent Luca work on emergent dual unitarity… has no appeared and can be cited…\n\nExperiments – Quantinuum and recent paper https://arxiv.org/abs/2405.07613. Also holographic paper"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html",
    "href": "talks/quantum-circuits-1/index.html",
    "title": "Quantum Circuits",
    "section": "",
    "text": "austen.uk/slides/quantum-circuits-1\n\n\n\n\n\nA way to describe operations on quantum state, usually consisting of several qubits (spin 1/2 subsystems)\n\n\n\n\n\n\\(f\\) acts on top five qubits, then \\(g\\) acts on lower seven\n\n\n\n\n\n\n\n\nSource: Wikipedia\n\n\n\n\\(H\\) (a Hadamard gate) is a single qubit unitary\nAlso two qubit unitary gates (CNOT here)\nMeasurements\n\n\n\n\n\n\nModel of universal quantum computation\n\nHow to generate an arbitrary quantum state\nOne of several options e.g. measurement-based\n\nExample of discrete time, many body dynamics\n\n\n\n\n\n\n(Mostly) concerned with unitary circuits made from unitary gates\nGate is \\(n\\)-qubit unitary \\(U_{s_1\\ldots s_n,s'_1,\\ldots, s'_n}\\)\n\n$$ \\sum_{s_1'\\ldots s_N'}U_{s_1\\ldots s_n,s'_1,\\ldots, s'_n} U^\\dagger_{s'_1\\ldots s'_n,s''_1,\\ldots, s''_n}=\\delta_{s_1,s_1''}\\ldots \\delta_{s_N,s_N''} $$\n\n\n\n\n\nState of \\(N\\) qubits expressed in product basis\n\n$$ \\ket{\\Psi} = \\sum_{s_{1:N}\\in \\{0,1\\}^N} \\Psi_{s_1\\ldots s_N}\\ket{s_1}_1\\ket{s_2}_2\\cdots \\ket{s_N}_N $$\n\nWrite $\\ket{s_1}_1\\ket{s_2}_2\\cdots \\ket{s_N}_N =\\ket{s_1\\cdots s_N}=\\ket{s_{1:N}}$ for brevity\nOperator on \\(N\\) qubits has matrix elements\n\n$$ \\mathcal{O}_{s_{1:N},s'_{1:N}} = \\bra{s_{1:N}}\\mathcal{O}\\ket{s'_{1:N}} $$\n\n\n\n\n\n\n\nSee Pan Zhang’s tutorial\n\n\n\n\n\n\n\nMultiplication by a Pauli matrix: \\(X\\), \\(Y\\), or \\(Z\\).\nGeneral case \\(U = a_0\\mathbb{1} + \\vectorbold{a}\\cdot(X,Y,Z)\\) with \\(|a_0|^2+|\\vectorbold{a}|^2=1\\)\nOther special cases used in quantum information e.g. Hadamard gate $$ H = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 & 1 \\\\ 1 & -1 \\end{pmatrix} $$\n\n\n\n\n\n\nUsually write in basis \\(\\ket{00}\\), \\(\\ket{01}\\), \\(\\ket{10}\\), \\(\\ket{11}\\)\nSimplest example: SWAP gate $$ \\operatorname{SWAP}=\\left[\\begin{array}{llll} 1 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\end{array}\\right] $$\nTakes product state to product state in computational basis\n\n\\[\n\\operatorname{SWAP}\\ket{10} = \\ket{01}\n\\]\n\n\n\n\n$$ \\sqrt{\\operatorname{SWAP}}=\\left[\\begin{array}{cccc} 1 & 0 & 0 & 0 \\\\ 0 & \\frac{1}{2}(1+i) & \\frac{1}{2}(1-i) & 0 \\\\ 0 & \\frac{1}{2}(1-i) & \\frac{1}{2}(1+i) & 0 \\\\ 0 & 0 & 0 & 1 \\end{array}\\right] $$\n\nGenerates entanglement\n\n\\[\n\\sqrt{\\operatorname{SWAP}}\\ket{10} = \\frac{1}{2}\\left[(1+i)\\ket{10}+(1-i)\\ket{01}\\right]\n\\]\n\nConserves number of 1s and 0s (in fact fully rotationally invariant)\n\\(\\sqrt{\\operatorname{SWAP}}\\) and single qubit unitaries are universal gate set\n\n\n\n\n\n\nAny two-qubit unitary \\(U\\in \\mathcal{U(4)}\\) can be written\n\n\\[\\begin{equation}\nU = e^{i \\phi} (u_+ \\otimes u_-) V[J_x, J_y, J_z] (v_- \\otimes v_+),\n\\end{equation}\\]\n\n\\(u_{\\pm}, v_{\\pm} \\in SU(2)\\)\n\n\\begin{align}  V[J_x, J_y, J_z] &= \\exp \\left[-i\\left(J_x \\sigma^x \\otimes \\sigma^x + J_y \\sigma^y \\otimes \\sigma^y+ J_z \\sigma^z \\otimes \\sigma^z\\right)\\right]\\\\  &= \\begin{bmatrix} e^{-i J_z} \\cos(J_-) & 0 & 0 & -i e^{-i J_z \\sin(J_-)} \\\\ 0 & e^{iJ_z} \\cos(J_+) & -ie^{i J_z} \\sin(J_+) & 0 \\\\ 0 & -ie^{i J_z} \\sin(J_+) & e^{iJ_z} \\cos(J_+) & 0 \\\\ -i e^{-i J_z \\sin(J_-)} & 0 & 0 & e^{-i J_z} \\cos(J_-) \\\\ \\end{bmatrix} \\end{align}\n\n16 parameters!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime evolution operator \\(U=\\exp(-iHt)\\)\nIf \\(H=\\sum_j h_j\\) a sum of single qubit terms\n\n\\[\nU = \\exp(-iHt) = \\prod_j \\exp(-ih_j) = \\prod_j U_j\n\\] \\[\nU_j=\\mathbb{1}\\otimes \\ldots \\otimes\\mathbb{1} \\otimes \\overbrace{u_j}^{j\\text{th factor}} \\ldots \\otimes\\mathbb{1}\n\\]\n\n\n\n\n\nSimplest example of two qubit interaction is exchange Hamiltonian\n\n$$ \\begin{align} h_{12} &= J\\left[X\\otimes X+Y\\otimes Y+Z\\otimes Z\\right] =J\\left[X_1X_2+Y_1Y_2 + Z_1Z_2\\right]\\\\ &=2\\operatorname{SWAP} - 1 \\end{align} $$ $$ U(J) = \\exp(-ih_{12}) = e^{iJ}\\left[\\cos (2J) \\mathbb{1} - i\\sin (2J) \\operatorname{SWAP}\\right] $$\n\nSpecial cases\n\n\\[\nU(\\pi/4)=\\operatorname{SWAP}\n\\] \\[\nU(\\pi/8)=\\sqrt{\\operatorname{SWAP}}\n\\]\n\n\n\\(H=\\sum_{i,j} h_{i,j}\\) a sum of two qubit terms with \\([h_{i,j},h_{j,k}]\\neq 0\\)\n\\(U\\neq \\prod_{i,j} \\exp(-ih_{i,j})\\). More complicated!\nSuzuki–Trotter expansion: decompose \\(H=H_A + H_B\\)\n\n\\[\nU = \\exp(-iH) = \\left[\\exp\\left(-\\frac{iH}{n}\\right)\\right]^n \\sim \\left[e^{-iH_A/n} e^{-iH_B/n}\\right]^n\n\\]\n\n\n\n\n\\[\nH = \\sum_j h_{j,j+1}\n\\] \\[\nH_A = \\sum_j h_{2j, 2j+1}\\qquad H_B = \\sum_j h_{2j-1, 2j}\n\\] \\[\ne^{-iH_A/n}=\\prod_j U_{2j,2j+1}\\qquad e^{-iH_B/n} = \\prod_j U_{2j-1,2j}\n\\]\n\n\n\n\n\n\n\n\nTime dependent Hamiltonian with kicks at \\(t=0,1,2,\\ldots\\).\n\n$$ \\begin{aligned} H_{\\text{KIM}}(t) = H_\\text{I}[\\mathbf{h}] + \\sum_{m}\\delta(t-n)H_\\text{K}\\\\ H_\\text{I}[\\mathbf{h}]=\\sum_{j=1}^L\\left[J Z_j Z_{j+1} + h_j Z_j\\right],\\qquad H_\\text{K} &= b\\sum_{j=1}^L X_j, \\end{aligned} $$\n\n“Stroboscopic” form of \\(U(t)=\\mathcal{T}\\exp\\left[-i\\int^t H_{\\text{KIM}}(t') dt'\\right]\\)\n\n$$ \\begin{aligned}   U(n_+) &= \\left[U(1_+)\\right]^n,\\qquad U(1_-) = K I_\\mathbf{h}\\\\   I_\\mathbf{h} &= e^{-iH_\\text{I}[\\mathbf{h}]}, \\qquad K = e^{-iH_\\text{K}} \\end{aligned} $$\n\n\n\n\n\n\n\n$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]. \\end{aligned} $$\n\n\n\n\n\nGoogle Sycamore processor\n\n\n \n\n\n\n\n\n\nSampling from circuits basis of Google’s “quantum supremacy”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHave causality built in\n\n\n\nMore complicated tensor networks → more complicated spacetimes (black holes, AdS, etc.)\n\n\n\n\nSource: Quantum Frontiers\n\n\n\n\n\n\n\n\n\n\nNormally matrix-vector multiplication is \\(O(\\operatorname{dim}^2)=2^{2N}\\)\nGates are sparse so \\(O(\\operatorname{dim})=2^{N}\\), but still exponentially hard\nFor low depth \\(T&lt;N\\) move horizontally instead\n\n\n\n\n\n\nEvaluate \\(\\bra{\\Psi}\\mathcal{O}\\ket{\\Psi}=\\bra{\\Psi_0}U^\\dagger\\mathcal{O}U\\ket{\\Psi_0}\\) for local \\(\\mathcal{O}\\)\nIf \\(\\Psi_0\\) is product state top and bottom indices match \n\n\n\n\n\n\nRecall unitary condtion\n\n\n\n\n\n\nAfter folding lines correspond to two indices / 4 dimensions\nSemicircle denotes \\(\\delta_{ab}\\)\n\n\n\n\n\n\n\n\nEmergence of “light cone”\n\n\n\n\n\n\n\n\\[\n\\rho_A = \\operatorname{tr}_B\\left[\\ket{\\Psi}\\bra{\\Psi}\\right]=\\operatorname{tr}_B\\left[U\\ket{\\Psi_0}\\bra{\\Psi_0}U^\\dagger\\right]\n\\]\n\n\n\n\n\n\n\nIn $\\mathcal{H}=\\mathcal{H}_A\\otimes\\mathcal{H}_B$ any state $\\Psi_{AB}$ can be written\n\n$$ \\ket{\\Psi_{AB}} = \\sum_{\\alpha=1}^{\\min(\\operatorname{dim} \\mathcal{H}_A, \\operatorname{dim} \\mathcal{H}_B)} \\lambda_\\alpha \\ket{u_\\alpha}_A\\otimes\\ket{v_\\alpha}_B $$\n\n\\(\\ket{u_\\alpha}\\) and \\(\\ket{v_\\alpha}\\) orthonormal; \\(\\lambda_\\alpha\\geq 0\\)\n\\(\\lambda_\\alpha\\) quantify entanglement between A and B\n\n\n\n\n\n$$ \\begin{align} \\rho_A &= \\operatorname{tr}_B\\left[\\ket{\\Psi}\\bra{\\Psi}\\right] \\\\ &= \\sum_\\alpha \\lambda_\\alpha^2 \\ket{u_\\alpha}\\bra{u_\\alpha} \\end{align} $$\n\n\\(p_\\alpha\\equiv \\lambda_\\alpha^2\\) are the eigenvalues of \\(\\rho_A\\)\n\n\n\n\n\n\n\\(\\operatorname{rank}=\\min(\\operatorname{dim} \\mathcal{H}_A, \\operatorname{dim} \\mathcal{H}_B)=2^{\\min(2t-2, N_A)}\\)\nHere \\(t=4\\), \\(N_A=4\\) \n\n\n\n\n\n\nvon Neumann entropy of \\(\\rho_A\\)\n\n$$ \\begin{align} S_A &= -\\operatorname{tr}\\left[\\rho_A\\log \\rho_A\\right]\\\\ &=-\\sum_\\alpha p_\\alpha \\log p_\\alpha \\end{align} $$\n\nMaximum value for equal probabilities \\(p_\\alpha = \\frac{1}{2^{\\min(2t-2, N_A)}}\\)\n\n\\[\nS_A \\leq \\min(2t-2, N_A)\\log 2\n\\]\n\n\n\n\nBertini, Kos, Prosen (2019) found that when \\(|J|=|b|=\\pi/4\\)\n\n\\[\n\\lim_{L\\to\\infty} S_A =\\min(2t-2,N_A)\\log 2,\n\\]\n\nAny \\(h_j\\); initial \\(Z_j\\) product state\n\n\n\n\n\n\n\n\n\n\nRényi entropies depend on eigenvalues of reduced density matrix\n\n$$   S^{(n)}_A = \\frac{1}{1-n}\\log \\text{tr}\\left[\\rho^n\\right]=\\frac{1}{1-n}\\sum_\\alpha p_\\alpha^n $$\n\nFor SDKIM have \\(2^{\\min(2t-2,N_A)}\\) non-zero eigenvalues all equal\n\n\\[\np_\\alpha = \\left(\\frac{1}{2}\\right)^{\\min(2t-2,N_A)}\n\\]\n\n\n\n\n\nAfter \\(N_A/2 + 1\\) steps, reduced density matrix is \\(\\propto \\mathbb{1}\\)\nAll expectations (with \\(A\\)) take on infinite temperature value\n\n\n\n\n\n\nRecall KIM has circuit representation\n\n\n\n\n$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]. \\end{aligned} $$\n\n\nAt \\(|J|=|b|=\\pi/4\\) has additional property of dual unitarity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(\\(q=2\\) here) Not satisfied by e.g. \\(\\operatorname{SWAP}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRDM is unitary transformation of\n\n\\[\n\\rho_0=\\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1} \\otimes\\overbrace{|Z_1\\rangle\\langle Z_1|\\otimes |Z_2\\rangle\\langle Z_2| \\cdots }^{N_A-2t+2 } \\otimes \\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1}\n\\]\n\nRDM has \\(2^{\\min(2t-2,N_A)}\\) non-zero eigenvalues all equal to \\(\\left(\\frac{1}{2}\\right)^{\\min(2t-2,N_A)}\\)\n\n\n\n\n\n\nDual unitary circuits were introduced in\n\nGopalakrishnan and Lamacraft for kicked Ising\nBertini, Kos, and Prosen in general\nPiroli et al discuss more general initial conditions"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#what-is-a-quantum-circuit",
    "href": "talks/quantum-circuits-1/index.html#what-is-a-quantum-circuit",
    "title": "Quantum Circuits",
    "section": "",
    "text": "A way to describe operations on quantum state, usually consisting of several qubits (spin 1/2 subsystems)\n\n\n\n\n\n\\(f\\) acts on top five qubits, then \\(g\\) acts on lower seven"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#possible-operations",
    "href": "talks/quantum-circuits-1/index.html#possible-operations",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Source: Wikipedia\n\n\n\n\\(H\\) (a Hadamard gate) is a single qubit unitary\nAlso two qubit unitary gates (CNOT here)\nMeasurements"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#why-consider-circuits",
    "href": "talks/quantum-circuits-1/index.html#why-consider-circuits",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Model of universal quantum computation\n\nHow to generate an arbitrary quantum state\nOne of several options e.g. measurement-based\n\nExample of discrete time, many body dynamics"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#unitary-circuits",
    "href": "talks/quantum-circuits-1/index.html#unitary-circuits",
    "title": "Quantum Circuits",
    "section": "",
    "text": "(Mostly) concerned with unitary circuits made from unitary gates\nGate is \\(n\\)-qubit unitary \\(U_{s_1\\ldots s_n,s'_1,\\ldots, s'_n}\\)\n\n$$ \\sum_{s_1'\\ldots s_N'}U_{s_1\\ldots s_n,s'_1,\\ldots, s'_n} U^\\dagger_{s'_1\\ldots s'_n,s''_1,\\ldots, s''_n}=\\delta_{s_1,s_1''}\\ldots \\delta_{s_N,s_N''} $$"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#everything-is-a-tensor",
    "href": "talks/quantum-circuits-1/index.html#everything-is-a-tensor",
    "title": "Quantum Circuits",
    "section": "",
    "text": "State of \\(N\\) qubits expressed in product basis\n\n$$ \\ket{\\Psi} = \\sum_{s_{1:N}\\in \\{0,1\\}^N} \\Psi_{s_1\\ldots s_N}\\ket{s_1}_1\\ket{s_2}_2\\cdots \\ket{s_N}_N $$\n\nWrite $\\ket{s_1}_1\\ket{s_2}_2\\cdots \\ket{s_N}_N =\\ket{s_1\\cdots s_N}=\\ket{s_{1:N}}$ for brevity\nOperator on \\(N\\) qubits has matrix elements\n\n$$ \\mathcal{O}_{s_{1:N},s'_{1:N}} = \\bra{s_{1:N}}\\mathcal{O}\\ket{s'_{1:N}} $$"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#graphical-notation",
    "href": "talks/quantum-circuits-1/index.html#graphical-notation",
    "title": "Quantum Circuits",
    "section": "",
    "text": "See Pan Zhang’s tutorial"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#unitary-gates-one-qubit",
    "href": "talks/quantum-circuits-1/index.html#unitary-gates-one-qubit",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Multiplication by a Pauli matrix: \\(X\\), \\(Y\\), or \\(Z\\).\nGeneral case \\(U = a_0\\mathbb{1} + \\vectorbold{a}\\cdot(X,Y,Z)\\) with \\(|a_0|^2+|\\vectorbold{a}|^2=1\\)\nOther special cases used in quantum information e.g. Hadamard gate $$ H = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 & 1 \\\\ 1 & -1 \\end{pmatrix} $$"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#two-qubits",
    "href": "talks/quantum-circuits-1/index.html#two-qubits",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Usually write in basis \\(\\ket{00}\\), \\(\\ket{01}\\), \\(\\ket{10}\\), \\(\\ket{11}\\)\nSimplest example: SWAP gate $$ \\operatorname{SWAP}=\\left[\\begin{array}{llll} 1 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\end{array}\\right] $$\nTakes product state to product state in computational basis\n\n\\[\n\\operatorname{SWAP}\\ket{10} = \\ket{01}\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#square-root-of-swap",
    "href": "talks/quantum-circuits-1/index.html#square-root-of-swap",
    "title": "Quantum Circuits",
    "section": "",
    "text": "$$ \\sqrt{\\operatorname{SWAP}}=\\left[\\begin{array}{cccc} 1 & 0 & 0 & 0 \\\\ 0 & \\frac{1}{2}(1+i) & \\frac{1}{2}(1-i) & 0 \\\\ 0 & \\frac{1}{2}(1-i) & \\frac{1}{2}(1+i) & 0 \\\\ 0 & 0 & 0 & 1 \\end{array}\\right] $$\n\nGenerates entanglement\n\n\\[\n\\sqrt{\\operatorname{SWAP}}\\ket{10} = \\frac{1}{2}\\left[(1+i)\\ket{10}+(1-i)\\ket{01}\\right]\n\\]\n\nConserves number of 1s and 0s (in fact fully rotationally invariant)\n\\(\\sqrt{\\operatorname{SWAP}}\\) and single qubit unitaries are universal gate set"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#general-two-qubit-unitary",
    "href": "talks/quantum-circuits-1/index.html#general-two-qubit-unitary",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Any two-qubit unitary \\(U\\in \\mathcal{U(4)}\\) can be written\n\n\\[\\begin{equation}\nU = e^{i \\phi} (u_+ \\otimes u_-) V[J_x, J_y, J_z] (v_- \\otimes v_+),\n\\end{equation}\\]\n\n\\(u_{\\pm}, v_{\\pm} \\in SU(2)\\)\n\n\\begin{align}  V[J_x, J_y, J_z] &= \\exp \\left[-i\\left(J_x \\sigma^x \\otimes \\sigma^x + J_y \\sigma^y \\otimes \\sigma^y+ J_z \\sigma^z \\otimes \\sigma^z\\right)\\right]\\\\  &= \\begin{bmatrix} e^{-i J_z} \\cos(J_-) & 0 & 0 & -i e^{-i J_z \\sin(J_-)} \\\\ 0 & e^{iJ_z} \\cos(J_+) & -ie^{i J_z} \\sin(J_+) & 0 \\\\ 0 & -ie^{i J_z} \\sin(J_+) & e^{iJ_z} \\cos(J_+) & 0 \\\\ -i e^{-i J_z \\sin(J_-)} & 0 & 0 & e^{-i J_z} \\cos(J_-) \\\\ \\end{bmatrix} \\end{align}\n\n16 parameters!"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#time-evolution-single-qubit-gates",
    "href": "talks/quantum-circuits-1/index.html#time-evolution-single-qubit-gates",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Time evolution operator \\(U=\\exp(-iHt)\\)\nIf \\(H=\\sum_j h_j\\) a sum of single qubit terms\n\n\\[\nU = \\exp(-iHt) = \\prod_j \\exp(-ih_j) = \\prod_j U_j\n\\] \\[\nU_j=\\mathbb{1}\\otimes \\ldots \\otimes\\mathbb{1} \\otimes \\overbrace{u_j}^{j\\text{th factor}} \\ldots \\otimes\\mathbb{1}\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#two-qubit-gates",
    "href": "talks/quantum-circuits-1/index.html#two-qubit-gates",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Simplest example of two qubit interaction is exchange Hamiltonian\n\n$$ \\begin{align} h_{12} &= J\\left[X\\otimes X+Y\\otimes Y+Z\\otimes Z\\right] =J\\left[X_1X_2+Y_1Y_2 + Z_1Z_2\\right]\\\\ &=2\\operatorname{SWAP} - 1 \\end{align} $$ $$ U(J) = \\exp(-ih_{12}) = e^{iJ}\\left[\\cos (2J) \\mathbb{1} - i\\sin (2J) \\operatorname{SWAP}\\right] $$\n\nSpecial cases\n\n\\[\nU(\\pi/4)=\\operatorname{SWAP}\n\\] \\[\nU(\\pi/8)=\\sqrt{\\operatorname{SWAP}}\n\\]\n\n\n\\(H=\\sum_{i,j} h_{i,j}\\) a sum of two qubit terms with \\([h_{i,j},h_{j,k}]\\neq 0\\)\n\\(U\\neq \\prod_{i,j} \\exp(-ih_{i,j})\\). More complicated!\nSuzuki–Trotter expansion: decompose \\(H=H_A + H_B\\)\n\n\\[\nU = \\exp(-iH) = \\left[\\exp\\left(-\\frac{iH}{n}\\right)\\right]^n \\sim \\left[e^{-iH_A/n} e^{-iH_B/n}\\right]^n\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#time-evolution-of-chain",
    "href": "talks/quantum-circuits-1/index.html#time-evolution-of-chain",
    "title": "Quantum Circuits",
    "section": "",
    "text": "\\[\nH = \\sum_j h_{j,j+1}\n\\] \\[\nH_A = \\sum_j h_{2j, 2j+1}\\qquad H_B = \\sum_j h_{2j-1, 2j}\n\\] \\[\ne^{-iH_A/n}=\\prod_j U_{2j,2j+1}\\qquad e^{-iH_B/n} = \\prod_j U_{2j-1,2j}\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#floquet-theory-kicked-ising-model",
    "href": "talks/quantum-circuits-1/index.html#floquet-theory-kicked-ising-model",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Time dependent Hamiltonian with kicks at \\(t=0,1,2,\\ldots\\).\n\n$$ \\begin{aligned} H_{\\text{KIM}}(t) = H_\\text{I}[\\mathbf{h}] + \\sum_{m}\\delta(t-n)H_\\text{K}\\\\ H_\\text{I}[\\mathbf{h}]=\\sum_{j=1}^L\\left[J Z_j Z_{j+1} + h_j Z_j\\right],\\qquad H_\\text{K} &= b\\sum_{j=1}^L X_j, \\end{aligned} $$\n\n“Stroboscopic” form of \\(U(t)=\\mathcal{T}\\exp\\left[-i\\int^t H_{\\text{KIM}}(t') dt'\\right]\\)\n\n$$ \\begin{aligned}   U(n_+) &= \\left[U(1_+)\\right]^n,\\qquad U(1_-) = K I_\\mathbf{h}\\\\   I_\\mathbf{h} &= e^{-iH_\\text{I}[\\mathbf{h}]}, \\qquad K = e^{-iH_\\text{K}} \\end{aligned} $$"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#kim-as-a-circuit",
    "href": "talks/quantum-circuits-1/index.html#kim-as-a-circuit",
    "title": "Quantum Circuits",
    "section": "",
    "text": "$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]. \\end{aligned} $$"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#locality-as-a-feature-of-real-circuits",
    "href": "talks/quantum-circuits-1/index.html#locality-as-a-feature-of-real-circuits",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Google Sycamore processor"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#hype",
    "href": "talks/quantum-circuits-1/index.html#hype",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Sampling from circuits basis of Google’s “quantum supremacy”"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#brickwork-unitary-circuits",
    "href": "talks/quantum-circuits-1/index.html#brickwork-unitary-circuits",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Have causality built in\n\n\n\nMore complicated tensor networks → more complicated spacetimes (black holes, AdS, etc.)\n\n\n\n\nSource: Quantum Frontiers"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#computational-complexity",
    "href": "talks/quantum-circuits-1/index.html#computational-complexity",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Normally matrix-vector multiplication is \\(O(\\operatorname{dim}^2)=2^{2N}\\)\nGates are sparse so \\(O(\\operatorname{dim})=2^{N}\\), but still exponentially hard\nFor low depth \\(T&lt;N\\) move horizontally instead"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#expectation-values",
    "href": "talks/quantum-circuits-1/index.html#expectation-values",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Evaluate \\(\\bra{\\Psi}\\mathcal{O}\\ket{\\Psi}=\\bra{\\Psi_0}U^\\dagger\\mathcal{O}U\\ket{\\Psi_0}\\) for local \\(\\mathcal{O}\\)\nIf \\(\\Psi_0\\) is product state top and bottom indices match"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#folded-picture",
    "href": "talks/quantum-circuits-1/index.html#folded-picture",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Recall unitary condtion\n\n\n\n\n\n\nAfter folding lines correspond to two indices / 4 dimensions\nSemicircle denotes \\(\\delta_{ab}\\)"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#brapsimathcaloketpsi-in-folded-picture",
    "href": "talks/quantum-circuits-1/index.html#brapsimathcaloketpsi-in-folded-picture",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Emergence of “light cone”"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#reduced-density-matrix",
    "href": "talks/quantum-circuits-1/index.html#reduced-density-matrix",
    "title": "Quantum Circuits",
    "section": "",
    "text": "\\[\n\\rho_A = \\operatorname{tr}_B\\left[\\ket{\\Psi}\\bra{\\Psi}\\right]=\\operatorname{tr}_B\\left[U\\ket{\\Psi_0}\\bra{\\Psi_0}U^\\dagger\\right]\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#schmidt-decomposition",
    "href": "talks/quantum-circuits-1/index.html#schmidt-decomposition",
    "title": "Quantum Circuits",
    "section": "",
    "text": "In $\\mathcal{H}=\\mathcal{H}_A\\otimes\\mathcal{H}_B$ any state $\\Psi_{AB}$ can be written\n\n$$ \\ket{\\Psi_{AB}} = \\sum_{\\alpha=1}^{\\min(\\operatorname{dim} \\mathcal{H}_A, \\operatorname{dim} \\mathcal{H}_B)} \\lambda_\\alpha \\ket{u_\\alpha}_A\\otimes\\ket{v_\\alpha}_B $$\n\n\\(\\ket{u_\\alpha}\\) and \\(\\ket{v_\\alpha}\\) orthonormal; \\(\\lambda_\\alpha\\geq 0\\)\n\\(\\lambda_\\alpha\\) quantify entanglement between A and B"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#apply-to-reduced-density-matrix",
    "href": "talks/quantum-circuits-1/index.html#apply-to-reduced-density-matrix",
    "title": "Quantum Circuits",
    "section": "",
    "text": "$$ \\begin{align} \\rho_A &= \\operatorname{tr}_B\\left[\\ket{\\Psi}\\bra{\\Psi}\\right] \\\\ &= \\sum_\\alpha \\lambda_\\alpha^2 \\ket{u_\\alpha}\\bra{u_\\alpha} \\end{align} $$\n\n\\(p_\\alpha\\equiv \\lambda_\\alpha^2\\) are the eigenvalues of \\(\\rho_A\\)"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#schmidt-rank",
    "href": "talks/quantum-circuits-1/index.html#schmidt-rank",
    "title": "Quantum Circuits",
    "section": "",
    "text": "\\(\\operatorname{rank}=\\min(\\operatorname{dim} \\mathcal{H}_A, \\operatorname{dim} \\mathcal{H}_B)=2^{\\min(2t-2, N_A)}\\)\nHere \\(t=4\\), \\(N_A=4\\)"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#entanglement-entropy",
    "href": "talks/quantum-circuits-1/index.html#entanglement-entropy",
    "title": "Quantum Circuits",
    "section": "",
    "text": "von Neumann entropy of \\(\\rho_A\\)\n\n$$ \\begin{align} S_A &= -\\operatorname{tr}\\left[\\rho_A\\log \\rho_A\\right]\\\\ &=-\\sum_\\alpha p_\\alpha \\log p_\\alpha \\end{align} $$\n\nMaximum value for equal probabilities \\(p_\\alpha = \\frac{1}{2^{\\min(2t-2, N_A)}}\\)\n\n\\[\nS_A \\leq \\min(2t-2, N_A)\\log 2\n\\]\n\n\n\n\nBertini, Kos, Prosen (2019) found that when \\(|J|=|b|=\\pi/4\\)\n\n\\[\n\\lim_{L\\to\\infty} S_A =\\min(2t-2,N_A)\\log 2,\n\\]\n\nAny \\(h_j\\); initial \\(Z_j\\) product state"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#entanglement-spectrum",
    "href": "talks/quantum-circuits-1/index.html#entanglement-spectrum",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Rényi entropies depend on eigenvalues of reduced density matrix\n\n$$   S^{(n)}_A = \\frac{1}{1-n}\\log \\text{tr}\\left[\\rho^n\\right]=\\frac{1}{1-n}\\sum_\\alpha p_\\alpha^n $$\n\nFor SDKIM have \\(2^{\\min(2t-2,N_A)}\\) non-zero eigenvalues all equal\n\n\\[\np_\\alpha = \\left(\\frac{1}{2}\\right)^{\\min(2t-2,N_A)}\n\\]"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#thermalization",
    "href": "talks/quantum-circuits-1/index.html#thermalization",
    "title": "Quantum Circuits",
    "section": "",
    "text": "After \\(N_A/2 + 1\\) steps, reduced density matrix is \\(\\propto \\mathbb{1}\\)\nAll expectations (with \\(A\\)) take on infinite temperature value"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#dual-unitarity",
    "href": "talks/quantum-circuits-1/index.html#dual-unitarity",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Recall KIM has circuit representation\n\n\n\n\n$$ \\begin{aligned}   \\mathcal{K} &= \\exp\\left[-i b X\\right]\\\\   \\mathcal{I} &= \\exp\\left[-iJ Z_1 Z_2 -i \\left(h_1 Z_1 + h_2 Z_2\\right)/2\\right]. \\end{aligned} $$\n\n\nAt \\(|J|=|b|=\\pi/4\\) has additional property of dual unitarity"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#kim-property",
    "href": "talks/quantum-circuits-1/index.html#kim-property",
    "title": "Quantum Circuits",
    "section": "",
    "text": "(\\(q=2\\) here) Not satisfied by e.g. \\(\\operatorname{SWAP}\\)"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#rho_a-via-dual-unitarity-kim",
    "href": "talks/quantum-circuits-1/index.html#rho_a-via-dual-unitarity-kim",
    "title": "Quantum Circuits",
    "section": "",
    "text": "RDM is unitary transformation of\n\n\\[\n\\rho_0=\\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1} \\otimes\\overbrace{|Z_1\\rangle\\langle Z_1|\\otimes |Z_2\\rangle\\langle Z_2| \\cdots }^{N_A-2t+2 } \\otimes \\overbrace{\\frac{\\mathbb{1}}{2}\\otimes \\frac{\\mathbb{1}}{2} \\cdots }^{t-1}\n\\]\n\nRDM has \\(2^{\\min(2t-2,N_A)}\\) non-zero eigenvalues all equal to \\(\\left(\\frac{1}{2}\\right)^{\\min(2t-2,N_A)}\\)"
  },
  {
    "objectID": "talks/quantum-circuits-1/index.html#further-reading",
    "href": "talks/quantum-circuits-1/index.html#further-reading",
    "title": "Quantum Circuits",
    "section": "",
    "text": "Dual unitary circuits were introduced in\n\nGopalakrishnan and Lamacraft for kicked Ising\nBertini, Kos, and Prosen in general\nPiroli et al discuss more general initial conditions"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Quarto and Pyodide\n\n\n\n\n\n\ntech\n\n\n\n\n\n\n\n\n\nJun 24, 2024\n\n\nAusten Lamacraft\n\n\n\n\n\n\n\n\n\n\n\n\nTrying Out Typst\n\n\n\n\n\n\ntech\n\n\n\n\n\n\n\n\n\nJun 24, 2024\n\n\nAusten Lamacraft\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning and Statistical Mechanics II\n\n\n\n\n\n\nML\n\n\nPhysics\n\n\n\n\n\n\n\n\n\nMay 25, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning and Statistical Mechanics I\n\n\n\n\n\n\nML\n\n\nPhysics\n\n\n\n\n\n\n\n\n\nMay 19, 2021\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/qpl-2024/index.html#d-lattice",
    "href": "talks/qpl-2024/index.html#d-lattice",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "1D Lattice",
    "text": "1D Lattice"
  },
  {
    "objectID": "talks/qpl-2024/index.html#local-unitary-dynamics",
    "href": "talks/qpl-2024/index.html#local-unitary-dynamics",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Local unitary dynamics",
    "text": "Local unitary dynamics"
  },
  {
    "objectID": "talks/qpl-2024/index.html#unitary-circuits-1",
    "href": "talks/qpl-2024/index.html#unitary-circuits-1",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Unitary circuits",
    "text": "Unitary circuits"
  },
  {
    "objectID": "talks/qpl-2024/index.html#heterogenous-biunitary-cicuits",
    "href": "talks/qpl-2024/index.html#heterogenous-biunitary-cicuits",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Heterogenous biunitary cicuits",
    "text": "Heterogenous biunitary cicuits\n\nWe can vary the shading pattern…\n\n\n\n…by introducing new elements\n\n\n\n\n\n\n\nBiunitarity implies that these vertices correspond to quantum Latin squares\nMatrix of vectors U_{a,b} with every row and column forming orthonormal basis"
  },
  {
    "objectID": "talks/qpl-2024/index.html#heterogenous-biunitary-cicuits-1",
    "href": "talks/qpl-2024/index.html#heterogenous-biunitary-cicuits-1",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Heterogenous biunitary cicuits",
    "text": "Heterogenous biunitary cicuits\n\nIntroducing additional shading patterns\n\n\n\n\n\n\n\n\n\n…by introducing new elements"
  },
  {
    "objectID": "talks/qpl-2024/index.html#quantum-latin-squares",
    "href": "talks/qpl-2024/index.html#quantum-latin-squares",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Quantum latin squares1",
    "text": "Quantum latin squares1\n\nVertical unitarity determines the properties of the rows\n\n\n\n\n\n\n\nHoritzontal unitarity fixes same property for the columns\n\nD. J. Reutter and J. Vicary, Higher Structures 3, 109 (2019)"
  },
  {
    "objectID": "talks/qpl-2024/index.html#heterogenous-biunitary-cicuits-with-qlss",
    "href": "talks/qpl-2024/index.html#heterogenous-biunitary-cicuits-with-qlss",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Heterogenous biunitary cicuits with QLSs",
    "text": "Heterogenous biunitary cicuits with QLSs"
  },
  {
    "objectID": "talks/qpl-2024/index.html#complex-hadamard-matrices",
    "href": "talks/qpl-2024/index.html#complex-hadamard-matrices",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Complex Hadamard matrices",
    "text": "Complex Hadamard matrices\n\nA biunitary with two opposite shaded regions\n\n\n\n\n\n\n\nCorresponds to complex Hadamard matrix: U^\\dagger U = U U^\\dagger = q\\mathbb{1}, |U_{a,b}|=1\nRepresents either one-site unitary or two-site controlled phase"
  },
  {
    "objectID": "talks/qpl-2024/index.html#classification-of-biunitaries",
    "href": "talks/qpl-2024/index.html#classification-of-biunitaries",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Classification of biunitaries",
    "text": "Classification of biunitaries\n\n\n\n\nDual-unitary gates\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantum crosses\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantum Latin squares\n\n\n\n\n\n\n\n\n\n\n\n\n\nComplex Hadamard matrices\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnitary error bases"
  },
  {
    "objectID": "talks/qpl-2024/index.html#zoo-of-biunitary-circuits",
    "href": "talks/qpl-2024/index.html#zoo-of-biunitary-circuits",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Zoo of biunitary circuits",
    "text": "Zoo of biunitary circuits"
  },
  {
    "objectID": "talks/qpl-2024/index.html#complex-hadamard-circuits",
    "href": "talks/qpl-2024/index.html#complex-hadamard-circuits",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Complex Hadamard circuits",
    "text": "Complex Hadamard circuits\n\nConstruct circuit exclusively out of complex Hadamard matrices\n\n\n\n\n\n\n\nDepending on unit cell, can be interpreted as brickwork…"
  },
  {
    "objectID": "talks/qpl-2024/index.html#compositions",
    "href": "talks/qpl-2024/index.html#compositions",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Compositions1",
    "text": "Compositions1\n\n\n\n\n\n\n\nQLS + QLS = Dual unitary\n\n\n\n\n\n\n\nQLS + QLS = Quantum cross\n\n\n\n\n\n\n\n\n\nHad + Had = QLS\n\n\n\n\n\n\n\nUEB + UEB = QLS\n\n\n\n\n\nD. J. Reutter and J. Vicary, Higher Structures 3, 109 (2019)"
  },
  {
    "objectID": "talks/qpl-2024/index.html#solvable-tensors",
    "href": "talks/qpl-2024/index.html#solvable-tensors",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Solvable tensors",
    "text": "Solvable tensors\n\nStart from tensor with arbitrary shading pattern\n\n\n\n\n\n\n\nSatisfies notion of horizontal unitarity"
  },
  {
    "objectID": "talks/qpl-2024/index.html#entanglement-dynamics",
    "href": "talks/qpl-2024/index.html#entanglement-dynamics",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Entanglement dynamics",
    "text": "Entanglement dynamics\n\nInitial state constructed from solvable tensors\n\n\n\nEvolve using biunitary circuit"
  },
  {
    "objectID": "talks/qpl-2024/index.html#reduced-density-matrix",
    "href": "talks/qpl-2024/index.html#reduced-density-matrix",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Reduced density matrix",
    "text": "Reduced density matrix\n\n\\rho_A(t)=\\operatorname{tr}_{\\bar A}\\left[\\ket{\\Psi(t,\\mathcal{N})}\\bra\\Psi(t,\\mathcal{N})\\right]"
  },
  {
    "objectID": "talks/qpl-2024/index.html#unitary-circuits",
    "href": "talks/qpl-2024/index.html#unitary-circuits",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Unitary circuits",
    "text": "Unitary circuits\n\n\n\nAdd explicit expression for contraction"
  },
  {
    "objectID": "talks/qpl-2024/index.html#outline",
    "href": "talks/qpl-2024/index.html#outline",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Outline",
    "text": "Outline\n\nDual-unitary circuits\nShaded calculus\nBiunitary circuits\nSolvable states"
  },
  {
    "objectID": "talks/qpl-2024/index.html#causal-light-cone",
    "href": "talks/qpl-2024/index.html#causal-light-cone",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Causal light cone",
    "text": "Causal light cone"
  },
  {
    "objectID": "talks/qpl-2024/index.html#dual-unitary-circuits",
    "href": "talks/qpl-2024/index.html#dual-unitary-circuits",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Dual unitary circuits",
    "text": "Dual unitary circuits\n\nWhat if propagation in space direction also unitary?\n\n\n\nIntroduce dual unitary gates"
  },
  {
    "objectID": "talks/qpl-2024/index.html#du-motivation",
    "href": "talks/qpl-2024/index.html#du-motivation",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "DU: Motivation",
    "text": "DU: Motivation\n\nDU circuits are a minimal model of local and unitary many-body dynamics with many interesting properties\nExact solvability\nMaximally chaotic\nMaximal entanglement velocity: Entanglement spreads at fastest possible rate"
  },
  {
    "objectID": "talks/qpl-2024/index.html#dual-unitarity-from-biunitarity",
    "href": "talks/qpl-2024/index.html#dual-unitarity-from-biunitarity",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Dual unitarity from biunitarity",
    "text": "Dual unitarity from biunitarity"
  },
  {
    "objectID": "talks/qpl-2024/index.html#dual-unitarity-from-biunitarity-1",
    "href": "talks/qpl-2024/index.html#dual-unitarity-from-biunitarity-1",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Dual unitarity from biunitarity",
    "text": "Dual unitarity from biunitarity"
  },
  {
    "objectID": "talks/qpl-2024/index.html#dual-unitarity-from-biunitarity-du-gates",
    "href": "talks/qpl-2024/index.html#dual-unitarity-from-biunitarity-du-gates",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Dual unitarity from biunitarity: DU gates",
    "text": "Dual unitarity from biunitarity: DU gates"
  },
  {
    "objectID": "talks/qpl-2024/index.html#dual-unitarity-from-biunitarity-du-clockwork",
    "href": "talks/qpl-2024/index.html#dual-unitarity-from-biunitarity-du-clockwork",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Dual unitarity from biunitarity: DU clockwork",
    "text": "Dual unitarity from biunitarity: DU clockwork\n\n\n\n\n\n\n\\sum_e (U_{a,c})^\\dagger_{b,e} (U_{a,c})^\\dagger_{e,d} = \\delta_{bd}"
  },
  {
    "objectID": "talks/qpl-2024/index.html#biunitary-circuits",
    "href": "talks/qpl-2024/index.html#biunitary-circuits",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Biunitary circuits",
    "text": "Biunitary circuits\n\nWe consider lattices where every vertex is biunitary\n\n\n\nGray background = region can be shaded or not"
  },
  {
    "objectID": "talks/qpl-2024/index.html#dynamics-of-correlation-functions",
    "href": "talks/qpl-2024/index.html#dynamics-of-correlation-functions",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Dynamics of correlation functions",
    "text": "Dynamics of correlation functions\n\nProof from dual-unitarity directly extends to biunitary circuits\n\n\n\n\n\n\n\nVertical unitarity implies causal light cone"
  },
  {
    "objectID": "talks/qpl-2024/index.html#dynamics-of-correlation-functions-1",
    "href": "talks/qpl-2024/index.html#dynamics-of-correlation-functions-1",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Dynamics of correlation functions",
    "text": "Dynamics of correlation functions\n\nProof from dual-unitarity directly extends to biunitary circuits\n\n\n\n\n\n\n\nVertical unitarity implies causal light cone"
  },
  {
    "objectID": "talks/qpl-2024/index.html#dynamics-of-correlation-functions-2",
    "href": "talks/qpl-2024/index.html#dynamics-of-correlation-functions-2",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Dynamics of correlation functions",
    "text": "Dynamics of correlation functions\n\nProof from dual-unitarity directly extends to biunitary circuits\n\n\n\n\n\n\n\nVertical unitarity implies causal light cone"
  },
  {
    "objectID": "talks/qpl-2024/index.html#dynamics-of-correlation-functions-3",
    "href": "talks/qpl-2024/index.html#dynamics-of-correlation-functions-3",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Dynamics of correlation functions",
    "text": "Dynamics of correlation functions\n\nProof from dual-unitarity directly extends to biunitary circuits\n\n\n\n\n\n\n\nNow using horizontal unitarity…"
  },
  {
    "objectID": "talks/qpl-2024/index.html#dynamics-of-correlation-functions-4",
    "href": "talks/qpl-2024/index.html#dynamics-of-correlation-functions-4",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Dynamics of correlation functions",
    "text": "Dynamics of correlation functions\n\nProof from dual-unitarity directly extends to biunitary circuits\n\n\n\n\n\n\n\nNow using horizontal unitarity…"
  },
  {
    "objectID": "talks/qpl-2024/index.html#dynamics-of-correlation-functions-5",
    "href": "talks/qpl-2024/index.html#dynamics-of-correlation-functions-5",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Dynamics of correlation functions",
    "text": "Dynamics of correlation functions\n\nProof from dual-unitarity directly extends to biunitary circuits\n\n\n\n\n\n\n\nNow using horizontal unitarity…"
  },
  {
    "objectID": "talks/qpl-2024/index.html#dynamics-of-correlation-functions-6",
    "href": "talks/qpl-2024/index.html#dynamics-of-correlation-functions-6",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Dynamics of correlation functions",
    "text": "Dynamics of correlation functions\n\nProof from dual-unitarity directly extends to biunitary circuits\n\n\n\n\n\n\n\n…correlations vanish inside the light cone"
  },
  {
    "objectID": "talks/qpl-2024/index.html#light-cone-dynamics",
    "href": "talks/qpl-2024/index.html#light-cone-dynamics",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Light-cone dynamics",
    "text": "Light-cone dynamics\n\nLight-cone correlation functions can be efficiently calculated\n\n\n\n\n\n\n\n… in the exact same way as for dual-unitarity"
  },
  {
    "objectID": "talks/qpl-2024/index.html#light-cone-dynamics-1",
    "href": "talks/qpl-2024/index.html#light-cone-dynamics-1",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Light-cone dynamics",
    "text": "Light-cone dynamics\n\nLight-cone correlation functions can be efficiently calculated\n\n\n\n\n\n\n\n… in the exact same way as for dual-unitarity"
  },
  {
    "objectID": "talks/qpl-2024/index.html#light-cone-dynamics-2",
    "href": "talks/qpl-2024/index.html#light-cone-dynamics-2",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Light-cone dynamics",
    "text": "Light-cone dynamics\n\nLight-cone correlation functions can be efficiently calculated\n\n\n\n\n\n\n\n… in the exact same way as for dual-unitarity"
  },
  {
    "objectID": "talks/qpl-2024/index.html#complex-hadamard-circuits-1",
    "href": "talks/qpl-2024/index.html#complex-hadamard-circuits-1",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Complex Hadamard circuits",
    "text": "Complex Hadamard circuits\n\nConstruct circuit exclusively out of complex Hadamard matrices\n\n\n\n\n\n\n\n… or clockwork\n\n\n\n\n\n\n\nBiunitaries combine into biunitaries!"
  },
  {
    "objectID": "talks/qpl-2024/index.html#dual-unitarity-round-a-face",
    "href": "talks/qpl-2024/index.html#dual-unitarity-round-a-face",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Dual unitarity round-a-face",
    "text": "Dual unitarity round-a-face"
  },
  {
    "objectID": "talks/qpl-2024/index.html#shaded-tensor-networks",
    "href": "talks/qpl-2024/index.html#shaded-tensor-networks",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Shaded tensor networks",
    "text": "Shaded tensor networks"
  },
  {
    "objectID": "talks/qpl-2024/index.html#solvable-states",
    "href": "talks/qpl-2024/index.html#solvable-states",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Solvable states",
    "text": "Solvable states\n\nDynamics so far restricted to initial (ultralocal) operators\nWhat about initial states?\nClass of solvable matrix product states introduced by Piroli et al.1\n\n\n\nConsistent with dual-unitarity if \\mathcal{N} satisfies some (graphical) identities\n\nPhys. Rev. B 101, 094304 (2020)"
  },
  {
    "objectID": "talks/qpl-2024/index.html#ordinary-tensor-network",
    "href": "talks/qpl-2024/index.html#ordinary-tensor-network",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "“Ordinary” tensor network",
    "text": "“Ordinary” tensor network"
  },
  {
    "objectID": "talks/qpl-2024/index.html#reduced-density-matrix-1",
    "href": "talks/qpl-2024/index.html#reduced-density-matrix-1",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Reduced density matrix",
    "text": "Reduced density matrix\n\n\\rho_A(t)=\\operatorname{tr}_{\\bar A}\\left[\\ket{\\Psi(t,\\mathcal{N})}\\bra\\Psi(t,\\mathcal{N})\\right]"
  },
  {
    "objectID": "talks/qpl-2024/index.html#reduced-density-matrix-2",
    "href": "talks/qpl-2024/index.html#reduced-density-matrix-2",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Reduced density matrix",
    "text": "Reduced density matrix\n\n\\rho_A(t)=\\operatorname{tr}_{\\bar A}\\left[\\ket{\\Psi(t,\\mathcal{N})}\\bra\\Psi(t,\\mathcal{N})\\right]"
  },
  {
    "objectID": "talks/qpl-2024/index.html#reduced-density-matrix-3",
    "href": "talks/qpl-2024/index.html#reduced-density-matrix-3",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Reduced density matrix",
    "text": "Reduced density matrix\n\n\\rho_A(t)=\\operatorname{tr}_{\\bar A}\\left[\\ket{\\Psi(t,\\mathcal{N})}\\bra\\Psi(t,\\mathcal{N})\\right]"
  },
  {
    "objectID": "talks/qpl-2024/index.html#reduced-density-matrix-4",
    "href": "talks/qpl-2024/index.html#reduced-density-matrix-4",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Reduced density matrix",
    "text": "Reduced density matrix\n\n\\rho_A(t)=\\operatorname{tr}_{\\bar A}\\left[\\ket{\\Psi(t,\\mathcal{N})}\\bra\\Psi(t,\\mathcal{N})\\right]"
  },
  {
    "objectID": "talks/qpl-2024/index.html#reduced-density-matrix-5",
    "href": "talks/qpl-2024/index.html#reduced-density-matrix-5",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Reduced density matrix",
    "text": "Reduced density matrix\n\n\\rho_A(t)=\\operatorname{tr}_{\\bar A}\\left[\\ket{\\Psi(t,\\mathcal{N})}\\bra\\Psi(t,\\mathcal{N})\\right]\n\n\n\n\n\n\n\nBiunitary circuits exactly thermalize \\rho_A(t\\geq |A|/2)\\propto \\mathbb{1}"
  },
  {
    "objectID": "talks/qpl-2024/index.html#maximal-entanglement-entropy-growth",
    "href": "talks/qpl-2024/index.html#maximal-entanglement-entropy-growth",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Maximal entanglement entropy growth",
    "text": "Maximal entanglement entropy growth"
  },
  {
    "objectID": "talks/qpl-2024/index.html#solvable-initial-states",
    "href": "talks/qpl-2024/index.html#solvable-initial-states",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Solvable initial states",
    "text": "Solvable initial states\n\nNo shading: returns solvable matrix product state of Piroli et al.1\n\n\n\n\n\n\n\n\nFully shaded = new solvable initial state for clockwork circuits\n\n\n\n\n\n\nPhys. Rev. B 101, 094304 (2020)"
  },
  {
    "objectID": "talks/qpl-2024/index.html#solvable-initial-states-1",
    "href": "talks/qpl-2024/index.html#solvable-initial-states-1",
    "title": "From Dual Unitarity to Biunitarity",
    "section": "Solvable initial states",
    "text": "Solvable initial states\n\n\n\n\n\n\nHorizontal unitarity corresponds to unitarity of \\mathcal{N}^{(b)}"
  }
]