<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2021-05-19">

<title>Austen Lamacraft - Machine Learning and Statistical Mechanics I</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Austen Lamacraft</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../talks.html"> 
<span class="menu-text">Talks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../cv.pdf"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/AustenLamacraft"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/AustenLamacraft"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Machine Learning and Statistical Mechanics I</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">ML</div>
                <div class="quarto-category">Physics</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Austen Lamacraft </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 19, 2021</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#probability-in-statistical-mechanics" id="toc-probability-in-statistical-mechanics" class="nav-link active" data-scroll-target="#probability-in-statistical-mechanics">Probability in Statistical Mechanics</a></li>
  <li><a href="#probability-in-machine-learning" id="toc-probability-in-machine-learning" class="nav-link" data-scroll-target="#probability-in-machine-learning">Probability in Machine Learning</a></li>
  <li><a href="#lecture-1-fundamentals" id="toc-lecture-1-fundamentals" class="nav-link" data-scroll-target="#lecture-1-fundamentals">Lecture 1: Fundamentals</a>
  <ul class="collapse">
  <li><a href="#some-mathematical-background" id="toc-some-mathematical-background" class="nav-link" data-scroll-target="#some-mathematical-background">Some mathematical background</a></li>
  <li><a href="#variational-inference-vi" id="toc-variational-inference-vi" class="nav-link" data-scroll-target="#variational-inference-vi">Variational inference (VI)</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>In these lectures we are going to explore some connections between machine learning (ML) and (classical) statistical mechanics (SM). To be precise, we are going to see how the appearance of <em>probabilistic models</em> with <em>large numbers of variables</em> in both fields means that certain theoretical concepts and tools can be applied in both. To get things going, let’s see how this probabilistic viewpoint arises in the two settings.</p>
<p><span class="math display">\[
\DeclareMathOperator*{\E}{\mathbb{E}}
\newcommand{\cE}{\mathcal{E}}
\]</span></p>
<section id="probability-in-statistical-mechanics" class="level3">
<h3 class="anchored" data-anchor-id="probability-in-statistical-mechanics">Probability in Statistical Mechanics</h3>
<p>The basic problem of SM is to describe the thermodynamic properties of a macroscopic system <em>probabilistically</em> in terms its microscopic constituents.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note that we say <em>probabilistically</em>, not <em>statistically</em>. What’s the difference? In probability we have a definite model for randomness in mind (the Boltzmann distribution, say), whereas in statistics we are interested in inferring these probabilities from observation. Statistics is thus <a href="https://en.wikipedia.org/wiki/Inverse_probability">inverse probability</a>, and statistical mechanics is really a misnomer.</p>
</div>
</div>
<p>The probabilistic model is normally the Boltzmann distribution</p>
<p><span class="math display">\[
p(\mathbf{x})=\frac{\exp\left[-\beta \mathcal{E}(\mathbf{x})\right]}{Z},
\]</span></p>
<p>where <span class="math inline">\(Z\)</span> is a normalizing constant called the partition function, <span class="math inline">\(\mathcal{E}(\mathbf{x})\)</span> is the energy of the configuration <span class="math inline">\(\mathbf{x}\)</span>, and <span class="math inline">\(\beta=1/T\)</span> is the inverse temperature (setting the Boltzmann constant <span class="math inline">\(k_\text{B}=1\)</span>).</p>
<p>The <em>central problem</em> of statistical mechanics is computing ensemble averages of physical quantities, and the <em>principle difficulty</em> is the intractability of those averages for large systems. For example, if we are dealing with a classical gas, the configuration space point <span class="math inline">\(\mathbf{x}\)</span> corresponds to the positions of each of the gas molecules <span class="math inline">\(\mathbf{x}=(\mathbf{x}_1,\ldots \mathbf{x}_N)\)</span> and an average is a <span class="math inline">\(3N\)</span>-dimensional integral. The only situation in which this integral is tractable is when the gas is noninteracting (ideal), in which case the energy function takes the form</p>
<p><span class="math display">\[
\mathcal{E}(\mathbf{x}) = \sum_{n=1}^N \mathcal{E}_1(\mathbf{x}_n)
\]</span></p>
<p>where <span class="math inline">\(\mathcal{E}_1(\mathbf{x})\)</span> is the single particle energy. In this case the integral factorizes. As soon as we introduce interactions between particles of the form</p>
<p><span class="math display">\[
\mathcal{E}(\mathbf{x}) = \sum_{n&lt;m}^N \mathcal{E}_2(\mathbf{x}_n,\mathbf{x}_m)
\]</span></p>
<p>things get a lot harder. The same issue arises in models involving discrete random variables. The canonical example is the <a href="https://en.wikipedia.org/wiki/Ising_model">Ising model</a>, in which a configuration corresponds to fixing the values of <span class="math inline">\(N\)</span> “spins” <span class="math inline">\(\sigma_n=\pm 1\)</span> with an energy function of the form</p>
<p><span class="math display">\[
\mathcal{E}(\sigma)=\sum_n h_n\sigma_n + \sum_{n,m} J_{mn}\sigma_m\sigma_n.
\]</span></p>
<p>The two terms correspond to a (magnetic) field that acts on each spin and a coupling between spins. As in the gas, it’s the latter that causes problems / interest.</p>
<p>The Ising model comes in a great many flavours according to how the fields and couplings are chosen. They may reflect a lattice structure: <span class="math inline">\(J_{mn}\neq 0\)</span> for nearest neighbours, say, or longer range. They may be fixed or random, defining an ensemble of models. You’ve probably seen lots of examples already.</p>
<p>The most pessimistic assessment is that to calculate an average we are going to have sum over <span class="math inline">\(2^N\)</span> configurations. You probably know, however, that over the years physicists have developed lots of methods to solve the problem approximately, including mean field theory and Monte Carlo simulations. We’ll return to this stuff later.</p>
<p>If you ever find yourself talking to a probabilist, you may find it helpful to know that these kind of models are called (undirected) <a href="https://en.wikipedia.org/wiki/Graphical_model">graphical models</a>, because their probability distribution is defined by a graph, called a <a href="https://en.wikipedia.org/wiki/Factor_graph">factor graph</a>.</p>
</section>
<section id="probability-in-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="probability-in-machine-learning">Probability in Machine Learning</h3>
<p>What about ML? Let’s take computer vision, one of the problems in which ML has made great progress in recent years. A (static) image is defined by a set of <span class="math inline">\((R,G,B)\)</span> values at each pixel, each defined by eight bits i.e.&nbsp;an integer in <span class="math inline">\([0,255]\)</span>. The <strong>basic hypothesis</strong> on which probabilistic machine learning rests is that a dataset represents a set of independent and identically distributed (<strong>iid</strong>) samples of some random variables. In the case of an image, the random variables are the RGB values of all the pixels. The distribution of these variables has to be highly correlated and have a great deal of complex structure: rather than generating white noise for each sample we instead get (say) cats and dogs.</p>
<p>While this may seem like a funny way of thinking about a stack of photos it does conceptually have a lot in common with the way probability is often used in physics. After all, classical statistical mechanics is built on the notion that the motion of gas molecules is completely deterministic but incredibly complicated. While detailed knowledge of the dynamics is completely beyond our reach it is also irrelevant for the thermodynamic behaviour of interest: two boxes of gas behave in exactly the same way despite the underlying configurations of the molecules being completely different. Physics is used, however, to constrain our probability model. For example, collisions between molecules are elastic and momentum conserving.</p>
<p>The <strong>difference</strong> from the SM situation is that we don’t know the probability distribution up front. The goal is to <em>infer</em> the distribution from data. Conceptually then, probabilistic ML is the same as <a href="https://en.wikipedia.org/wiki/Statistical_inference">statistical inference</a>. The different terms mostly reflect the differing background of practitioners: ML comes from computer science; statistical inference from mathematics. It all comes down to the tools you use: in recent years probabilistic ML has made great strides using models based on neural networks together with the associated training algorithms, which have allowed very rich probability distributions, describing datasets of images or audio signals, to be successfully modelled.</p>
<!-- Should note that the iid assumption is clearly wrong -->
<!-- The tone will be theoretical.

Applications of probablistic ML

- Sampling (**generative modelling**)
- Density estimation
- Compression

Physics uses. Sampling, better MC, etc, etc.


Mention possibility of *synthetic data*.

Planted ensembles

- [ ] Contrast Ising model and pics of faces
- [ ] Not going to discuss supervised learning, labels and all that
- [ ] Refer to Alemi here? -->
</section>
<section id="lecture-1-fundamentals" class="level2">
<h2 class="anchored" data-anchor-id="lecture-1-fundamentals">Lecture 1: Fundamentals</h2>
<section id="some-mathematical-background" class="level3">
<h3 class="anchored" data-anchor-id="some-mathematical-background">Some mathematical background</h3>
<section id="probabilities-joint-and-conditional" class="level4">
<h4 class="anchored" data-anchor-id="probabilities-joint-and-conditional">Probabilities: joint and conditional</h4>
<p>Probabilities are real positive numbers <span class="math inline">\(p(x)\geq 0\)</span> satisfying</p>
<p><span class="math display">\[
\sum_x p(x)=1
\]</span></p>
<p>For continuous variables we have an integral of a probability density function</p>
<p><span class="math display">\[
\int p(x) dx=1,
\]</span></p>
<p>but for brevity we’ll use the discrete notation throughout.</p>
<p><strong>Joint probability</strong> distributions of several variables are denoted <span class="math inline">\(p(x_1,\ldots x_N)\)</span>. By summing over some subset of the variables, we arrive at a <strong>marginal distribution</strong> of the remaining variables:</p>
<p><span class="math display">\[
p(x)= \sum_{y} p(x,y).
\]</span></p>
<p>A related notion is the <strong>conditional probability</strong> <span class="math inline">\(p(x|y)\)</span>: the probability distribution of <span class="math inline">\(x\)</span> given a fixed value of random variable <span class="math inline">\(y\)</span>. The relation between joint and conditional probabilities is</p>
<p><span class="math display">\[
p(x,y)=p(x|y)p(y)
\tag{1}
\label{eq:joint}
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>We <em>should</em> write <span class="math inline">\(p_X(x)\)</span> for the distribution of random variable <span class="math inline">\(X\)</span> and <span class="math inline">\(p_Y(y)\)</span> for random variable <span class="math inline">\(Y\)</span>. Instead, we just let the name of the argument tell us it’s a different distribution. Everyone does this.</p>
</div>
</div>
<p>For a joint probability of many variables, we have</p>
<p><span class="math display">\[
p(x_1,\ldots x_N)=p(x_1)p(x_2|x_1)p(x_3|x_2,x_1)\cdots p(x_N|x_1,\ldots x_{N-1}),
\tag{2}
\label{eq:chain}
\]</span></p>
<p>which is sometimes called the <a href="https://en.wikipedia.org/wiki/Chain_rule_(probability)">chain rule of probability</a>. Although it’s always possible <em>in principle</em> to express a joint probability like this, there’s no guarantee it’s easy to do or useful. One situation in which one may expect it to be a convenient description is when there is a natural order to the variables. For example, words or characters in text or any kind of time series. In this case the model may still be useful if the conditional probabilities involve only a fixed number <span class="math inline">\(p\)</span> of the preceding variables, even as <span class="math inline">\(N\to\infty\)</span>. Such models are called <a href="https://en.wikipedia.org/wiki/Autoregressive_model">autoregressive</a>, although a physicist may be tempted to call them <em>causal</em>.</p>
<p>Sampling from a highly complex joint distribution <span class="math inline">\(p(x_1,\ldots x_N)\)</span> is generally difficult. One of the benefits of formulating a model as in <span class="math inline">\(\eqref{eq:chain}\)</span> is that producing samples is much easier. First you sample <span class="math inline">\(x_1\)</span> using <span class="math inline">\(p(\cdot)\)</span>, then sample <span class="math inline">\(x_2\)</span> using <span class="math inline">\(p(\cdot|x_1)\)</span>, and so on. You never have to sample more than one variable at once!</p>
</section>
<section id="priors-and-posteriors" class="level4">
<h4 class="anchored" data-anchor-id="priors-and-posteriors">Priors and posteriors</h4>
<p>Another way to express the joint probability <span class="math inline">\(\eqref{eq:joint}\)</span> is</p>
<p><span class="math display">\[
p(x,y)=p(y|x)p(x)
\]</span></p>
<p>We deduce <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes’ theorem</a></p>
<p><span class="math display">\[
p(y|x)=\frac{p(x|y)p(y)}{p(x)}
\]</span></p>
<p>Note that if we are dealing with continuous variables, any change in dimensions in going from a distribution over <span class="math inline">\(x\)</span> to a distribution over <span class="math inline">\(y\)</span> is handled by the ratio <span class="math inline">\(p(y)/p(x)\)</span>.</p>
<p>Bayes’ theorem is the workhorse of Bayesian statistics. The idea to to regard any parameters <span class="math inline">\(z\)</span> in your probability model as random variables taken from some initial distribution <span class="math inline">\(p(z)\)</span>, called the <strong>prior distribution</strong> (or just the <strong>prior</strong>).</p>
<blockquote class="blockquote">
<p><strong>Example</strong>: if your model distribution is a Gaussian normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, then your parameters are <span class="math inline">\(z=(\mu,\sigma^2)\)</span>. For a prior you could choose a normal distribution for <span class="math inline">\(\mu\)</span> with its own mean <span class="math inline">\(\mu_\mu\)</span> and variance <span class="math inline">\(\sigma^2_\mu\)</span> (we write <span class="math inline">\(\mu\sim \mathcal{N}(\mu_\mu,\sigma^2_\mu))\)</span>. For <span class="math inline">\(\sigma^2\)</span> you’d need a distribution of a positive quantity: the <a href="https://en.wikipedia.org/wiki/Inverse-gamma_distribution">inverse gamma distribution</a> is a popular choice.</p>
</blockquote>
<p>Once these parameters are fixed, you have a model distribution for your data that can be thought of as the conditional distribution <span class="math inline">\(p(x|z)\)</span>. What does an observation of <span class="math inline">\(x\)</span> tell me? Just use Bayes:</p>
<p><span class="math display">\[
p(z|x) = \frac{p(x|z)p(z)}{p(x)}.
\]</span></p>
<p>This is called the <strong>posterior distribution</strong> (or just <strong>posterior</strong>). Note that the denominator doesn’t depend on <span class="math inline">\(z\)</span>, it just provides a normalization. If you have lots of data points then</p>
<p><span class="math display">\[
p(z|x_1,\ldots x_N) \propto  p(x_1,\ldots x_N|z)p(z).
\]</span></p>
<p>Bayes’ theorem lets us update our beliefs about parameters based on our initial beliefs and any evidence we receive. This process is called <strong>inference</strong>.</p>
<!-- This feature of Bayesian statistics has led to a great many "thought leader" types describing themselves as Bayesians even though they wouldn't know their numerators from their denominators. -->
{{&lt; tweet 1325474361407660034 &gt;}}
<!-- In the real world, it's not that easy. You don't actually get the data distribution $p(x)$, but rather samples from it. Also, your model may not be good enough for the task in hand. We'll talk about how we deal with these issues shortly. -->
</section>
<section id="latent-variables-generative-models" class="level4">
<h4 class="anchored" data-anchor-id="latent-variables-generative-models">Latent variables; generative models</h4>
<p>Bayesian inference also underlies models involving <em>latent</em> (or hidden, or unobserved) variables. The idea here is that instead of the data telling us about the distribution of <span class="math inline">\(z\)</span>s whose values may describe the entire dataset i.e.&nbsp;<span class="math inline">\(p(x_1,\ldots x_N|z)\)</span>, we allow the <span class="math inline">\(z\)</span>s to have different distributions for different data points <span class="math inline">\(p(z_n|x_n)\)</span>. Equivalently, our model is defined by a joint distribution <span class="math inline">\(p(x,z)\)</span>.</p>
<p>The simplest example of a latent variable model is a <a href="https://en.wikipedia.org/wiki/Mixture_model">mixture model</a>, which describes a distribution of a variable <span class="math inline">\(x\)</span> as arising from <span class="math inline">\(M\)</span> different components, each with their own distribution <span class="math inline">\(p(x|m)\)</span> and occurring with probability <span class="math inline">\(p(m)\)</span>, so that</p>
<p><span class="math display">\[
p(x) = \sum_m p(m)p(x|m).
\]</span></p>
<p>An observation <span class="math inline">\(x\)</span> will give me information about <span class="math inline">\(p(m|x)\)</span>, telling which of the <span class="math inline">\(M\)</span> components that observation belongs to. This may bring insight, if the latent variables lend themselves to interpretation. Alternatively, it may simply give a more powerful model.</p>
<p>Latent variables are a route to perform <strong>structure learning</strong>: uncovering meaningful structures in the data. A lot of effort has gone into trying to build models that “discover” such structures automatically. For example, for a dataset of images of people walking we’d like to find latent variables parameterize a manifold of different poses.</p>
<p>Latent variable models are also the basis of <strong>generative modelling</strong>: sampling from a distribution <span class="math inline">\(p(x)\)</span> learnt from data. If the model has been formulated in terms of a prior <span class="math inline">\(p(z)\)</span> over latent variables and a generative model <span class="math inline">\(p(x|z)\)</span>, sampling is straightforward in principle.</p>
</section>
<section id="entropy" class="level4">
<h4 class="anchored" data-anchor-id="entropy">Entropy</h4>
<p>In SM we’re familiar with the entropy associated with a probability distribution. This quantity arrived in ML from information theory and is given the symbol <span class="math inline">\(H\)</span> (for <a href="https://en.wikipedia.org/wiki/Ralph_Hartley">Hartley</a>?)</p>
<p><span class="math display">\[
H[p]=- \sum_x p(x)\log_2p(x).
\]</span></p>
<p>Taking the logarithm base 2 means we measure in bits (the natural logarithm that is normally used for the Gibbs entropy is measured in “nats”). In the following we’ll normally drop the base.</p>
<p>There are lots of ways to think about the entropy so I’ll just describe one that’s quite useful in our setting. <!-- Suppose we have a $N$ samples from a uniform random distribution on $x$ (so strictly there will have to be a finite number of possible outcomes, but we can always take limits). What's the chance of observing the fractions $p(x)=N_x/N$? The chance of any set of values is just $1/|X|^N$, where $|X|$ is the number of possible outcomes, so to get the probability of the fractions $p(x)$ we multiply by the multinomial coefficient

$$
p(N_1,\ldots N_{|X|})= |X|^{-N}\frac{N!}{\prod_x N_x!}.
$$

Using Stirling's approximation $\log n! \sim n\log n -n$ gives, for large $N$

$$
p(N_1,\ldots N_{|X|})\sim|X|^{-N}2^{-N\sum_x p(x)\log_2 p(x)}=|X|^{-N}2^{NH[p]}.
$$

::: {.callout-note}
To see what $\sim$ means in this context note that when $p(x)=1/|X|$ (uniform distribution) the RHS is one, so this expression is missing a normalization factor (which you can get from a [better Stirling's approximation](https://en.wikipedia.org/wiki/Stirling%27s_approximation)), but that factor is not exponential in $N$, so we drop it.
:::

 The entropy is therefore a useful measure of **exponentially unlikely events**. If we divide a container of $N$ ideal gas molecules up into $|X|$ identical regions $x=1\,\ldots |X|$, the probability of finding a fraction of gas $p(x)$ in each region is $\propto 2^{NH[p]}$.  --> Suppose we have <span class="math inline">\(N\)</span> iid variables with distribution <span class="math inline">\(p(x)\)</span>. The probability of observing a sequence <span class="math inline">\(x_1,\ldots x_N\)</span> is</p>
<p><span class="math display">\[
\begin{equation}
p(x_1,\ldots x_N)=\prod_{n=1}^N p(x_n).
\end{equation}
\tag{3}
\label{eq:seq}
\]</span></p>
<p>This probability is obviously exponentially small as <span class="math inline">\(N\to\infty\)</span>, but how small? The answer is</p>
<p><span class="math display">\[
\lim_{N\to\infty} \frac{1}{N}\log p(x_1,\ldots x_N) = -H[p].
\]</span></p>
<p>This is called the <a href="https://en.wikipedia.org/wiki/Asymptotic_equipartition_property">asymptotic partition property</a>. It probably looks a bit strange. Shouldn’t the probability depend on what you actually get? After all, some outcomes <em>are</em> more likely than others. Suppose you have a biased coin that gives heads with probability <span class="math inline">\(p_H&gt;0.5\)</span> and tails with probability <span class="math inline">\(p_T=1-p_H\)</span>. In a very long sequence of tosses the chance of getting half heads and half tails becomes exponentially small. What you’re going to get instead is</p>
<p><span class="math display">\[
\frac{N_H}{N}\to p_H\qquad \frac{N_T}{N}\to p_T\qquad .
\]</span></p>
<p>What is the probability of such a sequence? From <span class="math inline">\(\eqref{eq:seq}\)</span> it is <span class="math inline">\(p_H^{N_H}p_T^{N_T}\)</span>, but this can be rewritten</p>
<p><span class="math display">\[
\log_2\left(p_H^{N_H}p_T^{N_T}\right)= N_H\log_2 p_H + N_T\log_2 p_T = -N H[p_H, p_T].
\]</span></p>
</section>
<section id="entropy-and-information" class="level4">
<h4 class="anchored" data-anchor-id="entropy-and-information">Entropy and information</h4>
<p>This property of entropy provides a way to quantify the amount of information in a signal. If the coin is <em>really</em> biased, returning a head almost every time, you won’t be surprised when you get heads, but will be surprised when you get tails. Note that the entropy of such a sequence is lower than for a fair coin, which has the maximum entropy <span class="math inline">\(H=1\)</span> . If you wanted to describe such sequence, like</p>
<blockquote class="blockquote">
<p>HHHHHHHHHHHHHHHHHHHHHTHHHHHHHHHHHHHTHHHHT</p>
</blockquote>
<p>you might find yourself saying something like “21 H, 13 H, 4 H”, with the understanding that between each string of heads there’s one tail. Such a description is shorter than the original sequence, which is possible because of the high degree of predictability. This isn’t a like for like comparison, however, because we’ve introduced extra symbols including the digits 0-9 and some delimiter like the comma. We should instead compare with a binary code of only two symbols. How can we exploit the lower entropy of the sequence to come up with an encoding that is better than the “literal” one? One (not very practical) way is to use the fact that we expect <span class="math inline">\(N_H=Np_H\)</span> heads and <span class="math inline">\(N_T=N p_T\)</span> tails, so we can just give the <em>ordering</em> of these heads and tails, which is one of</p>
<p><span class="math display">\[
\frac{N!}{N_H! N_T!}
\]</span></p>
<p>possibilities. If we label each of these with a binary number, we end up with a description of length</p>
<p><span class="math display">\[
\log_2\left(\frac{N!}{N_H! N_T!}\right)\sim N H[p]\leq N
\]</span></p>
<p>(where we used Stirling’s approximation <span class="math inline">\(\log n! \sim n\log n -n\)</span>). Now of course, we are unlikely to get exactly this number of heads and tails, but correcting for this requires a number of bits that can be neglected in the large <span class="math inline">\(N\)</span> limit (i.e.&nbsp;it is <span class="math inline">\(o(N)\)</span>).</p>
<p>This example is the simplest illustration of <a href="https://en.wikipedia.org/wiki/Shannon%27s_source_coding_theorem">Shannon’s source coding theorem</a>:</p>
<blockquote class="blockquote">
<p>N i.i.d. random variables each with entropy H(X) can be compressed into more than N H(X) bits with negligible risk of information loss, as N → ∞; but conversely, if they are compressed into fewer than N H(X) bits it is virtually certain that information will be lost.</p>
</blockquote>
<p>Shannon’s theorem is the core idea that underlies (lossless) data compression: the more predictable a signal (i.e.&nbsp;the lower the entropy) the more it can be compressed, with the entropy setting a fundamental limit on the number of bits required.</p>
<p>How is this idea applied in the real world? It’s probably clear that real binary data doesn’t have a preponderance of 1s or 0s, that would obviously be inefficient. It all hinges on what you regard as your iid random variables. For example, text consists of strings of characters, of which there are 143,859 in the <a href="https://home.unicode.org/">Unicode standard</a>, including scripts from different languages and Screaming Cat 🙀. These obviously don’t occur with the same frequency, so the entropy is going to be much less than <span class="math inline">\(\log_2(143859)\approx 17.1\)</span> bits per character. Very roughly, a compression scheme involves choosing short codewords for common characters and long codewords for rare characters. Immediately you’ll notice there’s an issue in deciding where one character ends and the next begins. If you’re interested in how this works in practice, see <a href="https://en.wikipedia.org/wiki/Huffman_coding">Huffman coding</a>, <a href="https://en.wikipedia.org/wiki/Arithmetic_coding">arithmetic coding</a>, and <a href="https://en.wikipedia.org/wiki/Asymmetric_numeral_systems">asymmetric numeral systems</a>, or the book <a href="https://www.oreilly.com/library/view/understanding-compression/9781491961520/">Understanding Compression</a>.</p>
<p>The bigger issue, however, is that text <em>doesn’t</em> consists of iid characters, even if drawn with the right frequencies. A <a href="https://en.wikipedia.org/wiki/Markov_model">Markov model</a> would be the natural next step, in which the probability of each character is conditional on the preceding character: <span class="math inline">\(p(x_{n+1}|x_{n})\)</span>. You’re likely (in English) to encounter a <code>u</code> after a <code>q</code>, for instance. Next you can go to a “second order” Markov model, with <span class="math inline">\(p(x_{n+1}|x_{n}, x_{n-1})\)</span>, and so on. <a href="https://ieeexplore.ieee.org/document/6773067">Shannon’s original paper</a> is wonderfully clear and provides examples of experiments on these models. He calls the character frequency model “first order” and the Markov model “second order”.</p>
<p>What really matters, then, is <em>how good your model is</em>. Suppose you want to compress data that consists of (unrelated) images. Each image is described by the RGB values of all the pixels: we’ll denote these values collectively by <span class="math inline">\(\mathbf{x}\)</span>. If you choose your encoding according to some model probabilities <span class="math inline">\(p_\text{M}(\mathbf{x})\)</span>, the encoding of image <span class="math inline">\(\mathbf{x}\)</span> will have length <span class="math inline">\(-\log_2\left[p_\text{M}(\mathbf{x})\right]\)</span> bits. When you encode your data you get on average</p>
<p><span class="math display">\[
-\frac{1}{N}\sum_{\mathbf{x}} \log_2\left[p_\text{M}(\mathbf{x})\right] = -\sum_{\mathbf{x}} p_\text{D}(\mathbf{x})\log_2\left[p_\text{M}(\mathbf{x})\right]
\]</span></p>
<p>bits per image, where <span class="math inline">\(p_\text{D}(\mathbf{x})\)</span> is the <strong>empirical distribution</strong> of the data. The quantity on the RHS is called the <a href="https://en.wikipedia.org/wiki/Cross_entropy">cross entropy</a> (or relative entropy) <span class="math inline">\(H(p_\text{D}, p_\text{M})\)</span>. As we’ll see in the next section, it has the key property that is it bounded from below by the entropy <span class="math inline">\(H(p_\text{D})\)</span></p>
<p><span class="math display">\[
H(p_\text{D}, p_\text{M})\geq H(p_\text{D}).
\]</span></p>
<p>The trade-off, then, is</p>
<ul>
<li>By considering bigger chunks of data you approach closer to the iid situation to which Shannon’s theorem applies, <strong>but</strong></li>
<li>These big chunks (images in our example) will have correspondingly more complicated distributions <span class="math inline">\(p_\text{D}\)</span>, which your model <span class="math inline">\(p_\text{M}\)</span> will have to match if you want to approach optimal encoding.</li>
</ul>
</section>
<section id="divergences" class="level4">
<h4 class="anchored" data-anchor-id="divergences">Divergences</h4>
<p>The above discussion should make it clear that we need some way of talking about the degree to which two distributions differ. The most common measure in use in ML is the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback–Leibler divergence</a> (KL)</p>
<p><span class="math display">\[
D_\text{KL}(p||q)=\sum_x p(x)\log\left(\frac{p(x)}{q(x)}\right)=\E_{x\sim p}\log\left(\frac{p(x)}{q(x)}\right).
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>More notation. <span class="math inline">\(\E\)</span> denotes the expectation and <span class="math inline">\(x\sim p\)</span> means that <span class="math inline">\(x\)</span> follows the distribution <span class="math inline">\(p\)</span>. Thus <span class="math display">\[
\E_{x\sim p}\left[f(x)\right]=\sum_x p(x)f(x)
\]</span></p>
</div>
</div>
<p>It’s not hard to show that the KL is related to the cross entropy we just introduced by</p>
<p><span class="math display">\[
H(p,q)= D_\text{KL}(p||q)+ H(p).
\]</span></p>
<p>Thus the statement that the cross entropy <span class="math inline">\(H(p,q)\)</span> is bounded from below by the entropy <span class="math inline">\(H(p)\)</span> is equivalent to the KL being non-negative</p>
<p><span class="math display">\[
D_\text{KL}(p||q)\geq 0
\]</span></p>
<p>This is simple consequence of <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality">Jensen’s inequality</a>, which is the statement that for a convex function <span class="math inline">\(\varphi(x)\)</span></p>
<p><span class="math display">\[
\E\left[\varphi(x))\right]\geq \varphi\left(\E\left[x\right]\right)
\]</span></p>
<p>If we apply this to the KL then, using the convexity of <span class="math inline">\(\varphi(x)=-\log(x)\)</span></p>
<p><span class="math display">\[
D_\text{KL}(p||q)=-\E_{x\sim p}\log\left(\frac{q(x)}{p(x)}\right)\geq -\log\left(\E_{x\sim p}\left[\frac{q(x)}{p(x)}\right]\right)=-\log(1)=0,
\]</span></p>
<p>with equality if and only if <span class="math inline">\(p=q\)</span>.</p>
<!-- By the way, the term **divergence** is used to distinguish from a **distance**, which is symmetric and satisfies the triangle inequality.



KL page discusses relation to coding

[Sanov theorem](https://en.wikipedia.org/wiki/Sanov%27s_theorem) but Wikipedia page isn't great.

Divergences, KL divergences. Properties. 

Gibbs inequality. ELBO

How compressed is your signal in practice? KL



Minimal description length

- [ ] Forward and reverse KL and the meaning -->
</section>
</section>
<section id="variational-inference-vi" class="level3">
<h3 class="anchored" data-anchor-id="variational-inference-vi">Variational inference (VI)</h3>
<p>After introducing Bayes’ theorem we discussed how you might go about fitting a model to data. It’s not as easy we made it sound. Recall that Bayes’ says the posterior distribution is</p>
<p><span class="math display">\[
p(z|x) = \frac{p(x|z)p(z)}{p(x)}=\frac{p(x,z)}{p(x)}.
\]</span></p>
<p>The denominator <span class="math inline">\(p(x)=\sum_z p(x,z)\)</span> normalizes the distribution <span class="math inline">\(p(z|x)\)</span>, just like the partition function of a SM model. If we are dealing with a complicated latent variable model where <span class="math inline">\(z\)</span> and <span class="math inline">\(x\)</span> are both high dimensional, and <span class="math inline">\(p(x,z)\)</span> has a complex structure, this is intractable.</p>
<!-- The problems are

1. We don't actually have $p(x)$, just a dataset that we interpret as providing samples from $p(x)$.

2. If the data is highly structured and complex (keep our images example in mind) then $p(x|z)$ will have to be a similarly complicated model if it's going to have a chance of success. Think of the Ising model with all sorts of nasty couplings and fields. To evaluate $p(x|z)$ we are going to have to calculate the normalization factor aka the partition function $Z$, and that's going to be hard for a big model. -->
<p>In this section we’ll see that it’s possible to develop a variational formulation of the problem that returns the “best” posterior given a family of models. It’s basically a straight copy of physicists’ mean field theory, so we’ll review that first using the language of probability.</p>
<section id="mean-field-theory" class="level4">
<h4 class="anchored" data-anchor-id="mean-field-theory">Mean field theory</h4>
<p>For an SM model like the Ising model the probability has the form</p>
<p><span class="math display">\[
p(\sigma) = \frac{\exp\left[-\beta\cE(\sigma)\right]}{Z}.
\tag{4}
\label{eq:boltzmann}
\]</span></p>
<p>The goal is to find expectations, for example the average energy <span class="math inline">\(\E_{\sigma\sim p}\left[\cE(\sigma)\right]\)</span>. Since this is difficult for the <span class="math inline">\(p(\sigma)\)</span> nature gives us we are going to try and approximate <span class="math inline">\(p(\sigma)\)</span> by a <em>simpler</em> class of distributions <span class="math inline">\(q_\phi(\sigma)\)</span>, where <span class="math inline">\(\phi\)</span> denote the parameters that define the family, and find the <em>best</em> approximation.</p>
<p>What does <em>simpler</em> mean? It means one where we can actually calculate expectations (with the resources we have available). Probably the most drastic simplification we can take is to suppose that the variables are independent, so that the probability distribution factorizes</p>
<p><span class="math display">\[
q_\phi(\sigma)=\prod_n q_{\phi_n}(\sigma_n).
\tag{5}
\label{eq:factor}
\]</span></p>
<p>We are allowing for the single spin distributions to be different, which will be appropriate for an inhomogeneous model, the kind of thing you would use to describe a disordered spin system.</p>
<p>What does <em>best</em> mean? We’ve seen that the KL quantifies the difference between distributions, so it’s natural to try to minimize</p>
<p><span class="math display">\[
D_\text{KL}(q||p)=\E_{\sigma\sim q_\phi}\left[\log\left(\frac{q_\phi(\sigma)}{p(\sigma)}\right)\right].
\]</span></p>
<p>Why do we minimize <span class="math inline">\(D(q||p)\)</span> and not <span class="math inline">\(D(p||q)\)</span>? The pragmatic answer is: <em><span class="math inline">\(D(q||p)\)</span> is the one we can calculate</em>, as it involves an expectation with respect to the tractable trial distribution. Substituting in the Boltzmann distribution <span class="math inline">\(\eqref{eq:boltzmann}\)</span> we find</p>
<p><span class="math display">\[
D_\text{KL}(q||p)= \log Z - H[q_\phi] + \beta \E_{\sigma\sim q_\phi}\left[\cE(\sigma)\right]\geq 0,
\]</span></p>
<p>or in usual SM language</p>
<p><span class="math display">\[
\E_{\sigma\sim q_\phi}\left[\cE(\sigma)\right]-TH[q_\phi] \geq F,
\tag{6}
\label{eq:mft}
\]</span></p>
<p>where <span class="math inline">\(F=-T\log Z\)</span> is the Helmholtz free energy. This is known as variously as the <a href="https://en.wikipedia.org/wiki/Helmholtz_free_energy#Bogoliubov_inequality">Bogoliubov</a> or <a href="https://en.wikipedia.org/wiki/Gibbs%27_inequality">Gibbs</a> inequality. By optimizing the left hand side over <span class="math inline">\(\phi\)</span> we can find the best approximation within our family, and it will achieve a free energy closest to the true value.</p>
<p>For Ising spins our factorized distributions <span class="math inline">\(\eqref{eq:factor}\)</span> are defined by fields on each site</p>
<p><span class="math display">\[
q_{\phi_n}(\sigma_n) = \frac{\exp\left[-\beta\phi_n\sigma_n\right]}{2\cosh (\beta\phi_n)},
\]</span></p>
<p>with average spin</p>
<p><span class="math display">\[
\E_{\sigma_n\sim q_n}\left[\sigma_n\right] = -\tanh\left(\beta\phi_n\right).
\]</span></p>
<p>Optimizing <span class="math inline">\(\eqref{eq:mft}\)</span> with respect to <span class="math inline">\(\phi_n\)</span> reproduces the equations of <a href="https://en.wikipedia.org/wiki/Mean-field_theory#Ising_model">mean field theory</a>. The optimal values of <span class="math inline">\(\phi_n\)</span> are interpreted as the “mean fields” due to the applied field and the other spins coupled to <span class="math inline">\(\sigma_n\)</span>.</p>
</section>
<section id="vi-in-latent-variable-models" class="level4">
<h4 class="anchored" data-anchor-id="vi-in-latent-variable-models">VI in latent variable models</h4>
<p>The only thing we need to do to apply the same idea to latent variable models is to replace <span class="math inline">\(\eqref{eq:boltzmann}\)</span> with</p>
<p><span class="math display">\[
p(z|x) =\frac{p(x,z)}{p_\text{M}(x)}.
\]</span></p>
<p>(we add the subscript “M” for model) The role of the spins <span class="math inline">\(\sigma\)</span> is now played by the latent variables. Following exactly the same steps leads us to</p>
<p><span class="math display">\[
\log p_\text{M}(x) \geq \E_{z\sim q_\phi(\cdot|x)}\left[\log p(x,z)\right]+ H[q_\phi(\cdot|z)].
\tag{7}
\label{eq:elbo}
\]</span></p>
<p>The right hand side is called the <a href="https://en.wikipedia.org/wiki/Evidence_lower_bound">Evidence lower bound</a> or <strong>ELBO</strong> (because the marginalized probability <span class="math inline">\(p(x)\)</span> on the left is sometimes called the <strong>model evidence</strong>).</p>
<p>It’s possible to re-write <span class="math inline">\(\eqref{eq:elbo}\)</span> as</p>
<p><span class="math display">\[
\log p_\text{M}(x) \geq \log p_\text{M}(x) - D_\text{KL}(q_\phi(\cdot|x)||p(\cdot|x)),
\]</span></p>
<p>so the bound is saturated when the variational posterior for the latent variables coincides with the true posterior <span class="math inline">\(p(z|x)=p(x,z)/p_\text{M}(x)\)</span>.</p>
<p>For complicated models it isn’t practical to optimize the ELBO for each data point <span class="math inline">\(x\)</span> to obtain the best <span class="math inline">\(\phi(x)\)</span>. Instead, we average over the entire data set (this is called <em>amortization</em>, a pretty confusing term). I like to think of this as follows. We have two representations of the same joint distribution. One (“forward”) in terms of the generative model and the prior</p>
<p><span class="math display">\[
p_\text{F}(x,z)= p(x|z)p(z)
\]</span></p>
<p>and the other (“backward”) in terms of the data distribution <span class="math inline">\(p_\text{D}(x)\)</span> and the posterior</p>
<p><span class="math display">\[
p_\text{B}(x,z)= q_\phi(z|x)p_\text{D}(x).
\]</span></p>
<p>To make the two equal we should minimize the KL over joint distributions</p>
<p><span class="math display">\[
D_\text{KL}(q||p)(p_\text{B}||p_\text{F})=\E_{x\sim \text{Data}}\left[\E_{z\sim q_\phi(\cdot|x)}\left[\log\left(\frac{q_\phi(z|x)p_\text{D}(x)}{p(x|z)p(z)}\right)\right]\right]\geq 0,
\]</span></p>
<p>or</p>
<p><span class="math display">\[
H[p_\text{D}]\leq H(p_\text{D}, p_\text{M}) \leq \E_{x\sim \text{Data}}\left[\E_{z\sim q_\phi(\cdot|x)}\left[\log\left(\frac{q_\phi(z|x)}{p(x|z)p(z)}\right)\right]\right].
\]</span></p>
<p>By improving our posterior we can saturate the second equality. By improving our generative model <span class="math inline">\(p(x|z)\)</span> we can saturate the first.</p>
<p>A popular modern approach is to introduce models <span class="math inline">\(q_\phi(x|z)\)</span> and <span class="math inline">\(p_\theta(z|x)\)</span>, often parameterized in terms of neural networks, and optimize both sets of parameters <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span> simultaneously. This is the basis of the <a href="https://en.wikipedia.org/wiki/Autoencoder#Variational_autoencoder_(VAE)">Variational Autoencoder</a>, which we’ll meet in the next lecture.</p>
<!-- #### A toy model


Community detection
Other stuff. Message passing

Example of planted models

### A zoo of models

Graphical models, Markov models, autoregressive models

Hidden Markov models

Examples from applications

### Formalising the problem

See Alemi paper "the world we want" 



## Lecture 2: Models

### Variational autoencoder

Continuous *vs.* discrete variables.

Bits back encoding

### Normalizing flows

Relation to VAEs

### Diffusion models

### Optimal Importance Sampling

Jarzynski inequality. Annealed importance sampling

### Schrodinger bridge

Turning a model into an autoregressive model -->


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>