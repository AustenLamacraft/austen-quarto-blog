---
title: "The Planted Directed Polymer"
author: "Austen Lamacraft (Cambridge) and Sun Woo Kim (KCL)"
data: 
format:
  revealjs:
    theme: default
    slide-number: true
    hash: true
    center: true
    auto-stretch: false
    html-math-method: katex
    preview-links: true
---

![](assets/2_good_image.svg)

---

![](assets/3_good_inference.svg)

## Outline

- Inferring a path in a noisy image

- Relation to directed polymer

- Numerics in $d=1+1$

- Analytic solution on tree


<!-- - Kalman filter
  - As an inference problem

- Relation to measurement induced phase transition
- Planting. Connection to other problems.
- Machine learning approaches and models used
- Data Assimilation
- Other occurrences in the literature (road tracking, etc)

- Measures: overlap. RMS error

- The 1D case
  - Wandering exponent and KPZ scaling
  - Connection to quantum mechanics and Feynman-Kac
  - Free energy profiles

- The tree case
  - Recursion
  - Overlap
  - Transition in the planted case -->

## Bayes' rule

- Measure $y$, infer $x$ based on prior $p(x)$ and model $p(y|x)$
$$
\begin{align*}
p(x|y) = \frac{p(y|x)p(x)}{p(y)}\\
p(y) = \int dx \,p(y|x)p(x)
\end{align*}
$$

## Inference in HMM

![](assets/1000px-Hmm_temporal_bayesian_net.svg.png)

$$
\begin{align*}
p(x_t|y_{1:t})&=\frac{p(y_t|x_t)p(x_t|y_{1:t-1})}{p(y_t)}\\
&=\frac{p(y_t|x_t)}{p(y_t)}\sum_{x_{t-1}}p(x_t|x_{t-1})p(x_{t-1}|y_{1:t-1})
\end{align*}
$$

- Separate update of $x$ by $p(x_t|x_{t-1})$ and reweighting due to measurement outcome $y_t$ 

## Filtering, smoothing, etc.

- _Filtering_ is  estimation of current state $x_t$ based on past history of $y_{1:t}$ i.e. $p(x_t|y_{1:t})$

- _Smoothing_ uses all measurements $y_{1:T}$ up to some time horizon $T$ i.e. $p(x_t|y_{1:T})$

## Example: [Kalman filter](https://en.wikipedia.org/wiki/Kalman_filter)

<figure align="center">
<img src="assets/1000px-Hmm_temporal_bayesian_net.svg.png" width="70%"/>
</figure>

$$
\begin{align*}
x_{t} = x_{t-1} + w_t\qquad y_{t} = x_t + v_t \\
w_t\sim \mathcal{N}(0,\sigma^2)\qquad v_t\sim\mathcal{N}(0,\sigma_y^2)\\
p(x_t|x_{t-1}, y_t) = \frac{p(x_t|x_{t-1})p(y_t|x_t)}{p(y_t)}
\end{align*}
$$

- Prediction is Gaussian!

## "Image" model

- Take $x_t\in \mathbb{Z}$ simple random walk
- "Pixel" values $\phi_{x,t}\sim \mathcal{N}(\epsilon\delta_{x,x_t}, \sigma^2)$ 
- Nonlinear! (c.f. Kalman)


- What is $p(x_t|\phi_{1:t})$?

---

![](assets/1_true_path.svg)

---

![](assets/2_good_image.svg)

---

![](assets/3_good_inference.svg)

---

![](assets/4_bad_image.svg)

---

![](assets/5_bad_inference.svg)


## Application: road tracking

- [Yuille and Coughlan (2000)](https://ieeexplore.ieee.org/abstract/document/825754)

![](assets/road-tracking.png)


- [Offer (2018)](https://ieeexplore.ieee.org/abstract/document/8455360): Phase Transition in Bayesian Tracking in Clutter


## Image distribution
$$
\begin{align*}
p(\varphi_t|x_t) &= \prod_{\xi\in\mathbb{Z}}\frac{1}{\sqrt{2\pi \sigma_\varphi^2 }} \exp\left[-\frac{\left(\varphi_{\xi,t}-\epsilon \delta_{x_t,\xi}\right)^2}{2\sigma_\varphi^2}\right]\\
&= \pi(\varphi_t)\prod_{\xi\in\mathbb{Z}}\exp\left[\frac{\delta_{x_t,\xi}\left(\epsilon\varphi_{x,t}-\frac{\epsilon^2}{2}\right)}{\sigma_\varphi^2}\right]\\
&= \pi(\varphi_t)\exp\left[-h(x_t,\varphi_{x_t,t})\right]
\end{align*}
$$

- $\exp(-h(x_t,\varphi_{x_t,t})$ represents change in Gaussian measure due to presence of walker ("polymer")

---

- Marginalizing over random walker gives

$$
\begin{align*}
p(\varphi_{1:T}) &= \frac{\pi(\varphi_{1:T})}{\mathcal{N}_T}\sum_{x_{1:T}} \exp\left[-\sum_{t=1}^T h(x_t,\varphi_{x_t,t})\right]\\
&\equiv\frac{\pi(\varphi_{1:T})}{\mathcal{N}_T} Z_T(\varphi_{1:T})
\end{align*}
$$

- Assuming uniform prior $p(x_{1:T})=1/\mathcal{N}_T$ ($\mathcal{N}_T$ is number of trajectories of length $T$) 

- Key point: distribution of $\varphi_{\xi,t}$ is affected by the polymer trajectories "planted" in it, via $\epsilon$

---

- Posterior is then normalized Boltzmann probability
$$
p(x_{1:T}|\varphi_{1:T}) = \frac{\exp\left[-\sum_{t=1}^T h(x_t, \varphi_{x_t,t})\right]}{Z_T(\varphi_{1:T})}
$$

- Unnormalized posterior $q(x_T|\varphi_{1:T})$ obeys
$$
\begin{align*}
q(x_T|\varphi_{1:T}) &= e^{-h(x_T,\varphi_{x_T, T})}\sum_{x_{T-1}}p(x_T|x_{T-1}) q(x_{T-1}|\varphi_{1:T-1})\\
Z(\varphi_{1:T}) &= \sum_{x_T} q(x_T|\varphi_{1:T})
\end{align*}
$$

- $q$ "point-to-point" partition function or imaginary-time "wavefunction" in path integral picture


---

## Directed Polymer

- Classic problem in statistical physics of disordered systems

- Walker $x_t$ ("polymer") weighted by Boltzmann weight 
$$
\exp\left[-\beta\sum_t \varphi_{x_t,t}\right]
$$
(inverse temperature $\beta$)

- Iid random "potential" $\varphi_{x,t}\sim \mathcal{N(0,\sigma_\varphi^2)}$ 

---

![Source: [Kardar, Statistical Physics of Fields](https://www.cambridge.org/core/books/statistical-physics-of-fields/06F49D11030FB3108683F413269DE945) ](assets/directed-polymer.png)

## Phenomenology

- __High temperature phase__ ($\beta$ small, weak potential): random walk with _wandering exponent_ $1/2$ ($x\sim t^{1/2}$)

- __Low temperature phase__: polymer _pinned_ by disorder
 
- $d=1+1$ always in low temperature phase. Wandering exponent $z=2/3$ (_superdiffusion_)


## Planting

- $p(\varphi_{1:T})$ determined by "ground truth"

- _Planting_: generate samples by sampling $x_t$ from prior and using observation model $p(\varphi_{1:T}|x_{1:T})$ (see [Zdeborová & Krzakala (2016)](https://www.tandfonline.com/doi/full/10.1080/00018732.2016.1211393))

![](assets/2_good_image.svg)

## "Teacher-Student" setting

- Simulate "true" trajectory $x^*_{1:T}$; generate measurements from $p(\varphi_{t}|x_{1:T}^*)$; infer posterior $p(x_{1:T}|\varphi_{1:T})$

$$
\begin{align*}
p(X,X^*,\Phi) &= p(X|\Phi)p(\Phi|X^*)p(X^*)\\
&= \frac{p(\Phi|X)p(X)p(\Phi|X^*)p(X^*)}{p(\Phi)}\\
\end{align*}
$$

- $X$ and $X^*$ are _conditionally_ independent given $\Phi$

---

$$
\begin{align*}
p(X,X^*,\Phi) = \frac{p(\Phi|X)p(X)p(\Phi|X^*)p(X^*)}{p(\Phi)}\\
\end{align*}
$$

-  _Symmetry_ between $X$ and $X^*$ is a consequence of the distribution $p(\Phi|X^*)$ being identical to $p(\Phi|X)$. Likewise $p(X^*)$ and prior $p(X)$

 - This is _Bayes optimal_ setting, and corresponds to the _Nishimori point_ in spin glasses
 
 - The wandering exponent of $x_t$ must be $1/2$, as for $x_t^*$

## Non-optimal case

- $p(\varphi_{1:T})$ depends on teacher parameter $\epsilon_\text{t}$

$$
p(\varphi_{1:T}) = \frac{\pi(\varphi_{1:T})}{\mathcal{N}_T}\sum_{x_{1:T}} \exp\left[\sigma_\varphi^{-2}\sum_{t=1}^T \left(\epsilon_\text{t}\varphi_{x_t,t}-\frac{\epsilon_\text{t}^2}{2}\right)\right]
$$

- When $\epsilon_\text{t}=0$ iid disorder: directed polymer!

---

- $p(x_{1:t}|\varphi_{1:T})$ depends on student parameter $\epsilon_\text{s}$

$$
p(x_{1:T}|\varphi_{1:T}) = \frac{\exp\left[-\sum_{t=1}^T h_{\epsilon_\text{s}}(x_t, \varphi_{x_t,t})\right]}{Z_T(\varphi_{1:T})}
$$

- $\epsilon_\text{s}$ sets polymer temperature / disorder

- Large $\epsilon_\text{s}$: confidence in signal even if signal is weak!

## Measures

- Mean square error

$$
\text{MSE}_t \equiv \operatorname{\mathbb{E}}\left[\left(x_t-x_t^*\right)^2\right]
$$

- Overlap (for discrete variables)

$$
\text{O} \equiv \frac{1}{T}\operatorname{\mathbb{E}}\left[\sum_{t=1}^T\delta_{x_t,x_t^*}\right]
$$

---

## Data Assimilation


$$
p(x_t|x_{t-1}, y_t) = \frac{p(x_t|x_{t-1})p(y_t|x_t)}{p(y_t)}
$$

- Applies also to _deterministic_ dynamics $x_t = f(x_{t_1})$

$$
p(x_t|x_{t-1}) = \begin{cases}
1 & x_t = f(x_{t_1})\\
0 & \text{otherwise}
\end{cases}
$$

---

- Challenge of many degrees of freedom (e.g. weather)

- Recent ML based methods e.g. score-based data assimilation [Rozet and Louppe (2023)](https://arxiv.org/abs/2306.10574)

![](assets/rozet-louppe.png)

## Quantum systems

- Described by __density matrix__ $\rho$, playing role of $p(x_t)$

- Updated after some measurement $M_\alpha$

$$
\rho\longrightarrow \frac{M_\alpha\rho M_\alpha^\dagger}{\operatorname{tr}\left[M_\alpha \rho M^\dagger_\alpha\right]}
$$

- Similar to Bayesian update
$$
p(x_t|x_{t-1}, y_t) = \frac{p(x_t|x_{t-1})p(y_t|x_t)}{p(y_t)}
$$


## Measurement induced phase transition

- [Skinner, Ruhman, Nahum (2019)](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.9.031009), [Li, Chen, Fisher (2019)](https://journals.aps.org/prb/abstract/10.1103/PhysRevB.100.134306)


![Source: [Gullans and Huse (2020)](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.10.041020)](assets/gullans-huse-circuit.png)


---

- [Gullans and Huse (2020)](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.10.041020) purification transition

![](assets/gullans-huse-phase-diagram.png)


## Numerics in $d=1+1$

<figure align="center">
<img src="assets/20_free_energy_profile_quadratic.svg" width="80%"/>
</figure>


---

<figure align="center">
<img src="assets/21_free_energy_profile_flat.svg" width="80%"/>
</figure>

---

<figure align="center">
<img src="assets/17_rms_crossover.svg" width="80%"/>
</figure>

- Recall $\epsilon_\text{t}=0$ is directed polymer with exponent $2/3$

- Finite $\epsilon_\text{t}$ gives crossover to random walk at long times

---

<figure align="center">
<img src="assets/16_rms_dist_plateau.svg" width="80%"/>
</figure>

- Finite $\epsilon_\text{t}$ leads to saturation as $t\to\infty$

---

## Conjectured phase diagram

<figure align="center">
<img src="assets/19_1d_phase_diagram.svg" width="60%"/>
</figure>

## Walking on a tree: soluble case

<figure align="center">
<img src="assets/derrida-spohn-tree.png" width="50%"/>
<figcaption>
Source: [Derrida and Spohn (1988)](https://link.springer.com/article/10.1007/BF01014886)
</figcaption>
</figure>

- Branching number $K=2$ here

---

<figure align="center">
<img src="assets/6_tree_true_path.svg" width="70%"/>
</figure>

---

<figure align="center">
<img src="assets/7_tree_good_image.svg" width="70%"/>
</figure>

---

<figure align="center">
<img src="assets/8_tree_good_inference.svg" width="70%"/>
</figure>

---

<figure align="center">
<img src="assets/9_tree_bad_image.svg" width="70%"/>
</figure>

---

<figure align="center">
<img src="assets/10_tree_bad_inference.svg" width="70%"/>
</figure>

## Recursion relation for $Z(\epsilon_\text{t}, t)$

- Tree of depth $t$ formed from $K$ trees of depth $t-1$

<figure align="center">
<img src="assets/derrida-spohn-tree.png" width="30%"/>
</figure>

- Unplanted case ($\epsilon_\text{t}=0$): $K$ copies are iid
$$
Z(0, t) = \exp(\varphi)\sum_{i=1}^K Z_i(0, t-1)\qquad \varphi \sim\mathcal{N}(0,\epsilon_\text{s}^2\sigma_\text{t}^2/\sigma_\text{s}^4)
$$

---

- Planted case: one branch has planted path 

$$
Z(\epsilon_\text{t},t) = \exp\left(\varphi+\epsilon\right)\left[Z(\epsilon_\text{t},t-1)+\sum_{i=1}^{K-1} Z_i(0,t-1)\right]
$$

- $\epsilon \equiv \frac{\epsilon_\text{s}\epsilon_{t}}{\sigma_\text{s}^2}$ is shift due to path passing through root of tree

---

## Generating function
$$
\begin{align*}
G_{\epsilon_\text{t}}(x,t) \equiv \operatorname{\mathbb{E}}\left[\exp\left(-Z(\epsilon_\text{t},t)e^{-x}\right)\right]\\
G_{\epsilon_\text{t}}(x,t)=\begin{cases}
0 & x\to -\infty\\
1 & x\to +\infty
\end{cases}
\end{align*}
$$

- Expect $\log Z\propto t$ at long times (extensive free energy) 

- Step centred at $\sim\log Z$

---

- Satisfies the linear equation

$$
G_{\epsilon_\text{t}}(x,t)  = \operatorname{\mathbb{E}}_\varphi\left[G_{\epsilon_\text{t}}(x-\varphi-\epsilon,t-1) \left(G_{0}(x-\varphi,t-1) \right)^{K-1}\right]
$$

- Along with the _nonlinear_ equation for $G_0(x,t)$

$$
G_{0}(x,t)  = \operatorname{\mathbb{E}}_\varphi\left[\left(G_{0}(x-\varphi,t-1) \right)^{K}\right]
$$

## Continuous time limit

<figure align="center">
<img src="assets/derrida-spohn-branching.png" width="30%"/>
</figure>


$$
\partial_t G_{\epsilon_{\text{t}}}=D\partial_x^2 G_{\epsilon_{\text{t}}}-v_\epsilon\partial_x G_{\epsilon_{\text{t}}} + \lambda\left(G_{0}-1\right)G_{\epsilon_{\text{t}}}
$$

- $G_0(x,t)$ satisfies Fisher KPP equation

$$
\partial_t G_{0}=D\partial_x^2 G_{0}+ \lambda\left(G_{0}-1\right)G_{0}
$$


## Traveling wave solutions

- Weak planting: $v_\epsilon < c_\beta$, speed of unplanted wave

<figure align="center">
<img src="assets/22_slower.svg" width="70%"/>
</figure>

- Step in $G_{\epsilon_T}$ "sticks" to step in $G_{0}$

---

- Strong planting: $v_\epsilon > c_\beta$

<figure align="center">
<img src="assets/23_faster.svg" width="60%"/>
</figure>
$$
\partial_t G_{\epsilon_{\text{t}}}=D\partial_x^2 G_{\epsilon_{\text{t}}}-v_\epsilon\partial_x G_{\epsilon_{\text{t}}} + \lambda\left(G_{0}-1\right)G_{\epsilon_{\text{t}}}
$$

## Overlap

$$
Z(\epsilon_\text{t},t) = \exp\left(\varphi+\epsilon\right)\left[Z(\epsilon_\text{t},t-1)+\sum_{i=1}^{K-1} Z_i(0,t-1)\right]
$$

- Partition function is weighted sum of contributions with different overlaps $Y=\sum_{t} \delta_{x_t, x_t^*}$
$$
\begin{align*}
Z(\epsilon_\text{t},t) = \sum_{Y=1}^T e^{\epsilon Y} Z_Y(t) \\
\langle Y\rangle = \frac{\partial \log Z(\epsilon_\text{t}, t)}{\partial \epsilon}
\end{align*}
$$

---

$$
\begin{align*}
\langle Y\rangle = \frac{\partial \log Z(\epsilon_\text{t}, t)}{\partial \epsilon}
\end{align*}
$$

- If fluctuations of $\log Z(\epsilon_\text{t}, t)$ are _sub-extensive_, $\operatorname{\mathbb{E}}\left[\log Z(\epsilon_\text{t}, t)\right]\sim \text{step position}$

<figure align="center">
<img src="assets/23_faster.svg" width="50%"/>
</figure>


## Phase diagram

<figure align="center">
<img src="assets/18_tree_phase_diagram.svg" width="70%"/>
</figure>

## Summary

- Inferring path from images related to __directed polymer__

- Phase transition in inference success, at least on tree (and perhaps $d>1+1$?)

- Relation to data assimilation and quantum systems?